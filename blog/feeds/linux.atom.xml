<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Petko's Coding Blog - Linux</title><link href="http://pminkov.github.io/blog/" rel="alternate"></link><link href="http://pminkov.github.io/blog/feeds/linux.atom.xml" rel="self"></link><id>http://pminkov.github.io/blog/</id><updated>2017-07-30T21:57:00-07:00</updated><entry><title>Versioning Docker Images</title><link href="http://pminkov.github.io/blog/versioning-docker-images.html" rel="alternate"></link><published>2017-07-30T21:57:00-07:00</published><updated>2017-07-30T21:57:00-07:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2017-07-30:/blog/versioning-docker-images.html</id><summary type="html">&lt;p&gt;If you're running Docker containers in the cloud, you're probably uploading them into a registry. If you're using Google Cloud, that would be &lt;a href="https://cloud.google.com/container-registry/"&gt;gcr.io &lt;/a&gt;(Google Container Registry).&lt;/p&gt;
&lt;p&gt;As you're iterating on your application, you'll need to push new Docker images to the registry. A natural questions that comes is …&lt;/p&gt;</summary><content type="html">&lt;p&gt;If you're running Docker containers in the cloud, you're probably uploading them into a registry. If you're using Google Cloud, that would be &lt;a href="https://cloud.google.com/container-registry/"&gt;gcr.io &lt;/a&gt;(Google Container Registry).&lt;/p&gt;
&lt;p&gt;As you're iterating on your application, you'll need to push new Docker images to the registry. A natural questions that comes is how to version these images? You don't want to overwrite images using the same tag and it's cumbersome to keep track of increasing version numbers. A good versioning scheme is to use a &lt;a href="https://blog.thoughtram.io/git/2014/11/18/the-anatomy-of-a-git-commit.html"&gt;git commit hash&lt;/a&gt;. So your image name might looks like this: &lt;code&gt;gcr.io/kubeproject-172120/simple:88d38d9&lt;/code&gt;. If you take your git repository at this hash, you'll find the files that produced this exact image.&lt;/p&gt;
&lt;p&gt;This sounds simple to implement. You get the last commit's hash, build the image using the hash as a tag and push it to the registry. There's one big inconvinience to this scheme though - you have to commit each change if you want to use a new hash (and you do, you don't want to overwrite your production image) and when you're iterating on an image, that gets tiresome quickly. One possible solution would be to commit "debug" images. These images might be tagged with something like this &lt;code&gt;88d38d9-debug&lt;/code&gt;. This is an image produced by taking the git repo at the &lt;code&gt;88d38d9&lt;/code&gt; hash and making some modifications. You'll know not to include these images in your production files and it's ok to overwrite them as you're iterating.&lt;/p&gt;
&lt;p&gt;So let's look at how all of this can be implemented. Let's say you're putting all your images in one directory. The contents of this directory might look like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ tree
.
├── build-image.sh
└── simple
    ├── app.py
    ├── Dockerfile
    └── requirements.txt

&lt;span class="m"&gt;1&lt;/span&gt; directory, &lt;span class="m"&gt;4&lt;/span&gt; files
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &lt;code&gt;build-image.sh&lt;/code&gt; script builds the Docker image and pushes it to &lt;code&gt;gcr.io&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The script itself looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; -z &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$1&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt;
  &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Usage: &lt;/span&gt;&lt;span class="nv"&gt;$0&lt;/span&gt;&lt;span class="s2"&gt; &amp;lt;image_dir&amp;gt; [--debug]&amp;quot;&lt;/span&gt;
  &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="nv"&gt;IMAGE_NAME&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$1&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$2&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;--debug&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt;
  &lt;span class="c1"&gt;# If we&amp;#39;re debugging, we can push code that&amp;#39;s not committed.&lt;/span&gt;
  &lt;span class="nv"&gt;APPEND&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;-debug&amp;quot;&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt;
  &lt;span class="nv"&gt;IMAGE_PATH&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/&lt;span class="nv"&gt;$IMAGE_NAME&lt;/span&gt;/

  &lt;span class="k"&gt;if&lt;/span&gt; git status . --porcelain &lt;span class="p"&gt;|&lt;/span&gt; grep &lt;span class="nv"&gt;$IMAGE_PATH&lt;/span&gt; &amp;gt; /dev/null&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;You have uncommited changes to your Docker image. Please commit them&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;before building and populating. This helps ensure that all docker images&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;are traceable back to a git commit.&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Or if you&amp;#39;re just building a debug image, use the --debug flag.&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;
  &lt;span class="k"&gt;fi&lt;/span&gt;
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="c1"&gt;# Set image tag.&lt;/span&gt;
&lt;span class="nv"&gt;GIT_REV&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;git log -n &lt;span class="m"&gt;1&lt;/span&gt; --pretty&lt;span class="o"&gt;=&lt;/span&gt;format:%h -- ./&lt;span class="nv"&gt;$IMAGE_NAME&lt;/span&gt;/&lt;span class="k"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; ! &lt;span class="nv"&gt;$GIT_REV&lt;/span&gt; &lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt;
  &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;You&amp;#39;re trying to build an image that has never been committed.&amp;quot;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;You need to commit at least one version.&amp;quot;&lt;/span&gt;
  &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="nv"&gt;TAG&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$GIT_REV&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$APPEND&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;

&lt;span class="c1"&gt;# Set image repo.&lt;/span&gt;
&lt;span class="nv"&gt;PROJECT_ID&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;gcloud config get-value project &lt;span class="m"&gt;2&lt;/span&gt;&amp;gt;/dev/null&lt;span class="k"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;DOCKER_REPO&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;gcr.io/&lt;/span&gt;&lt;span class="nv"&gt;$PROJECT_ID&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;

&lt;span class="c1"&gt;# Full image name.&lt;/span&gt;
&lt;span class="nv"&gt;IMAGE_SPEC&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$DOCKER_REPO&lt;/span&gt;&lt;span class="s2"&gt;/&lt;/span&gt;&lt;span class="nv"&gt;$IMAGE_NAME&lt;/span&gt;&lt;span class="s2"&gt;:&lt;/span&gt;&lt;span class="nv"&gt;$TAG&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;

&lt;span class="nb"&gt;cd&lt;/span&gt; &lt;span class="nv"&gt;$IMAGE_NAME&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; ! -f &lt;span class="nv"&gt;$DOCKERFILE&lt;/span&gt; &lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt;
  &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;No such file: &lt;/span&gt;&lt;span class="nv"&gt;$IMAGE_NAME&lt;/span&gt;&lt;span class="s2"&gt;/&lt;/span&gt;&lt;span class="nv"&gt;$DOCKERFILE&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
  &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="nv"&gt;$IMAGE_SPEC&lt;/span&gt;

docker build -t &lt;span class="nv"&gt;$IMAGE_SPEC&lt;/span&gt; .
gcloud docker -- push &lt;span class="nv"&gt;$IMAGE_SPEC&lt;/span&gt;

&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Pushed &lt;/span&gt;&lt;span class="nv"&gt;$IMAGE_SPEC&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;One thing to pay attention to is that the hash that we're using is the hash of the last commit to the directory that contains the container files. This way, if you want to push a production ready image (non-debug), you can only commit the files inside this directory and if you're still working on others outside of it, you can continue doing so.&lt;/p&gt;
&lt;p&gt;Let's run the &lt;code&gt;build-image.sh&lt;/code&gt; script:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ ./build-image.sh simple
gcr.io/kubehub-172120/simple:12430ce
Sending build context to Docker daemon &lt;span class="m"&gt;4&lt;/span&gt;.096 kB
Step &lt;span class="m"&gt;1&lt;/span&gt;/9 : FROM ubuntu:latest
 ---&amp;gt; 14f60031763d
Step &lt;span class="m"&gt;2&lt;/span&gt;/9 : MAINTAINER Petko Minkov &lt;span class="s2"&gt;&amp;quot;pminkov@gmail.com&amp;quot;&lt;/span&gt;
 ---&amp;gt; Using cache
 ---&amp;gt; 5a371036a9e3
Step &lt;span class="m"&gt;3&lt;/span&gt;/9 : RUN apt-get update -y
 ---&amp;gt; Using cache
 ---&amp;gt; 8992277faa20
Step &lt;span class="m"&gt;4&lt;/span&gt;/9 : RUN apt-get install -y python-pip python-dev build-essential
 ---&amp;gt; Using cache
 ---&amp;gt; 9c0937facaf0
Step &lt;span class="m"&gt;5&lt;/span&gt;/9 : COPY . /app
 ---&amp;gt; Using cache
 ---&amp;gt; dd9f289c1f55
Step &lt;span class="m"&gt;6&lt;/span&gt;/9 : WORKDIR /app
 ---&amp;gt; Using cache
 ---&amp;gt; d93c62ac371a
Step &lt;span class="m"&gt;7&lt;/span&gt;/9 : RUN pip install --upgrade pip
 ---&amp;gt; Using cache
 ---&amp;gt; cb2f0a65c93f
Step &lt;span class="m"&gt;8&lt;/span&gt;/9 : RUN pip install -r requirements.txt
 ---&amp;gt; Using cache
 ---&amp;gt; d8fd659127d9
Step &lt;span class="m"&gt;9&lt;/span&gt;/9 : CMD python app.py
 ---&amp;gt; Using cache
 ---&amp;gt; 8493c8ad1a01
Successfully built 8493c8ad1a01
The push refers to a repository &lt;span class="o"&gt;[&lt;/span&gt;gcr.io/kubehub-172120/simple&lt;span class="o"&gt;]&lt;/span&gt;
dacb974e8350: Layer already exists 
6c4d57527510: Layer already exists 
5348dff0fc19: Layer already exists 
738da70fc9f8: Layer already exists 
f665434eb0ee: Layer already exists 
26b126eb8632: Layer already exists 
220d34b5f6c9: Layer already exists 
8a5132998025: Layer already exists 
aca233ed29c3: Layer already exists 
e5d2f035d7a4: Layer already exists 
12430ce: digest: sha256:51cd80db604d1ffa5230289c1f3fe40d19b3b8dc2afb0a0c003713360b07d2c6 size: &lt;span class="m"&gt;2411&lt;/span&gt;
Pushed gcr.io/kubehub-172120/simple:12430ce
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Great, now the image is pushed. But I always like to use a "trust but verify" policy, so let's see how can we dig into what's going on at the registry.&lt;/p&gt;
&lt;p&gt;My image's name is this &lt;code&gt;gcr.io/kubehub-172120/simple&lt;/code&gt;. Here's how I see the tags I have uploaded to &lt;code&gt;gcr.io&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ gcloud beta container images list-tags gcr.io/kubehub-172120/simple
DIGEST        TAGS                   TIMESTAMP
9b424f849df2  88d38d9-debug,e8bc006  &lt;span class="m"&gt;2017&lt;/span&gt;-07-30T23:03:14
51cd80db604d  12430ce                &lt;span class="m"&gt;2017&lt;/span&gt;-07-30T23:06:42
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If you want to inspect the contents of the image, you can just run a shell, like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ gcloud docker -- run -i -t gcr.io/kubehub-172120/simple:12430ce /bin/bash
root@27cfb042d947:/app# ls
Dockerfile  app.py  requirements.txt
root@27cfb042d947:/app# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I've used this workflow when working with a Kubernetes deployment and it worked well for me. Hope it's useful for someone else too. Enjoy.&lt;/p&gt;</content></entry><entry><title>Examining a process in Linux.</title><link href="http://pminkov.github.io/blog/examining-a-process-in-linux.html" rel="alternate"></link><published>2017-03-01T12:26:00-08:00</published><updated>2017-03-01T12:26:00-08:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2017-03-01:/blog/examining-a-process-in-linux.html</id><summary type="html">&lt;p&gt;I've been thinking about writing a blog post about Linux tools and commands related to processes. Let's take a look at some of them.&lt;/p&gt;
&lt;p&gt;The process that we'll be looking at is a &lt;a href="https://github.com/pminkov/webserver"&gt;webserver&lt;/a&gt; that I wrote some time ago to practice my C and write some code that does …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've been thinking about writing a blog post about Linux tools and commands related to processes. Let's take a look at some of them.&lt;/p&gt;
&lt;p&gt;The process that we'll be looking at is a &lt;a href="https://github.com/pminkov/webserver"&gt;webserver&lt;/a&gt; that I wrote some time ago to practice my C and write some code that does network related work. This webserver runs a &lt;a href="https://github.com/pminkov/threadpool"&gt;threadpool&lt;/a&gt; where N threads are waiting for server requests that they're going to execute.&lt;/p&gt;
&lt;p&gt;So let's start the server:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ ./server
Running on port: &lt;span class="m"&gt;8000&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Great. So which process is this server running as? We can use the &lt;code&gt;pidof&lt;/code&gt; command to find that out. Its output looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ pidof server
&lt;span class="m"&gt;8876&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If we had other processes which were running an executable with that name, we'd see more process ids, but since we only have one, we see one process id.&lt;/p&gt;
&lt;p&gt;What next? Let's see how the process is layed out in memory. To do this, we can use the &lt;code&gt;pmap&lt;/code&gt; command. Its output looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ sudo pmap -p &lt;span class="m"&gt;8876&lt;/span&gt;
&lt;span class="m"&gt;8876&lt;/span&gt;:   ./server
&lt;span class="m"&gt;0000000000400000&lt;/span&gt;     16K r-x-- /home/petko/work/github/webserver/server
&lt;span class="m"&gt;0000000000603000&lt;/span&gt;      4K r---- /home/petko/work/github/webserver/server
&lt;span class="m"&gt;0000000000604000&lt;/span&gt;      4K rw--- /home/petko/work/github/webserver/server
000000000110f000    132K rw---   &lt;span class="o"&gt;[&lt;/span&gt; anon &lt;span class="o"&gt;]&lt;/span&gt;
00007fd5ca731000      4K -----   &lt;span class="o"&gt;[&lt;/span&gt; anon &lt;span class="o"&gt;]&lt;/span&gt;
00007fd5ca732000   8192K rw---   &lt;span class="o"&gt;[&lt;/span&gt; anon &lt;span class="o"&gt;]&lt;/span&gt;
00007fd5caf32000      4K -----   &lt;span class="o"&gt;[&lt;/span&gt; anon &lt;span class="o"&gt;]&lt;/span&gt;
00007fd5caf33000   8192K rw---   &lt;span class="o"&gt;[&lt;/span&gt; anon &lt;span class="o"&gt;]&lt;/span&gt;
00007fd5cb733000      4K -----   &lt;span class="o"&gt;[&lt;/span&gt; anon &lt;span class="o"&gt;]&lt;/span&gt;
00007fd5cb734000   8192K rw---   &lt;span class="o"&gt;[&lt;/span&gt; anon &lt;span class="o"&gt;]&lt;/span&gt;
00007fd5cbf34000      4K -----   &lt;span class="o"&gt;[&lt;/span&gt; anon &lt;span class="o"&gt;]&lt;/span&gt;
00007fd5cbf35000   8192K rw---   &lt;span class="o"&gt;[&lt;/span&gt; anon &lt;span class="o"&gt;]&lt;/span&gt;
00007fd5cc735000   1792K r-x-- /lib/x86_64-linux-gnu/libc-2.23.so
00007fd5cc8f5000   2044K ----- /lib/x86_64-linux-gnu/libc-2.23.so
00007fd5ccaf4000     16K r---- /lib/x86_64-linux-gnu/libc-2.23.so
00007fd5ccaf8000      8K rw--- /lib/x86_64-linux-gnu/libc-2.23.so
00007fd5ccafa000     16K rw---   &lt;span class="o"&gt;[&lt;/span&gt; anon &lt;span class="o"&gt;]&lt;/span&gt;
00007fd5ccafe000     96K r-x-- /lib/x86_64-linux-gnu/libpthread-2.23.so
00007fd5ccb16000   2044K ----- /lib/x86_64-linux-gnu/libpthread-2.23.so
00007fd5ccd15000      4K r---- /lib/x86_64-linux-gnu/libpthread-2.23.so
00007fd5ccd16000      4K rw--- /lib/x86_64-linux-gnu/libpthread-2.23.so
00007fd5ccd17000     16K rw---   &lt;span class="o"&gt;[&lt;/span&gt; anon &lt;span class="o"&gt;]&lt;/span&gt;
00007fd5ccd1b000    152K r-x-- /lib/x86_64-linux-gnu/ld-2.23.so
00007fd5ccf22000     12K rw---   &lt;span class="o"&gt;[&lt;/span&gt; anon &lt;span class="o"&gt;]&lt;/span&gt;
00007fd5ccf3e000      8K rw---   &lt;span class="o"&gt;[&lt;/span&gt; anon &lt;span class="o"&gt;]&lt;/span&gt;
00007fd5ccf40000      4K r---- /lib/x86_64-linux-gnu/ld-2.23.so
00007fd5ccf41000      4K rw--- /lib/x86_64-linux-gnu/ld-2.23.so
00007fd5ccf42000      4K rw---   &lt;span class="o"&gt;[&lt;/span&gt; anon &lt;span class="o"&gt;]&lt;/span&gt;
00007ffca0861000    132K rw---   &lt;span class="o"&gt;[&lt;/span&gt; stack &lt;span class="o"&gt;]&lt;/span&gt;
00007ffca09eb000      8K r----   &lt;span class="o"&gt;[&lt;/span&gt; anon &lt;span class="o"&gt;]&lt;/span&gt;
00007ffca09ed000      8K r-x--   &lt;span class="o"&gt;[&lt;/span&gt; anon &lt;span class="o"&gt;]&lt;/span&gt;
ffffffffff600000      4K r-x--   &lt;span class="o"&gt;[&lt;/span&gt; anon &lt;span class="o"&gt;]&lt;/span&gt;
total            39316K
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;What you see here are virtual memory addresses. For example, let's take a look at this line:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;00007fd5cc735000   1792K r-x-- /lib/x86_64-linux-gnu/libc-2.23.so&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This is the code for &lt;code&gt;libc&lt;/code&gt;, which is the C standard library. This code is shared between processes that need it. We can see the &lt;code&gt;x&lt;/code&gt; flag, which means that this is executable memory. The size if roughly the same as the size of this &lt;code&gt;so&lt;/code&gt; file. This library is memory mapped into a region starting at address &lt;code&gt;00007fd5cc735000&lt;/code&gt;, but in physical memory it's only stored in one place. To learn more about memory in Linux, here's a &lt;a href="https://techtalk.intersec.com/2013/07/memory-part-1-memory-types/"&gt;great post&lt;/a&gt; going into detail about it.&lt;/p&gt;
&lt;p&gt;Another interesting command is &lt;code&gt;lsof&lt;/code&gt;. &lt;code&gt;lsof&lt;/code&gt; stands for "list of open files". Let's see its output:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ sudo lsof -p &lt;span class="m"&gt;8876&lt;/span&gt;
COMMAND  PID  USER   FD   TYPE DEVICE SIZE/OFF    NODE NAME
server  &lt;span class="m"&gt;8876&lt;/span&gt; petko  cwd    DIR    &lt;span class="m"&gt;8&lt;/span&gt;,1     &lt;span class="m"&gt;4096&lt;/span&gt;  &lt;span class="m"&gt;262299&lt;/span&gt; /home/petko/work/github/webserver
server  &lt;span class="m"&gt;8876&lt;/span&gt; petko  rtd    DIR    &lt;span class="m"&gt;8&lt;/span&gt;,1     &lt;span class="m"&gt;4096&lt;/span&gt;       &lt;span class="m"&gt;2&lt;/span&gt; /
server  &lt;span class="m"&gt;8876&lt;/span&gt; petko  txt    REG    &lt;span class="m"&gt;8&lt;/span&gt;,1    &lt;span class="m"&gt;25536&lt;/span&gt;  &lt;span class="m"&gt;306491&lt;/span&gt; /home/petko/work/github/webserver/server
server  &lt;span class="m"&gt;8876&lt;/span&gt; petko  mem    REG    &lt;span class="m"&gt;8&lt;/span&gt;,1  &lt;span class="m"&gt;1864888&lt;/span&gt; &lt;span class="m"&gt;1184834&lt;/span&gt; /lib/x86_64-linux-gnu/libc-2.23.so
server  &lt;span class="m"&gt;8876&lt;/span&gt; petko  mem    REG    &lt;span class="m"&gt;8&lt;/span&gt;,1   &lt;span class="m"&gt;138744&lt;/span&gt; &lt;span class="m"&gt;1184980&lt;/span&gt; /lib/x86_64-linux-gnu/libpthread-2.23.so
server  &lt;span class="m"&gt;8876&lt;/span&gt; petko  mem    REG    &lt;span class="m"&gt;8&lt;/span&gt;,1   &lt;span class="m"&gt;162632&lt;/span&gt; &lt;span class="m"&gt;1184806&lt;/span&gt; /lib/x86_64-linux-gnu/ld-2.23.so
server  &lt;span class="m"&gt;8876&lt;/span&gt; petko    0u   CHR  &lt;span class="m"&gt;136&lt;/span&gt;,9      0t0      &lt;span class="m"&gt;12&lt;/span&gt; /dev/pts/9
server  &lt;span class="m"&gt;8876&lt;/span&gt; petko    1u   CHR  &lt;span class="m"&gt;136&lt;/span&gt;,9      0t0      &lt;span class="m"&gt;12&lt;/span&gt; /dev/pts/9
server  &lt;span class="m"&gt;8876&lt;/span&gt; petko    2u   CHR  &lt;span class="m"&gt;136&lt;/span&gt;,9      0t0      &lt;span class="m"&gt;12&lt;/span&gt; /dev/pts/9
server  &lt;span class="m"&gt;8876&lt;/span&gt; petko    3u  IPv4  &lt;span class="m"&gt;81993&lt;/span&gt;      0t0     TCP *:8000 &lt;span class="o"&gt;(&lt;/span&gt;LISTEN&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;As you can see, we have file descriptors 0,1 and 2, which are stdin, stdout and stderr. They are linked to the terminal in which the process is running in. You can write to that terminal btw. Just type &lt;code&gt;echo "hello world" &amp;gt; /dev/pts/9&lt;/code&gt; and you'll see that text in the terminal where your webserver is running. File descriptor number 3 is our socket which accepts connections.&lt;/p&gt;
&lt;p&gt;Another interesting way to inspect processes is the ps command. Its basic output looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ ps --pid &lt;span class="m"&gt;8876&lt;/span&gt;
  PID TTY          TIME CMD
 &lt;span class="m"&gt;8876&lt;/span&gt; pts/9    &lt;span class="m"&gt;00&lt;/span&gt;:00:00 server
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is simple. We can also show the threads inside a process, like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ ps  m --pid &lt;span class="m"&gt;8876&lt;/span&gt; -o pid,tid,cmd
  PID   TID CMD
 &lt;span class="m"&gt;8876&lt;/span&gt;     - ./server
    -  &lt;span class="m"&gt;8876&lt;/span&gt; -
    -  &lt;span class="m"&gt;8877&lt;/span&gt; -
    -  &lt;span class="m"&gt;8878&lt;/span&gt; -
    -  &lt;span class="m"&gt;8879&lt;/span&gt; -
    -  &lt;span class="m"&gt;8880&lt;/span&gt; -
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We have five threads here. One is our main thread and the other four are the threadpool threads. The &lt;code&gt;m&lt;/code&gt; option tells ps to show the threads of a process. The &lt;code&gt;-o&lt;/code&gt; option specifies fields to output. We can even get fancy and output the addresses of the threads' stack pointers and instruction pointers, like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ ps  m --pid &lt;span class="m"&gt;8876&lt;/span&gt; -o pid,tid,cmd,esp,eip
  PID   TID CMD                              ESP      EIP
 &lt;span class="m"&gt;8876&lt;/span&gt;     - ./server                           -        -
    -  &lt;span class="m"&gt;8876&lt;/span&gt; -                           a0880b70 ccb0e7ad
    -  &lt;span class="m"&gt;8877&lt;/span&gt; -                           cc733ec0 ccb0b3a0
    -  &lt;span class="m"&gt;8878&lt;/span&gt; -                           cbf32ec0 ccb0b3a0
    -  &lt;span class="m"&gt;8879&lt;/span&gt; -                           cb731ec0 ccb0b3a0
    -  &lt;span class="m"&gt;8880&lt;/span&gt; -                           caf30ec0 ccb0b3a0
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So all the threads are at the same instruction, but they have different stack pointers, which makes sense. If I execute something on one of the threads, both the &lt;code&gt;ESP&lt;/code&gt; and &lt;code&gt;EIP&lt;/code&gt; can possibly change.&lt;/p&gt;
&lt;p&gt;A lot of data about processes lives in the &lt;code&gt;proc&lt;/code&gt; filesytem, located in &lt;code&gt;/proc&lt;/code&gt;. For each running process, there's a subdirectory of &lt;code&gt;/proc&lt;/code&gt; named after the process id. For example, for our process &lt;code&gt;8876&lt;/code&gt;, there's a &lt;code&gt;status&lt;/code&gt; file which lists various information about the process. Let's look at it:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ cat /proc/8876/status
Name:   server
State:  S &lt;span class="o"&gt;(&lt;/span&gt;sleeping&lt;span class="o"&gt;)&lt;/span&gt;
Tgid:   &lt;span class="m"&gt;8876&lt;/span&gt;
Ngid:   &lt;span class="m"&gt;0&lt;/span&gt;
Pid:    &lt;span class="m"&gt;8876&lt;/span&gt;
PPid:   &lt;span class="m"&gt;2604&lt;/span&gt;
TracerPid:      &lt;span class="m"&gt;0&lt;/span&gt;
Uid:    &lt;span class="m"&gt;1000&lt;/span&gt;    &lt;span class="m"&gt;1000&lt;/span&gt;    &lt;span class="m"&gt;1000&lt;/span&gt;    &lt;span class="m"&gt;1000&lt;/span&gt;
Gid:    &lt;span class="m"&gt;1000&lt;/span&gt;    &lt;span class="m"&gt;1000&lt;/span&gt;    &lt;span class="m"&gt;1000&lt;/span&gt;    &lt;span class="m"&gt;1000&lt;/span&gt;
FDSize: &lt;span class="m"&gt;256&lt;/span&gt;
Groups: &lt;span class="m"&gt;4&lt;/span&gt; &lt;span class="m"&gt;24&lt;/span&gt; &lt;span class="m"&gt;27&lt;/span&gt; &lt;span class="m"&gt;30&lt;/span&gt; &lt;span class="m"&gt;46&lt;/span&gt; &lt;span class="m"&gt;113&lt;/span&gt; &lt;span class="m"&gt;128&lt;/span&gt; &lt;span class="m"&gt;999&lt;/span&gt; &lt;span class="m"&gt;1000&lt;/span&gt; 
NStgid: &lt;span class="m"&gt;8876&lt;/span&gt;
NSpid:  &lt;span class="m"&gt;8876&lt;/span&gt;
NSpgid: &lt;span class="m"&gt;8876&lt;/span&gt;
NSsid:  &lt;span class="m"&gt;2604&lt;/span&gt;
VmPeak:    &lt;span class="m"&gt;39316&lt;/span&gt; kB
VmSize:    &lt;span class="m"&gt;39316&lt;/span&gt; kB
VmLck:         &lt;span class="m"&gt;0&lt;/span&gt; kB
VmPin:         &lt;span class="m"&gt;0&lt;/span&gt; kB
VmHWM:       &lt;span class="m"&gt;800&lt;/span&gt; kB
VmRSS:       &lt;span class="m"&gt;800&lt;/span&gt; kB
VmData:    &lt;span class="m"&gt;32988&lt;/span&gt; kB
VmStk:       &lt;span class="m"&gt;136&lt;/span&gt; kB
VmExe:        &lt;span class="m"&gt;16&lt;/span&gt; kB
VmLib:      &lt;span class="m"&gt;2040&lt;/span&gt; kB
VmPTE:        &lt;span class="m"&gt;48&lt;/span&gt; kB
VmPMD:        &lt;span class="m"&gt;12&lt;/span&gt; kB
VmSwap:        &lt;span class="m"&gt;0&lt;/span&gt; kB
HugetlbPages:          &lt;span class="m"&gt;0&lt;/span&gt; kB
Threads:        &lt;span class="m"&gt;5&lt;/span&gt;
SigQ:   &lt;span class="m"&gt;0&lt;/span&gt;/7848
SigPnd: &lt;span class="m"&gt;0000000000000000&lt;/span&gt;
ShdPnd: &lt;span class="m"&gt;0000000000000000&lt;/span&gt;
SigBlk: &lt;span class="m"&gt;0000000000000000&lt;/span&gt;
SigIgn: &lt;span class="m"&gt;0000000000000000&lt;/span&gt;
SigCgt: &lt;span class="m"&gt;0000000180000000&lt;/span&gt;
CapInh: &lt;span class="m"&gt;0000000000000000&lt;/span&gt;
CapPrm: &lt;span class="m"&gt;0000000000000000&lt;/span&gt;
CapEff: &lt;span class="m"&gt;0000000000000000&lt;/span&gt;
CapBnd: 0000003fffffffff
CapAmb: &lt;span class="m"&gt;0000000000000000&lt;/span&gt;
Seccomp:        &lt;span class="m"&gt;0&lt;/span&gt;
Cpus_allowed:   &lt;span class="m"&gt;1&lt;/span&gt;
Cpus_allowed_list:      &lt;span class="m"&gt;0&lt;/span&gt;
Mems_allowed:   &lt;span class="m"&gt;00000000&lt;/span&gt;,00000001
Mems_allowed_list:      &lt;span class="m"&gt;0&lt;/span&gt;
voluntary_ctxt_switches:        &lt;span class="m"&gt;3&lt;/span&gt;
nonvoluntary_ctxt_switches:     &lt;span class="m"&gt;2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;There's a lot of data in here, but remember how we used &lt;code&gt;ps&lt;/code&gt; to count the number of threads in this process. That's also available here on the line saying &lt;code&gt;Threads:    5&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Our last command is &lt;code&gt;pidstat&lt;/code&gt;. &lt;code&gt;pidstat&lt;/code&gt; shows statistics about a running process, which can be updated at a regular time interval. A possible invocation can be:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ pidstat -p &lt;span class="m"&gt;8876&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;
Linux &lt;span class="m"&gt;4&lt;/span&gt;.4.0-64-generic &lt;span class="o"&gt;(&lt;/span&gt;virtbox&lt;span class="o"&gt;)&lt;/span&gt;        &lt;span class="m"&gt;03&lt;/span&gt;/01/2017      _x86_64_        &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; CPU&lt;span class="o"&gt;)&lt;/span&gt;

&lt;span class="m"&gt;12&lt;/span&gt;:22:00 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
&lt;span class="m"&gt;12&lt;/span&gt;:22:01 PM  &lt;span class="m"&gt;1000&lt;/span&gt;      &lt;span class="m"&gt;8876&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;.00    &lt;span class="m"&gt;0&lt;/span&gt;.00    &lt;span class="m"&gt;0&lt;/span&gt;.00    &lt;span class="m"&gt;0&lt;/span&gt;.00     &lt;span class="m"&gt;0&lt;/span&gt;  server
&lt;span class="m"&gt;12&lt;/span&gt;:22:02 PM  &lt;span class="m"&gt;1000&lt;/span&gt;      &lt;span class="m"&gt;8876&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;.00    &lt;span class="m"&gt;0&lt;/span&gt;.00    &lt;span class="m"&gt;0&lt;/span&gt;.00    &lt;span class="m"&gt;0&lt;/span&gt;.00     &lt;span class="m"&gt;0&lt;/span&gt;  server
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Our server is not doing anything right now, so you see a lot of zeroes.&lt;/p&gt;
&lt;p&gt;There are many other interesting commands that you can look to figure out what processes are doing. &lt;code&gt;strace&lt;/code&gt; shows system calls run by a process. &lt;code&gt;ltrace&lt;/code&gt; shows dynamic library calls. &lt;code&gt;tcpdump&lt;/code&gt; can be used to show traffic going in and out of a process.&lt;/p&gt;
&lt;p&gt;So, that's all for today. Happy running of processes.&lt;/p&gt;</content></entry><entry><title>The Linux init system.</title><link href="http://pminkov.github.io/blog/the-linux-init-system.html" rel="alternate"></link><published>2017-02-13T21:09:00-08:00</published><updated>2017-02-13T21:09:00-08:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2017-02-13:/blog/the-linux-init-system.html</id><summary type="html">&lt;p&gt;I decided that I'll dig down into &lt;a href="https://en.wikipedia.org/wiki/Init"&gt;init systems&lt;/a&gt; in Linux and learn more about them. I'm running Ubuntu 16.04, so this might look different on other distributions.&lt;/p&gt;
&lt;p&gt;The init system in Linux is mainly responsible for starting essential service processes, mounting file systems and possibly other tasks. The …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I decided that I'll dig down into &lt;a href="https://en.wikipedia.org/wiki/Init"&gt;init systems&lt;/a&gt; in Linux and learn more about them. I'm running Ubuntu 16.04, so this might look different on other distributions.&lt;/p&gt;
&lt;p&gt;The init system in Linux is mainly responsible for starting essential service processes, mounting file systems and possibly other tasks. The main init systems are systemd, System V init and Upstart. Ubuntu uses systemd.&lt;/p&gt;
&lt;p&gt;The init system starts after the Kernel starts its first user space process - init. Indeed, let's see what's running with PID 1:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ ps &lt;span class="m"&gt;1&lt;/span&gt;
  PID TTY      STAT   TIME COMMAND
    &lt;span class="m"&gt;1&lt;/span&gt; ?        Ss     &lt;span class="m"&gt;0&lt;/span&gt;:04 /sbin/init splash
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It's &lt;code&gt;/sbin/init&lt;/code&gt;. Let's see what this file is:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ ls -l /sbin/init
lrwxrwxrwx &lt;span class="m"&gt;1&lt;/span&gt; root root &lt;span class="m"&gt;20&lt;/span&gt; Sep &lt;span class="m"&gt;28&lt;/span&gt; &lt;span class="m"&gt;18&lt;/span&gt;:40 /sbin/init -&amp;gt; /lib/systemd/systemd
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;From this output, we can figure out that Ubuntu is using systemd. systemd is a fairly new project (initial release was 6 years ago), but it looks like its widely adopted now. systemd would take care of running various services like your ssh server, your web server and various other ones which are more "under the hood" oriented.&lt;/p&gt;
&lt;p&gt;systemd organizes itself with unit files which contain the description of various units and their dependencies. The units are organized in configuration files, which live in various directories. The main directories are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;System unit directory: &lt;code&gt;/usr/lib/systemd/&lt;/code&gt;. Your distribution maintains this, so don't edit it.&lt;/li&gt;
&lt;li&gt;System configuration directory: &lt;code&gt;/etc/systemd&lt;/code&gt;. Make your local changes here.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Well, these are not all directories that contain unit files. Here's the full set of paths that systemd uses:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ systemctl -p UnitPath show
&lt;span class="nv"&gt;UnitPath&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/etc/systemd/system /run/systemd/system /run/systemd/generator /usr/local/lib/systemd/system /lib/systemd/system /usr/lib/systemd/system /run/systemd/generator.late
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I won't go into details about what the unit files contain, but instead look at two services that I was curious about - ssh and apache. Who runs them? When are they run? How can I verify that they are running?&lt;/p&gt;
&lt;p&gt;Let's start with ssh. The main command to interface with systemd is &lt;code&gt;systemctl&lt;/code&gt;. We can use it to list all services that are running, by calling &lt;code&gt;systemctl list-units&lt;/code&gt;. Let's look for ssh in here:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ systemctl list-units &lt;span class="p"&gt;|&lt;/span&gt; grep ssh
ssh.service                                                                              loaded active running   OpenBSD Secure Shell server
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Indeed, we have ssh running. Now, let's look at its status and its config file.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ systemctl status ssh
● ssh.service - OpenBSD Secure Shell server
   Loaded: loaded &lt;span class="o"&gt;(&lt;/span&gt;/lib/systemd/system/ssh.service&lt;span class="p"&gt;;&lt;/span&gt; enabled&lt;span class="p"&gt;;&lt;/span&gt; vendor preset: enabled&lt;span class="o"&gt;)&lt;/span&gt;
   Active: active &lt;span class="o"&gt;(&lt;/span&gt;running&lt;span class="o"&gt;)&lt;/span&gt; since Thu &lt;span class="m"&gt;2017&lt;/span&gt;-02-09 &lt;span class="m"&gt;19&lt;/span&gt;:27:57 PST&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="m"&gt;4&lt;/span&gt; days ago
 Main PID: &lt;span class="m"&gt;786&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;sshd&lt;span class="o"&gt;)&lt;/span&gt;
    Tasks: &lt;span class="m"&gt;1&lt;/span&gt;
   Memory: &lt;span class="m"&gt;6&lt;/span&gt;.4M
      CPU: 199ms
   CGroup: /system.slice/ssh.service
           └─786 /usr/sbin/sshd -D

Feb &lt;span class="m"&gt;12&lt;/span&gt; &lt;span class="m"&gt;18&lt;/span&gt;:23:50 virtbox sshd&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;5791&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;: Accepted password &lt;span class="k"&gt;for&lt;/span&gt; petko from &lt;span class="m"&gt;192&lt;/span&gt;.168.1.86 port &lt;span class="m"&gt;57805&lt;/span&gt; ssh2
Feb &lt;span class="m"&gt;12&lt;/span&gt; &lt;span class="m"&gt;18&lt;/span&gt;:23:50 virtbox sshd&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;5791&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;: pam_unix&lt;span class="o"&gt;(&lt;/span&gt;sshd:session&lt;span class="o"&gt;)&lt;/span&gt;: session opened &lt;span class="k"&gt;for&lt;/span&gt; user petko by &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;uid&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
...
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So here it is. The ssh service is running as process 786. We can see that this process is listening on port 22:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ sudo netstat -tulpn &lt;span class="p"&gt;|&lt;/span&gt; grep &lt;span class="m"&gt;786&lt;/span&gt;
tcp        &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;.0.0.0:22              &lt;span class="m"&gt;0&lt;/span&gt;.0.0.0:*               LISTEN      &lt;span class="m"&gt;786&lt;/span&gt;/sshd        
tcp6       &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt; :::22                   :::*                    LISTEN      &lt;span class="m"&gt;786&lt;/span&gt;/sshd 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Indeed, it is. &lt;code&gt;systemctl&lt;/code&gt; has another useful command that allows us to print the configuration file for a unit. It works like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ systemctl cat ssh
&lt;span class="c1"&gt;# /lib/systemd/system/ssh.service&lt;/span&gt;
&lt;span class="o"&gt;[&lt;/span&gt;Unit&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;Description&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;OpenBSD Secure Shell server
&lt;span class="nv"&gt;After&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;network.target auditd.service
&lt;span class="nv"&gt;ConditionPathExists&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;!/etc/ssh/sshd_not_to_be_run

&lt;span class="o"&gt;[&lt;/span&gt;Service&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;EnvironmentFile&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-/etc/default/ssh
&lt;span class="nv"&gt;ExecStart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/usr/sbin/sshd -D &lt;span class="nv"&gt;$SSHD_OPTS&lt;/span&gt;
&lt;span class="nv"&gt;ExecReload&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/bin/kill -HUP &lt;span class="nv"&gt;$MAINPID&lt;/span&gt;
&lt;span class="nv"&gt;KillMode&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;process
&lt;span class="nv"&gt;Restart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;on-failure
&lt;span class="nv"&gt;RestartPreventExitStatus&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;255&lt;/span&gt;
&lt;span class="nv"&gt;Type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;notify

&lt;span class="o"&gt;[&lt;/span&gt;Install&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;WantedBy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;multi-user.target
&lt;span class="nv"&gt;Alias&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;sshd.service
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So here you can see where is the configuration file located.&lt;/p&gt;
&lt;p&gt;Alright, enough ssh. Let's move on to apache. First, a little history though. Before systemd, apparently the main init system in Linux was System V. System V is different than systemd, because it executes services in sequential order, while systemd can be parallel. System V also can't start services on "as-needed" basis. So I guess that's why systemd was implemented. systemd has its config files in &lt;code&gt;/etc/init.d&lt;/code&gt;. That's where Apache installs its command files as well - it doesn't create systemd unit files. However, systemd knows how to execute the System V init files. I won't go into details of how System V init works, but basically it executes commands on different runlevels and at each runlevel they are executed in sequential order.&lt;/p&gt;
&lt;p&gt;Let's see how apache looks like in systemd:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ systemctl list-units &lt;span class="p"&gt;|&lt;/span&gt; grep apache
apache2.service                                                                          loaded active running   LSB: Apache2 web server
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It's running. Now let's get its status:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ systemctl status apache2
● apache2.service - LSB: Apache2 web server
   Loaded: loaded &lt;span class="o"&gt;(&lt;/span&gt;/etc/init.d/apache2&lt;span class="p"&gt;;&lt;/span&gt; bad&lt;span class="p"&gt;;&lt;/span&gt; vendor preset: enabled&lt;span class="o"&gt;)&lt;/span&gt;
  Drop-In: /lib/systemd/system/apache2.service.d
           └─apache2-systemd.conf
   Active: active &lt;span class="o"&gt;(&lt;/span&gt;running&lt;span class="o"&gt;)&lt;/span&gt; since Mon &lt;span class="m"&gt;2017&lt;/span&gt;-02-13 &lt;span class="m"&gt;12&lt;/span&gt;:49:55 PST&lt;span class="p"&gt;;&lt;/span&gt; 8h ago
     Docs: man:systemd-sysv-generator&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;8&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
    Tasks: &lt;span class="m"&gt;55&lt;/span&gt;
   Memory: &lt;span class="m"&gt;6&lt;/span&gt;.5M
      CPU: &lt;span class="m"&gt;17&lt;/span&gt;.042s
   CGroup: /system.slice/apache2.service
           ├─9097 /usr/sbin/apache2 -k start
           ├─9100 /usr/sbin/apache2 -k start
           └─9101 /usr/sbin/apache2 -k start

Feb &lt;span class="m"&gt;13&lt;/span&gt; &lt;span class="m"&gt;12&lt;/span&gt;:49:54 virtbox systemd&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;: Starting LSB: Apache2 web server...
Feb &lt;span class="m"&gt;13&lt;/span&gt; &lt;span class="m"&gt;12&lt;/span&gt;:49:54 virtbox apache2&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;9071&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;:  * Starting Apache httpd web server apache2
Feb &lt;span class="m"&gt;13&lt;/span&gt; &lt;span class="m"&gt;12&lt;/span&gt;:49:54 virtbox apache2&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;9071&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;: AH00558: apache2: Could not reliably determine the server&lt;span class="s1"&gt;&amp;#39;s fully qualified domain name, using 127.0.1.1. Set the &amp;#39;&lt;/span&gt;ServerName&lt;span class="err"&gt;&amp;#39;&lt;/span&gt; directive globall
Feb &lt;span class="m"&gt;13&lt;/span&gt; &lt;span class="m"&gt;12&lt;/span&gt;:49:55 virtbox apache2&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;9071&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;:  *
Feb &lt;span class="m"&gt;13&lt;/span&gt; &lt;span class="m"&gt;12&lt;/span&gt;:49:55 virtbox systemd&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;: Started LSB: Apache2 web server.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Look at something interesting here. The file responsible for starting apache is listed as &lt;code&gt;/etc/init.d/apache2&lt;/code&gt;. That's the file indeed. It's adapted into systemd by using the &lt;code&gt;systemd-sysv-generator&lt;/code&gt;. So that is systemd running. We can run a cat to see that:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ systemctl cat apache2
&lt;span class="c1"&gt;# /run/systemd/generator.late/apache2.service&lt;/span&gt;
&lt;span class="c1"&gt;# Automatically generated by systemd-sysv-generator&lt;/span&gt;

&lt;span class="o"&gt;[&lt;/span&gt;Unit&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;Documentation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;man:systemd-sysv-generator&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;8&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;SourcePath&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/etc/init.d/apache2
&lt;span class="nv"&gt;Description&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;LSB: Apache2 web server
&lt;span class="nv"&gt;Before&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;multi-user.target
&lt;span class="nv"&gt;Before&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;multi-user.target
&lt;span class="nv"&gt;Before&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;multi-user.target
&lt;span class="nv"&gt;Before&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;graphical.target
&lt;span class="nv"&gt;Before&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;shutdown.target
&lt;span class="nv"&gt;After&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;local-fs.target
&lt;span class="nv"&gt;After&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;remote-fs.target
&lt;span class="nv"&gt;After&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;network-online.target
&lt;span class="nv"&gt;After&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;systemd-journald-dev-log.socket
&lt;span class="nv"&gt;After&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;nss-lookup.target
&lt;span class="nv"&gt;Wants&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;network-online.target
&lt;span class="nv"&gt;Conflicts&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;shutdown.target

&lt;span class="o"&gt;[&lt;/span&gt;Service&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;Type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;forking
&lt;span class="nv"&gt;Restart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;no
&lt;span class="nv"&gt;TimeoutSec&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;5min
&lt;span class="nv"&gt;IgnoreSIGPIPE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;no
&lt;span class="nv"&gt;KillMode&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;process
&lt;span class="nv"&gt;GuessMainPID&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;no
&lt;span class="nv"&gt;RemainAfterExit&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;yes
&lt;span class="nv"&gt;ExecStart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/etc/init.d/apache2 start
&lt;span class="nv"&gt;ExecStop&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/etc/init.d/apache2 stop
&lt;span class="nv"&gt;ExecReload&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/etc/init.d/apache2 reload

&lt;span class="c1"&gt;# /lib/systemd/system/apache2.service.d/apache2-systemd.conf&lt;/span&gt;
&lt;span class="o"&gt;[&lt;/span&gt;Service&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;Type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;forking
&lt;span class="nv"&gt;RemainAfterExit&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;no
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is the file that systemd created in order to integrate the System V init command into its system.&lt;/p&gt;
&lt;p&gt;What are some other interesting systemctl commands? Let's list them:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Start / stop /restart a service.&lt;/span&gt;
$ sudo systemctl restart apache2

&lt;span class="c1"&gt;# List all services:&lt;/span&gt;
$ systemctl list-units --type&lt;span class="o"&gt;=&lt;/span&gt;service

&lt;span class="c1"&gt;# List dependencies:&lt;/span&gt;
$ systemctl list-dependencies sshd.service

&lt;span class="c1"&gt;# See low level properties of a unit:&lt;/span&gt;
$ systemctl show sshd.service
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And one last cool command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ systemd-analyze
Startup finished in &lt;span class="m"&gt;3&lt;/span&gt;.989s &lt;span class="o"&gt;(&lt;/span&gt;kernel&lt;span class="o"&gt;)&lt;/span&gt; + &lt;span class="m"&gt;7&lt;/span&gt;.673s &lt;span class="o"&gt;(&lt;/span&gt;userspace&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;11&lt;/span&gt;.663s
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This command prints the time it took to startup our system.&lt;/p&gt;
&lt;p&gt;So that's all for today. There's definitely more to explore in systemd land - the syntax of unit files, how systemd executes them and so on. I'll leave that for some other time.&lt;/p&gt;</content></entry><entry><title>What happens when you run out of memory in Linux?</title><link href="http://pminkov.github.io/blog/what-happens-when-you-run-out-of-memory-in-linux.html" rel="alternate"></link><published>2017-01-15T12:50:00-08:00</published><updated>2017-01-15T12:50:00-08:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2017-01-15:/blog/what-happens-when-you-run-out-of-memory-in-linux.html</id><summary type="html">&lt;p&gt;I've always been curious to figure out what happens when you run out of memory in Linux and recently I was experimenting with something that helped me figure it out. &lt;/p&gt;
&lt;p&gt;I was trying out &lt;a href="http://dhbox.org/"&gt;dhbox&lt;/a&gt; deployment on an EC2 machine. dhbox allows you to start a virtual environment in which …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've always been curious to figure out what happens when you run out of memory in Linux and recently I was experimenting with something that helped me figure it out. &lt;/p&gt;
&lt;p&gt;I was trying out &lt;a href="http://dhbox.org/"&gt;dhbox&lt;/a&gt; deployment on an EC2 machine. dhbox allows you to start a virtual environment in which you can try out various data science tools. These virtual environments are run on Docker containers. These Docker containers take a lot of memory, so you can't run too many on a single machine. So far so good. But let's see what actually happens.&lt;/p&gt;
&lt;p&gt;Before we start, &lt;a href="http://techblog.netflix.com/2015/11/linux-performance-analysis-in-60s.html"&gt;here&lt;/a&gt; is a great document from the Netflix Eng blog that describes the tools that can be used to debug a slow Linux box. &lt;/p&gt;
&lt;p&gt;I deployed DHBox on an Ubuntu image in EC2 with 1GB of memory and no swap file. Yes, no swap file. Why? It seems like that's done, because having a swap file might incur a lot of EBS IO, which leads to high pricing. But still, this makes for an interesting debugging scenario, so let's continue.&lt;/p&gt;
&lt;p&gt;Here's what our free memory situation is in the beginnging:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ free -m
              total        used        free      shared  buff/cache   available
Mem:            &lt;span class="m"&gt;990&lt;/span&gt;          &lt;span class="m"&gt;78&lt;/span&gt;         &lt;span class="m"&gt;518&lt;/span&gt;           &lt;span class="m"&gt;4&lt;/span&gt;         &lt;span class="m"&gt;392&lt;/span&gt;         &lt;span class="m"&gt;867&lt;/span&gt;
Swap:             &lt;span class="m"&gt;0&lt;/span&gt;           &lt;span class="m"&gt;0&lt;/span&gt;           &lt;span class="m"&gt;0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Notice how we have 392MB in "buff/cache". What is this? &lt;a href="http://www.tldp.org/LDP/sag/html/buffer-cache.html"&gt;Here&lt;/a&gt; is a good explanation of it. The buffer cache is caching (in RAM) data that's on disk. For example, the "ls" command, or the glibc library are things that are often used and are good candidates for caching.&lt;/p&gt;
&lt;p&gt;The first thing I do is to start the Python web app for DHBox. It's a simple Flask app running on &lt;a href="http://gunicorn.org/"&gt;gunicorn&lt;/a&gt;. After I start it, this is what &lt;code&gt;free&lt;/code&gt; is showing:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ free -m
              total        used        free      shared  buff/cache   available
Mem:            &lt;span class="m"&gt;990&lt;/span&gt;         &lt;span class="m"&gt;127&lt;/span&gt;         &lt;span class="m"&gt;453&lt;/span&gt;           &lt;span class="m"&gt;4&lt;/span&gt;         &lt;span class="m"&gt;410&lt;/span&gt;         &lt;span class="m"&gt;818&lt;/span&gt;
Swap:             &lt;span class="m"&gt;0&lt;/span&gt;           &lt;span class="m"&gt;0&lt;/span&gt;           &lt;span class="m"&gt;0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Reasonable. We are using a bit more memory, we have cached a bit more data from disk.&lt;/p&gt;
&lt;p&gt;Now, I'll start running vmstat and run four virtual labs. This seems to be enough to take 1GB of memory and pretty much bring down the machine. One other tool we're going to use is &lt;code&gt;vmstat&lt;/code&gt;. &lt;code&gt;vmstat&lt;/code&gt; is great, it's outputting a lot of useful information. Let's see how it looks like before we start running the Docker containers:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ vmstat &lt;span class="m"&gt;5&lt;/span&gt;
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;463880&lt;/span&gt;  &lt;span class="m"&gt;51328&lt;/span&gt; &lt;span class="m"&gt;369012&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;   &lt;span class="m"&gt;635&lt;/span&gt;    &lt;span class="m"&gt;32&lt;/span&gt;   &lt;span class="m"&gt;94&lt;/span&gt;  &lt;span class="m"&gt;231&lt;/span&gt;  &lt;span class="m"&gt;2&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="m"&gt;95&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt;
 &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;463356&lt;/span&gt;  &lt;span class="m"&gt;51336&lt;/span&gt; &lt;span class="m"&gt;369044&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;     &lt;span class="m"&gt;0&lt;/span&gt;     &lt;span class="m"&gt;2&lt;/span&gt;   &lt;span class="m"&gt;36&lt;/span&gt;   &lt;span class="m"&gt;68&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;100&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;
 &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;462884&lt;/span&gt;  &lt;span class="m"&gt;51372&lt;/span&gt; &lt;span class="m"&gt;369116&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;14&lt;/span&gt;     &lt;span class="m"&gt;2&lt;/span&gt;   &lt;span class="m"&gt;46&lt;/span&gt;   &lt;span class="m"&gt;69&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;99&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;
 &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;462380&lt;/span&gt;  &lt;span class="m"&gt;51372&lt;/span&gt; &lt;span class="m"&gt;369116&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;     &lt;span class="m"&gt;0&lt;/span&gt;     &lt;span class="m"&gt;0&lt;/span&gt;   &lt;span class="m"&gt;43&lt;/span&gt;  &lt;span class="m"&gt;101&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;100&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The telling part here is the &lt;code&gt;id&lt;/code&gt; column. That's the percentage which the CPU spends being idle. As you can see, the CPU is pretty idle. Not much to do.&lt;/p&gt;
&lt;p&gt;We're then starting the first Docker container. Things spike up for a while. Let's observe vmstat:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;462380&lt;/span&gt;  &lt;span class="m"&gt;51372&lt;/span&gt; &lt;span class="m"&gt;369116&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;     &lt;span class="m"&gt;0&lt;/span&gt;     &lt;span class="m"&gt;0&lt;/span&gt;   &lt;span class="m"&gt;43&lt;/span&gt;  &lt;span class="m"&gt;101&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;100&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;
&lt;span class="c1"&gt;# Here&amp;#39;s when we start the Docker container.&lt;/span&gt;
 &lt;span class="m"&gt;2&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;185252&lt;/span&gt;  &lt;span class="m"&gt;56072&lt;/span&gt; &lt;span class="m"&gt;497736&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;9159&lt;/span&gt;  &lt;span class="m"&gt;8016&lt;/span&gt; &lt;span class="m"&gt;2126&lt;/span&gt; &lt;span class="m"&gt;7829&lt;/span&gt; &lt;span class="m"&gt;22&lt;/span&gt; &lt;span class="m"&gt;14&lt;/span&gt; &lt;span class="m"&gt;43&lt;/span&gt; &lt;span class="m"&gt;21&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;
 &lt;span class="m"&gt;1&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;95416&lt;/span&gt;  &lt;span class="m"&gt;56576&lt;/span&gt; &lt;span class="m"&gt;525740&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;1924&lt;/span&gt;  &lt;span class="m"&gt;1036&lt;/span&gt;  &lt;span class="m"&gt;396&lt;/span&gt; &lt;span class="m"&gt;1467&lt;/span&gt; &lt;span class="m"&gt;51&lt;/span&gt; &lt;span class="m"&gt;13&lt;/span&gt; &lt;span class="m"&gt;30&lt;/span&gt;  &lt;span class="m"&gt;7&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;
 &lt;span class="m"&gt;1&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;147764&lt;/span&gt;  &lt;span class="m"&gt;56616&lt;/span&gt; &lt;span class="m"&gt;527408&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;   &lt;span class="m"&gt;336&lt;/span&gt;   &lt;span class="m"&gt;630&lt;/span&gt;  &lt;span class="m"&gt;117&lt;/span&gt;  &lt;span class="m"&gt;307&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="m"&gt;96&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;
 &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;65604&lt;/span&gt;  &lt;span class="m"&gt;56664&lt;/span&gt; &lt;span class="m"&gt;537452&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;     &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;82&lt;/span&gt;   &lt;span class="m"&gt;81&lt;/span&gt;  &lt;span class="m"&gt;494&lt;/span&gt;  &lt;span class="m"&gt;3&lt;/span&gt;  &lt;span class="m"&gt;3&lt;/span&gt; &lt;span class="m"&gt;94&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;
 &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;65556&lt;/span&gt;  &lt;span class="m"&gt;56676&lt;/span&gt; &lt;span class="m"&gt;537500&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;     &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;59&lt;/span&gt;   &lt;span class="m"&gt;59&lt;/span&gt;  &lt;span class="m"&gt;181&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;99&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;
 &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;65524&lt;/span&gt;  &lt;span class="m"&gt;56684&lt;/span&gt; &lt;span class="m"&gt;537504&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;     &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;58&lt;/span&gt;   &lt;span class="m"&gt;56&lt;/span&gt;  &lt;span class="m"&gt;179&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;99&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;
 &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;65400&lt;/span&gt;  &lt;span class="m"&gt;56692&lt;/span&gt; &lt;span class="m"&gt;537552&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;     &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;4928&lt;/span&gt;  &lt;span class="m"&gt;138&lt;/span&gt;  &lt;span class="m"&gt;231&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;98&lt;/span&gt;  &lt;span class="m"&gt;2&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;
 &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;65400&lt;/span&gt;  &lt;span class="m"&gt;56700&lt;/span&gt; &lt;span class="m"&gt;537552&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;     &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;3187&lt;/span&gt;  &lt;span class="m"&gt;107&lt;/span&gt;  &lt;span class="m"&gt;201&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;98&lt;/span&gt;  &lt;span class="m"&gt;2&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Interesting. As you can see the &lt;code&gt;id&lt;/code&gt; column value decreases. Less idleness, we're starting things. But after a while, the Docker container has started and we're back to things being quiet.&lt;/p&gt;
&lt;p&gt;Let's see what &lt;code&gt;free&lt;/code&gt; is saying:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ free -m
              total        used        free      shared  buff/cache   available
Mem:            &lt;span class="m"&gt;990&lt;/span&gt;         &lt;span class="m"&gt;350&lt;/span&gt;          &lt;span class="m"&gt;59&lt;/span&gt;          &lt;span class="m"&gt;10&lt;/span&gt;         &lt;span class="m"&gt;580&lt;/span&gt;         &lt;span class="m"&gt;569&lt;/span&gt;
Swap:             &lt;span class="m"&gt;0&lt;/span&gt;           &lt;span class="m"&gt;0&lt;/span&gt;           &lt;span class="m"&gt;0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So, &lt;code&gt;used&lt;/code&gt; went up from 127MB to 350MB. The buffer cache also went up. Less available memory.&lt;/p&gt;
&lt;p&gt;Let's start the second Docker container. We're looking at vmstat again.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;61304&lt;/span&gt;  &lt;span class="m"&gt;56740&lt;/span&gt; &lt;span class="m"&gt;537872&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;     &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;56&lt;/span&gt;   &lt;span class="m"&gt;83&lt;/span&gt;  &lt;span class="m"&gt;227&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;99&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;
&lt;span class="c1"&gt;# Starting second container here.&lt;/span&gt;
 &lt;span class="m"&gt;1&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;126516&lt;/span&gt;  &lt;span class="m"&gt;59292&lt;/span&gt; &lt;span class="m"&gt;341252&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;7109&lt;/span&gt;  &lt;span class="m"&gt;8100&lt;/span&gt;  &lt;span class="m"&gt;823&lt;/span&gt; &lt;span class="m"&gt;3255&lt;/span&gt; &lt;span class="m"&gt;22&lt;/span&gt; &lt;span class="m"&gt;15&lt;/span&gt; &lt;span class="m"&gt;56&lt;/span&gt;  &lt;span class="m"&gt;6&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;
 &lt;span class="m"&gt;1&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;47572&lt;/span&gt;  &lt;span class="m"&gt;59904&lt;/span&gt; &lt;span class="m"&gt;337152&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;9186&lt;/span&gt;  &lt;span class="m"&gt;7515&lt;/span&gt;  &lt;span class="m"&gt;882&lt;/span&gt; &lt;span class="m"&gt;2316&lt;/span&gt; &lt;span class="m"&gt;51&lt;/span&gt; &lt;span class="m"&gt;13&lt;/span&gt; &lt;span class="m"&gt;17&lt;/span&gt; &lt;span class="m"&gt;19&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;
 &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;153212&lt;/span&gt;  &lt;span class="m"&gt;59940&lt;/span&gt; &lt;span class="m"&gt;307720&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;1094&lt;/span&gt;  &lt;span class="m"&gt;2122&lt;/span&gt;  &lt;span class="m"&gt;214&lt;/span&gt;  &lt;span class="m"&gt;557&lt;/span&gt;  &lt;span class="m"&gt;2&lt;/span&gt;  &lt;span class="m"&gt;3&lt;/span&gt; &lt;span class="m"&gt;92&lt;/span&gt;  &lt;span class="m"&gt;3&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;
 &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;92848&lt;/span&gt;  &lt;span class="m"&gt;59996&lt;/span&gt; &lt;span class="m"&gt;303368&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;   &lt;span class="m"&gt;556&lt;/span&gt;   &lt;span class="m"&gt;149&lt;/span&gt;  &lt;span class="m"&gt;147&lt;/span&gt;  &lt;span class="m"&gt;690&lt;/span&gt;  &lt;span class="m"&gt;2&lt;/span&gt;  &lt;span class="m"&gt;3&lt;/span&gt; &lt;span class="m"&gt;93&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;
 &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;92848&lt;/span&gt;  &lt;span class="m"&gt;60004&lt;/span&gt; &lt;span class="m"&gt;303368&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;     &lt;span class="m"&gt;0&lt;/span&gt;   &lt;span class="m"&gt;108&lt;/span&gt;   &lt;span class="m"&gt;91&lt;/span&gt;  &lt;span class="m"&gt;311&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;99&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;
 &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;92724&lt;/span&gt;  &lt;span class="m"&gt;60012&lt;/span&gt; &lt;span class="m"&gt;303376&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;     &lt;span class="m"&gt;0&lt;/span&gt;   &lt;span class="m"&gt;102&lt;/span&gt;   &lt;span class="m"&gt;94&lt;/span&gt;  &lt;span class="m"&gt;326&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;98&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;
 &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;88296&lt;/span&gt;  &lt;span class="m"&gt;60028&lt;/span&gt; &lt;span class="m"&gt;305048&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;   &lt;span class="m"&gt;320&lt;/span&gt;   &lt;span class="m"&gt;102&lt;/span&gt;  &lt;span class="m"&gt;147&lt;/span&gt;  &lt;span class="m"&gt;424&lt;/span&gt;  &lt;span class="m"&gt;2&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="m"&gt;96&lt;/span&gt;  &lt;span class="m"&gt;2&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;
 &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;77228&lt;/span&gt;  &lt;span class="m"&gt;60364&lt;/span&gt; &lt;span class="m"&gt;314520&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;1876&lt;/span&gt;   &lt;span class="m"&gt;144&lt;/span&gt;  &lt;span class="m"&gt;306&lt;/span&gt;  &lt;span class="m"&gt;868&lt;/span&gt; &lt;span class="m"&gt;28&lt;/span&gt;  &lt;span class="m"&gt;4&lt;/span&gt; &lt;span class="m"&gt;64&lt;/span&gt;  &lt;span class="m"&gt;4&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;
 &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;86800&lt;/span&gt;  &lt;span class="m"&gt;60372&lt;/span&gt; &lt;span class="m"&gt;304968&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;26&lt;/span&gt;   &lt;span class="m"&gt;387&lt;/span&gt;  &lt;span class="m"&gt;111&lt;/span&gt;  &lt;span class="m"&gt;372&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="m"&gt;97&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;
 &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;86032&lt;/span&gt;  &lt;span class="m"&gt;60780&lt;/span&gt; &lt;span class="m"&gt;305120&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;   &lt;span class="m"&gt;110&lt;/span&gt;   &lt;span class="m"&gt;119&lt;/span&gt;  &lt;span class="m"&gt;150&lt;/span&gt;  &lt;span class="m"&gt;399&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;98&lt;/span&gt;  &lt;span class="m"&gt;2&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Similar situation. A spike in io, a spike in non-idle CPU percentage, followed by quiet. Let's look at &lt;code&gt;free&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ free -m
              total        used        free      shared  buff/cache   available
Mem:            &lt;span class="m"&gt;990&lt;/span&gt;         &lt;span class="m"&gt;549&lt;/span&gt;          &lt;span class="m"&gt;84&lt;/span&gt;          &lt;span class="m"&gt;17&lt;/span&gt;         &lt;span class="m"&gt;356&lt;/span&gt;         &lt;span class="m"&gt;371&lt;/span&gt;
Swap:             &lt;span class="m"&gt;0&lt;/span&gt;           &lt;span class="m"&gt;0&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;More used memory. But notice how this time the &lt;code&gt;buff/cache&lt;/code&gt; section went down. Why? Well, because our running processes are using more memory and this memory has to come from somewhere. The kernel is freeing memory from the buffer cache and giving it to processes. Again, reasonable behavior.&lt;/p&gt;
&lt;p&gt;Let's start the third and fourth Docker containers and see how &lt;code&gt;vmstat&lt;/code&gt; looks after that.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;46052&lt;/span&gt;  &lt;span class="m"&gt;11188&lt;/span&gt; &lt;span class="m"&gt;160564&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;     &lt;span class="m"&gt;0&lt;/span&gt;   &lt;span class="m"&gt;151&lt;/span&gt;  &lt;span class="m"&gt;153&lt;/span&gt;  &lt;span class="m"&gt;532&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="m"&gt;97&lt;/span&gt;  &lt;span class="m"&gt;2&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;
 &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;39828&lt;/span&gt;  &lt;span class="m"&gt;11336&lt;/span&gt; &lt;span class="m"&gt;166664&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;1246&lt;/span&gt;   &lt;span class="m"&gt;141&lt;/span&gt;  &lt;span class="m"&gt;235&lt;/span&gt;  &lt;span class="m"&gt;634&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="m"&gt;95&lt;/span&gt;  &lt;span class="m"&gt;4&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;
 &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;39704&lt;/span&gt;  &lt;span class="m"&gt;11344&lt;/span&gt; &lt;span class="m"&gt;166664&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;     &lt;span class="m"&gt;0&lt;/span&gt;   &lt;span class="m"&gt;149&lt;/span&gt;  &lt;span class="m"&gt;158&lt;/span&gt;  &lt;span class="m"&gt;542&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="m"&gt;97&lt;/span&gt;  &lt;span class="m"&gt;2&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;
&lt;span class="c1"&gt;# After we start the fourth container.&lt;/span&gt;
 &lt;span class="m"&gt;6&lt;/span&gt;  &lt;span class="m"&gt;3&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;18840&lt;/span&gt;  &lt;span class="m"&gt;11668&lt;/span&gt; &lt;span class="m"&gt;179484&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;18678&lt;/span&gt;  &lt;span class="m"&gt;7726&lt;/span&gt; &lt;span class="m"&gt;2711&lt;/span&gt; &lt;span class="m"&gt;7721&lt;/span&gt;  &lt;span class="m"&gt;5&lt;/span&gt;  &lt;span class="m"&gt;8&lt;/span&gt; &lt;span class="m"&gt;46&lt;/span&gt; &lt;span class="m"&gt;41&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;
 &lt;span class="m"&gt;1&lt;/span&gt;  &lt;span class="m"&gt;4&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;   &lt;span class="m"&gt;8964&lt;/span&gt;   &lt;span class="m"&gt;2796&lt;/span&gt; &lt;span class="m"&gt;103108&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;38137&lt;/span&gt;  &lt;span class="m"&gt;2508&lt;/span&gt; &lt;span class="m"&gt;4198&lt;/span&gt; &lt;span class="m"&gt;4872&lt;/span&gt; &lt;span class="m"&gt;37&lt;/span&gt; &lt;span class="m"&gt;21&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;41&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt;
 &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;11&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;   &lt;span class="m"&gt;9576&lt;/span&gt;    &lt;span class="m"&gt;588&lt;/span&gt; &lt;span class="m"&gt;101548&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;68988&lt;/span&gt;   &lt;span class="m"&gt;485&lt;/span&gt; &lt;span class="m"&gt;4097&lt;/span&gt; &lt;span class="m"&gt;6006&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="m"&gt;10&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;88&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;
 &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;8&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;   &lt;span class="m"&gt;9352&lt;/span&gt;    &lt;span class="m"&gt;152&lt;/span&gt; &lt;span class="m"&gt;100752&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;67797&lt;/span&gt;   &lt;span class="m"&gt;250&lt;/span&gt; &lt;span class="m"&gt;2463&lt;/span&gt; &lt;span class="m"&gt;4497&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;8&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;90&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt;

....


 &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="m"&gt;18&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;   &lt;span class="m"&gt;9508&lt;/span&gt;    &lt;span class="m"&gt;248&lt;/span&gt; &lt;span class="m"&gt;100560&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;63568&lt;/span&gt;   &lt;span class="m"&gt;138&lt;/span&gt; &lt;span class="m"&gt;1700&lt;/span&gt; &lt;span class="m"&gt;3935&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;8&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;91&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt;
 &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;14&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;   &lt;span class="m"&gt;8656&lt;/span&gt;    &lt;span class="m"&gt;400&lt;/span&gt; &lt;span class="m"&gt;100436&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;63154&lt;/span&gt;    &lt;span class="m"&gt;68&lt;/span&gt; &lt;span class="m"&gt;1580&lt;/span&gt; &lt;span class="m"&gt;3766&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;8&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;91&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt;
 &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;19&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;   &lt;span class="m"&gt;8852&lt;/span&gt;    &lt;span class="m"&gt;288&lt;/span&gt; &lt;span class="m"&gt;100552&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;63711&lt;/span&gt;   &lt;span class="m"&gt;128&lt;/span&gt; &lt;span class="m"&gt;1606&lt;/span&gt; &lt;span class="m"&gt;3705&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;8&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;92&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt;
 &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="m"&gt;47&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;10232&lt;/span&gt;    &lt;span class="m"&gt;372&lt;/span&gt;  &lt;span class="m"&gt;98616&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;63410&lt;/span&gt;    &lt;span class="m"&gt;94&lt;/span&gt; &lt;span class="m"&gt;1720&lt;/span&gt; &lt;span class="m"&gt;4316&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;7&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;91&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt;
 &lt;span class="m"&gt;2&lt;/span&gt; &lt;span class="m"&gt;50&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;   &lt;span class="m"&gt;9648&lt;/span&gt;    &lt;span class="m"&gt;420&lt;/span&gt;  &lt;span class="m"&gt;99604&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;63126&lt;/span&gt;    &lt;span class="m"&gt;77&lt;/span&gt; &lt;span class="m"&gt;1696&lt;/span&gt; &lt;span class="m"&gt;4425&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;8&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;91&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt;
 &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;40&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;10028&lt;/span&gt;    &lt;span class="m"&gt;272&lt;/span&gt;  &lt;span class="m"&gt;99432&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;63692&lt;/span&gt;    &lt;span class="m"&gt;74&lt;/span&gt; &lt;span class="m"&gt;1681&lt;/span&gt; &lt;span class="m"&gt;4506&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;7&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;91&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt;
 &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;75&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;   &lt;span class="m"&gt;9944&lt;/span&gt;    &lt;span class="m"&gt;160&lt;/span&gt;  &lt;span class="m"&gt;98220&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;63342&lt;/span&gt;    &lt;span class="m"&gt;59&lt;/span&gt; &lt;span class="m"&gt;1724&lt;/span&gt; &lt;span class="m"&gt;5150&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;10&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;89&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt;
 &lt;span class="m"&gt;3&lt;/span&gt; &lt;span class="m"&gt;34&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;   &lt;span class="m"&gt;8952&lt;/span&gt;    &lt;span class="m"&gt;296&lt;/span&gt; &lt;span class="m"&gt;100400&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;63575&lt;/span&gt;   &lt;span class="m"&gt;110&lt;/span&gt; &lt;span class="m"&gt;1958&lt;/span&gt; &lt;span class="m"&gt;4663&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;8&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;91&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt;
 &lt;span class="m"&gt;1&lt;/span&gt;  &lt;span class="m"&gt;5&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;   &lt;span class="m"&gt;9004&lt;/span&gt;   &lt;span class="m"&gt;1716&lt;/span&gt; &lt;span class="m"&gt;117640&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;62704&lt;/span&gt;   &lt;span class="m"&gt;123&lt;/span&gt; &lt;span class="m"&gt;2674&lt;/span&gt; &lt;span class="m"&gt;5329&lt;/span&gt;  &lt;span class="m"&gt;3&lt;/span&gt;  &lt;span class="m"&gt;9&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="m"&gt;88&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is where things start to get bad! The box becomes very unresponsive. Typing a simple command like &lt;code&gt;ls&lt;/code&gt; takes seconds to execute. Let's take a peek at &lt;code&gt;free&lt;/code&gt; and we'll continue to our analysis after that:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ free -m
              total        used        free      shared  buff/cache   available
Mem:            &lt;span class="m"&gt;990&lt;/span&gt;         &lt;span class="m"&gt;851&lt;/span&gt;          &lt;span class="m"&gt;20&lt;/span&gt;          &lt;span class="m"&gt;24&lt;/span&gt;         &lt;span class="m"&gt;119&lt;/span&gt;          &lt;span class="m"&gt;54&lt;/span&gt;
Swap:             &lt;span class="m"&gt;0&lt;/span&gt;           &lt;span class="m"&gt;0&lt;/span&gt;           &lt;span class="m"&gt;0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;As you can see, we barely have any free memory and the buffer cache has shrunk even more. But notice what's going on in &lt;code&gt;vmstat&lt;/code&gt;. The &lt;code&gt;bi&lt;/code&gt; (blocks received from a block device) is stuck at a constant high value. This means we're doing a lot of disk reads. Why is that, are our processes doing a lot of disk operations? No. Our many processes are executables that are located on disk. When the kernel executes them, it has to read instructions. If we have enough buffer cache, we can store these instruction in memory and not have to read them again. However, our buffer cache is small now. So when processes run, the kernel needs to pull their instructions from disk. It probably stores them in the buffer cache, but when the next process is running, it tries to store in the cache again and evicts what's stored from the old process. &lt;/p&gt;
&lt;p&gt;Are we done? Not yet. When this whole sad mess happens, the kernel will run something called &lt;a href="https://linux-mm.org/OOM_Killer"&gt;OOM killer&lt;/a&gt;. How do we know this is what's going on? We can use &lt;code&gt;dmesg&lt;/code&gt; and view the system messages:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ dmesg &lt;span class="p"&gt;|&lt;/span&gt; grep &lt;span class="s2"&gt;&amp;quot;Out of memory&amp;quot;&lt;/span&gt;
&lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="m"&gt;3635&lt;/span&gt;.537538&lt;span class="o"&gt;]&lt;/span&gt; Out of memory: Kill process &lt;span class="m"&gt;21580&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;jupyter-noteboo&lt;span class="o"&gt;)&lt;/span&gt; score &lt;span class="m"&gt;37&lt;/span&gt; or sacrifice child
&lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="m"&gt;3636&lt;/span&gt;.822607&lt;span class="o"&gt;]&lt;/span&gt; Out of memory: Kill process &lt;span class="m"&gt;22714&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;jupyter-noteboo&lt;span class="o"&gt;)&lt;/span&gt; score &lt;span class="m"&gt;37&lt;/span&gt; or sacrifice child
&lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="m"&gt;3643&lt;/span&gt;.006328&lt;span class="o"&gt;]&lt;/span&gt; Out of memory: Kill process &lt;span class="m"&gt;24976&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;jupyter-noteboo&lt;span class="o"&gt;)&lt;/span&gt; score &lt;span class="m"&gt;37&lt;/span&gt; or sacrifice child
&lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="m"&gt;3654&lt;/span&gt;.916468&lt;span class="o"&gt;]&lt;/span&gt; Out of memory: Kill process &lt;span class="m"&gt;26118&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;jupyter-noteboo&lt;span class="o"&gt;)&lt;/span&gt; score &lt;span class="m"&gt;37&lt;/span&gt; or sacrifice child
&lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="m"&gt;3658&lt;/span&gt;.712286&lt;span class="o"&gt;]&lt;/span&gt; Out of memory: Kill process &lt;span class="m"&gt;28364&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;jupyter-noteboo&lt;span class="o"&gt;)&lt;/span&gt; score &lt;span class="m"&gt;35&lt;/span&gt; or sacrifice child
&lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="m"&gt;3666&lt;/span&gt;.654763&lt;span class="o"&gt;]&lt;/span&gt; Out of memory: Kill process &lt;span class="m"&gt;30603&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;jupyter-noteboo&lt;span class="o"&gt;)&lt;/span&gt; score &lt;span class="m"&gt;36&lt;/span&gt; or sacrifice child
&lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="m"&gt;3685&lt;/span&gt;.390829&lt;span class="o"&gt;]&lt;/span&gt; Out of memory: Kill process &lt;span class="m"&gt;30620&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;jupyter-noteboo&lt;span class="o"&gt;)&lt;/span&gt; score &lt;span class="m"&gt;36&lt;/span&gt; or sacrifice child
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The strange thing here is that it keeps killing these &lt;a href="http://jupyter.org/"&gt;Jupyter&lt;/a&gt; processes for a long time. My guess here is that something restarts them after they're killed.&lt;/p&gt;
&lt;p&gt;The best thing to do here is to simply kill all the running Docker containers so that the box is usable again:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;docker &lt;span class="nb"&gt;kill&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;docker ps -q&lt;span class="k"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Things would look different if there was a swap partition on the disk. I might try such a setup as well. If you think about it, the swap would allow some of the memory used by processes to be transferred to disk. That's a great win, because some parts of memory might be very rarely if at all accessed. However, without a swap, there's no such option.&lt;/p&gt;</content></entry><entry><title>How to install collectd on Ubuntu.</title><link href="http://pminkov.github.io/blog/how-to-install-collectd-on-ubuntu.html" rel="alternate"></link><published>2017-01-05T14:46:00-08:00</published><updated>2017-01-05T14:46:00-08:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2017-01-05:/blog/how-to-install-collectd-on-ubuntu.html</id><summary type="html">&lt;p&gt;Some time ago I found out about &lt;a href="https://collectd.org/"&gt;collectd&lt;/a&gt; and I was curious to see what it does. collectd collects statistics about the machine its running on - cpu, disk, memory, processes, battery, etc. &lt;/p&gt;
&lt;p&gt;Here's how to install it on Ubuntu and visualize the data it has collected.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3&gt;Step 1: Install the …&lt;/h3&gt;</summary><content type="html">&lt;p&gt;Some time ago I found out about &lt;a href="https://collectd.org/"&gt;collectd&lt;/a&gt; and I was curious to see what it does. collectd collects statistics about the machine its running on - cpu, disk, memory, processes, battery, etc. &lt;/p&gt;
&lt;p&gt;Here's how to install it on Ubuntu and visualize the data it has collected.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3&gt;Step 1: Install the collectd package.&lt;/h3&gt;
&lt;p&gt;Easy, just install the package:&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sudo apt-get install collectd&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3&gt;Step 2: Make sure collectd and apache are running.&lt;/h3&gt;
&lt;p&gt;If you have installed apache, you should have both collectd and apache running&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ sudo service --status-all &lt;span class="p"&gt;|&lt;/span&gt; egrep &lt;span class="s2"&gt;&amp;quot;collectd|apache2&amp;quot;&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt; + &lt;span class="o"&gt;]&lt;/span&gt;  apache2
 &lt;span class="o"&gt;[&lt;/span&gt; + &lt;span class="o"&gt;]&lt;/span&gt;  collectd
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If collectd is not running, run &lt;code&gt;sudo service collectd start&lt;/code&gt;. For me at least, it was running after installation.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3&gt;Step 3: Install collectd's web app for generating graphs.&lt;/h3&gt;
&lt;p&gt;Ok, now we have collectd running. collectd is mostly about collecting data and it allows other frontends to display it. However, it comes with a simple set of cgi scripts that can be used to see some graphs.&lt;/p&gt;
&lt;p&gt;In the &lt;code&gt;/usr/share/doc/collectd/examples/&lt;/code&gt; directory, you'll find a directory named &lt;code&gt;collection3&lt;/code&gt;. Copy the entire directory to &lt;code&gt;/var/www/html&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$ sudo cp -r ./collection3 /var/www/html&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3&gt;Step 4: Enable apache to run CGI scripts.&lt;/h3&gt;
&lt;p&gt;Great, you can now access the cgi scripts by going to this url: &lt;code&gt;http://localhost/collection3/bin/index.cgi&lt;/code&gt;. However, you'll be served a text file, since apache doesn't know to run these cgi scripts. There's is a &lt;a href="http://httpd.apache.org/docs/2.2/howto/cgi.html"&gt;simple manual&lt;/a&gt; explaining cgi scripts in Apache.&lt;/p&gt;
&lt;p&gt;You'll have to do two things.&lt;/p&gt;
&lt;p&gt;First, you need to install the cgi module. So, go to &lt;code&gt;/etc/apache2/mods-enabled&lt;/code&gt; and run this: &lt;code&gt;$ sudo ln -s ../mods-available/cgi.load&lt;/code&gt;. You have now enabled the &lt;code&gt;cgi&lt;/code&gt; module.&lt;/p&gt;
&lt;p&gt;Next you'll have to change &lt;code&gt;apache2.conf&lt;/code&gt;, located in &lt;code&gt;/etc/apache2&lt;/code&gt; (Ubuntu doesn't use &lt;code&gt;httpd.conf&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;Add these lines to it:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&amp;lt;Directory /var/www/&amp;gt;
        Options +ExecCGI
        AddHandler cgi-script .cgi
&amp;lt;/Directory&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And - you're done! If you go to &lt;code&gt;http://localhost/cgi-bin/collection3/bin/index.cgi&lt;/code&gt;, you should see some graphs.&lt;/p&gt;</content></entry><entry><title>How to fix order-violation bugs with condition variables.</title><link href="http://pminkov.github.io/blog/how-to-fix-order-violation-bugs-with-condition-variables.html" rel="alternate"></link><published>2016-11-29T11:22:00-08:00</published><updated>2016-11-29T11:22:00-08:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2016-11-29:/blog/how-to-fix-order-violation-bugs-with-condition-variables.html</id><summary type="html">&lt;p&gt;Let's look at the following code and try to find the bug in it.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Thread 1:
void init() {
  ...
  mThread = PR_CreateThread(mMain, ...)
  ...
}

Thread 2:
void mMain(...) {
  ...
  mState = mThread-&amp;gt;State;
  ...
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The problem is that if thread two executes before thread one, it can access &lt;code&gt;mThread&lt;/code&gt; which is not initialized. We need to …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Let's look at the following code and try to find the bug in it.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Thread 1:
void init() {
  ...
  mThread = PR_CreateThread(mMain, ...)
  ...
}

Thread 2:
void mMain(...) {
  ...
  mState = mThread-&amp;gt;State;
  ...
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The problem is that if thread two executes before thread one, it can access &lt;code&gt;mThread&lt;/code&gt; which is not initialized. We need to make thread two wait for thread one. This is done with condition variables. But let's see how we're going to implement it.&lt;/p&gt;
&lt;h3&gt;Solution 1 (Incorrect) - Simple wait and signal&lt;/h3&gt;
&lt;p&gt;Let's say that we're not giving this a lot of thought and just put a wait and signal in the code. We have this code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pthread_mutex_t mtLock = PTHREAD_MUTEX_INITIALIZER;
pthread_cond_t mtCond = PTHREAD_COND_INITIALIZER;

Thread 1:
void init() {
  ...
  mThread = PR_CreateThread(mMain, ...)
  pthread_mutex_lock(&amp;amp;mtLock);
  pthread_cond_signal(&amp;amp;mtCond);
  pthread_mutex_unlock(&amp;amp;mtLock);
  ...
}

Thread 2:
void mMain(...) {
  ...
  pthread_mutex_lock(&amp;amp;mtLock);
  pthread_cond_wait(&amp;amp;mtCond, &amp;amp;mtLock);
  pthread_mutex_unlock(&amp;amp;mtLock);
  mState = mThread-&amp;gt;State;
  ...
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The problem here is that thread one can execute before thread two. In this case, thread one will signal on the condition variable, but nobody is waiting on it. Once thread two executes, it will start waiting and nobody is going to signal on the condition variable. Thus, thread two will stay in block state.&lt;/p&gt;
&lt;h3&gt;Solution 2 (Correct) - Using a synchronization variable.&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;  pthread_mutex_t mtLock = PTHREAD_MUTEX_INITIALIZER;
  pthread_cond_t mtCond = PTHREAD_COND_INITIALIZER;
  int mtInit = 0;

  Thread 1:
  void init() {
    ...
1   mThread = PR_CreateThread(mMain, ...)
2   pthread_mutex_lock(&amp;amp;mtLock);
3   mtInit = 1;
4   pthread_cond_signal(&amp;amp;mtCond);
5   pthread_mutex_unlock(&amp;amp;mtLock);
    ...
  }

  Thread 2:
  void mMain(...) {
    ...
6   pthread_mutex_lock(&amp;amp;mtLock);
7   if (mtInit == 0)
8     pthread_cond_wait(&amp;amp;mtCond, &amp;amp;mtLock);
9   pthread_mutex_unlock(&amp;amp;mtLock);
10  mState = mThread-&amp;gt;State;
    ...
  }
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here we have used the &lt;code&gt;mtInit&lt;/code&gt; variable to prevent the bug in Solution 1 from hapenning. Let's try to reproduce the conditions that led to a bug in out first solution. Let's say thread one executes before thread two. When thread two runs, it will see that &lt;code&gt;mtInit&lt;/code&gt; is 1 and it won't wait. That basically solves our problem. Let's trace things more carfully with two possible scenarios. Of course, there are other possibilities too, but with these two I have enough confidence in the correctness of the solution.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Scenario 1 - Thread 1 before Thread 2.

Line   T1    T2   COMMENT
       1
       2          Locked mutex
             6    Blocked, because mutex is locked.
       3
       4          Signals on the condition variable.
       5          Unblocks mutex.
             6    Continues, mutex was unblocked.
             7    False, jump to line 9.
             9    Unlock mutex, done
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So in this scenario, thread one obtains the lock first and the solution is correct.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Scenario 2 - Thread 2 before Thread 1.

Line   T1    T2   COMMENT
             6    Locked mutex.
             7
             8    Unlocks mutex, waiting on condition variable.
       1      
       2          Locks mutex.
       3      
       4          Signals, but mutex is still locked, so thread two doesn&amp;#39;t do anything.
       5          Unlocks mutex. Now thread two can continue.
             8    Returns from wait(), locks mutex.
             9    Unlocks mutex.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This scenario works too.&lt;/p&gt;
&lt;p&gt;There's one change that we should do though. Instead of an if statement in line 7, we should use a while. Why? Because when thread two wakes up in line 7 and obtains a lock on the mutex, it should re-verify that the condition that made it wait is not true anymore. While not a problem in this code segment, this can be a problem in other cases.&lt;/p&gt;</content></entry><entry><title>Pitfalls of POSIX condition variables.</title><link href="http://pminkov.github.io/blog/pitfalls-of-posix-condition-variables.html" rel="alternate"></link><published>2016-11-24T20:23:00-08:00</published><updated>2016-11-24T20:23:00-08:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2016-11-24:/blog/pitfalls-of-posix-condition-variables.html</id><summary type="html">&lt;p&gt;I'm reading this awesome &lt;a href="http://pages.cs.wisc.edu/~remzi/OSTEP/"&gt;book&lt;/a&gt; about operating systems. I find that with OSs, you can't understand things by just reading the text.
You have to write code, write out things on paper and read certain passages multiple times. That's the difference between learning and reading. Hopefully I'm learning something.&lt;/p&gt;
&lt;p&gt;So …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I'm reading this awesome &lt;a href="http://pages.cs.wisc.edu/~remzi/OSTEP/"&gt;book&lt;/a&gt; about operating systems. I find that with OSs, you can't understand things by just reading the text.
You have to write code, write out things on paper and read certain passages multiple times. That's the difference between learning and reading. Hopefully I'm learning something.&lt;/p&gt;
&lt;p&gt;So this book has a nice chapter on &lt;a href="https://computing.llnl.gov/tutorials/pthreads/#ConditionVariables"&gt;condition variables&lt;/a&gt;. The way condition variables operate is fairly clear, but I found two pitfalls that I had to dig deeper into in order to see what's going on.&lt;/p&gt;
&lt;p&gt;First, a crash course in how condition variables operate. I'm using shortened function names for readability. A condition variable is a variable that you can use to make a thread wait for some condition to be true. So roughly, it looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;// Thread one.
lock(mutex);
wait(condition, mutex);
unlock(mutex);

// Thread two.
lock(mutex);
signal(condition);
unlock(mutex);
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Let's say that the first thing that happens here is that thread one obtains the mutex. Thread two runs and blocks on its call to &lt;code&gt;lock&lt;/code&gt;. Now thread one proceeds and calls &lt;code&gt;wait(condition, mutex)&lt;/code&gt;. What happens here is that mutex is unlocked and thread one goes to sleep. It's waiting for the condition to become true. Thread two is able to obtain the lock and it then signals to thread one that the condition is satisfied. Thread one obtains a lock on the mutex again and finishes its job.&lt;/p&gt;
&lt;p&gt;Now that this is out of the way, let's look at the pitfalls.&lt;/p&gt;
&lt;h4&gt;Pitfall 1&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;When a thread signals a condition, if the thread holds a lock on the mutex, a waiting thread returns from &lt;code&gt;wait()&lt;/code&gt; only after the first thread unlocks the mutex.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Looking at our example, intuitively it looks like when we call &lt;code&gt;signal()&lt;/code&gt;, the first thread should return from wait. After all, the signal has been sent. But that's not the case. If thread two has more work to do after the signal, all of this will be done and just once &lt;code&gt;unlock()&lt;/code&gt; is called, that's when thread one will return from the wait.
Thread one will then lock the mutex and once it's done with its work, it will unlock it. This is way more logical than the mess that would happen if &lt;code&gt;signal()&lt;/code&gt; makes &lt;code&gt;wait()&lt;/code&gt; return immediately.&lt;/p&gt;
&lt;h4&gt;Pitfall 2&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;Calling &lt;code&gt;signal()&lt;/code&gt; doesn't necessarily unblock all threads waiting on this signal.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Well this one caused me to scratch my head when I was going through one of the exercises in the book. I assumed a call to &lt;code&gt;signal()&lt;/code&gt; simply unblocks all the waiting threads. No, it possibly unblocks only one of them. Apparently there's a &lt;code&gt;pthread_cond_broadcast&lt;/code&gt; &lt;a href="https://linux.die.net/man/3/pthread_cond_signal"&gt;function&lt;/a&gt; that can unblock all waiting threads.&lt;/p&gt;
&lt;p&gt;So that's it. Happy coding.&lt;/p&gt;</content><category term="Concurrency"></category></entry><entry><title>Implementing a fast multi-threaded counter.</title><link href="http://pminkov.github.io/blog/implementing-a-fast-multi-threaded-counter.html" rel="alternate"></link><published>2016-11-23T11:02:00-08:00</published><updated>2016-11-23T11:02:00-08:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2016-11-23:/blog/implementing-a-fast-multi-threaded-counter.html</id><summary type="html">&lt;p&gt;Today I'll write a bit about implementing a simple thread safe counter and improving its speed.&lt;/p&gt;
&lt;p&gt;Implementing a basic mutli-threaded counter is a fairly easy task. Using pthreads, you just need to wrap the counter increment in a lock.&lt;/p&gt;
&lt;p&gt;The code (&lt;a href="https://github.com/pminkov/wip/tree/master/mt-counters"&gt;github link&lt;/a&gt;) looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;quot;mythreads.h&amp;quot;&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;

&lt;span class="k"&gt;struct …&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;Today I'll write a bit about implementing a simple thread safe counter and improving its speed.&lt;/p&gt;
&lt;p&gt;Implementing a basic mutli-threaded counter is a fairly easy task. Using pthreads, you just need to wrap the counter increment in a lock.&lt;/p&gt;
&lt;p&gt;The code (&lt;a href="https://github.com/pminkov/wip/tree/master/mt-counters"&gt;github link&lt;/a&gt;) looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;quot;mythreads.h&amp;quot;&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;

&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;counter_t&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="n"&gt;pthread_mutex_t&lt;/span&gt; &lt;span class="n"&gt;lock&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;};&lt;/span&gt;

&lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;counter_t&lt;/span&gt; &lt;span class="n"&gt;counter&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;init&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;counter_t&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="n"&gt;pthread_mutex_init&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;lock&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;increment_by&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;counter_t&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;by&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="n"&gt;Pthread_mutex_lock&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;lock&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;by&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="n"&gt;Pthread_mutex_unlock&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;lock&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;increment&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;counter_t&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="n"&gt;increment_by&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;counter_t&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="n"&gt;Pthread_mutex_lock&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;lock&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;rc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="n"&gt;Pthread_mutex_unlock&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;lock&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;rc&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Nothing complicated. Let's say that we want to increment this counter 1,000,000 times. And let's do this with an increasing amount of threads, each thread incrementing the counter 1,000,000 times. I get the following timings for this exercise.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;1 thread:  0.064s real time.
2 threads: 9.930s
4 threads: 23.971s
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This counter is really slow. Also, it doesn't scale well, since at the moment more than one thread starts to use it, it becomes so much slower. Why is this? Well, it's a bit difficult to tell without knowing how mutexes are implemented, but since we're using a single mutex that has to switch between two threads, it looks like there's a lot of overhead in this. The core operation - the increment, is also not parallel, since it can be done by only one thread at a time. But judging from the single threaded timing, this operation by itself is not the bottleneck here. So the synchronization must be.&lt;/p&gt;
&lt;p&gt;How can we improve this? We can use what's called a sloppy counter. The sloppy counter is also fairly easy to understand. Each thread has its own counter and when that counter becomes bigger than a certain value, its current value is transferred into a global counter. Here's how the code for that looks like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;string.h&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;stdlib.h&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;

&lt;span class="cp"&gt;#define min(a, b) ((a) &amp;lt; (b) ? (a) : (b))&lt;/span&gt;

&lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="kt"&gt;uint64_t&lt;/span&gt; &lt;span class="n"&gt;SLOTS_COUNT&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;101&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;sloppy_counter_t&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

  &lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;counter_t&lt;/span&gt; &lt;span class="n"&gt;gcounter&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

  &lt;span class="c1"&gt;// A hash table for per-thread counters. Since we&amp;#39;re unlikely to run too many threads at the same time,&lt;/span&gt;
  &lt;span class="c1"&gt;// chances for collision are low. If that&amp;#39;s not the case, we can always use a per-counter mutex.&lt;/span&gt;
  &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;lcounters&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;SLOTS_COUNT&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;span class="p"&gt;};&lt;/span&gt;

&lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;sloppy_counter_t&lt;/span&gt; &lt;span class="n"&gt;sloppy_counter&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;sloppy_init&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;sloppy_counter_t&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;SLOTS_COUNT&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;lcounters&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="n"&gt;init&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;gcounter&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;slot_id&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pthread_t&lt;/span&gt; &lt;span class="n"&gt;thread_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="kt"&gt;uint64_t&lt;/span&gt; &lt;span class="n"&gt;ptid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="n"&gt;memcpy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;ptid&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;thread_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;thread_id&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ptid&lt;/span&gt;&lt;span class="p"&gt;)));&lt;/span&gt;

  &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;sid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ptid&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;SLOTS_COUNT&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;sid&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;sloppy_increment&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;sloppy_counter_t&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pthread_t&lt;/span&gt; &lt;span class="n"&gt;thread_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;sid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;slot_id&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;thread_id&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

  &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;lcounters&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;sid&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;lcounters&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;sid&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;increment_by&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;gcounter&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;lcounters&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;sid&lt;/span&gt;&lt;span class="p"&gt;]);&lt;/span&gt;
    &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;lcounters&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;sid&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;sloppy_flush&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;sloppy_counter_t&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pthread_t&lt;/span&gt; &lt;span class="n"&gt;thread_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;sid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;slot_id&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;thread_id&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;lcounters&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;sid&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;increment_by&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;gcounter&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;lcounters&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;sid&lt;/span&gt;&lt;span class="p"&gt;]);&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;


&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;sloppy_get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;sloppy_counter_t&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;counter&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;counter&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;gcounter&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now let's time this counter.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;1 thread:  0.026s
2 threads: 0.050s
4 threads: 0.164s
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Much better! This counter, just like the first one, is thread safe. It's not as accurate, but the inaccuracy is small (at most 128 * number of threads) and we can use the flush function if we want accurate counts.&lt;/p&gt;</content><category term="Concurrency"></category><category term="Linux"></category></entry><entry><title>Monitoring Disk I/O on Linux.</title><link href="http://pminkov.github.io/blog/monitoring-disk-io-on-linux.html" rel="alternate"></link><published>2016-11-16T14:59:00-08:00</published><updated>2016-11-16T14:59:00-08:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2016-11-16:/blog/monitoring-disk-io-on-linux.html</id><summary type="html">&lt;p&gt;Today I wrote a little piece of code that generates a random array of numbers, stores it into disk and sorts it on disk, using bubble sort. This uses O(1) memory, but it's obviously very slow. I did this for fun mostly. The code is &lt;a href="https://github.com/pminkov/wip/blob/master/os/disksort.c"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I wanted to …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Today I wrote a little piece of code that generates a random array of numbers, stores it into disk and sorts it on disk, using bubble sort. This uses O(1) memory, but it's obviously very slow. I did this for fun mostly. The code is &lt;a href="https://github.com/pminkov/wip/blob/master/os/disksort.c"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I wanted to know, if I'm running this code, what Linux tools are going to show an increase in disk I/O.&lt;/p&gt;
&lt;p&gt;So, I run this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ ./disksort &lt;span class="m"&gt;150000&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This starts the sorting. It takes a long time to sort 150k numbers on disk, at least with that algorithm.&lt;/p&gt;
&lt;p&gt;So the first command that we can run is &lt;code&gt;iostat&lt;/code&gt;. Let's see what it is outputting before I start &lt;code&gt;disksort&lt;/code&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ sudo iostat &lt;span class="m"&gt;5&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;
Linux &lt;span class="m"&gt;4&lt;/span&gt;.4.0-31-generic &lt;span class="o"&gt;(&lt;/span&gt;petko-VirtualBox&lt;span class="o"&gt;)&lt;/span&gt;       &lt;span class="m"&gt;11&lt;/span&gt;/16/2016      _x86_64_        &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; CPU&lt;span class="o"&gt;)&lt;/span&gt;

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
          &lt;span class="m"&gt;14&lt;/span&gt;.68    &lt;span class="m"&gt;0&lt;/span&gt;.19   &lt;span class="m"&gt;38&lt;/span&gt;.34    &lt;span class="m"&gt;0&lt;/span&gt;.05    &lt;span class="m"&gt;0&lt;/span&gt;.00   &lt;span class="m"&gt;46&lt;/span&gt;.73

Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn
sda               &lt;span class="m"&gt;5&lt;/span&gt;.60        &lt;span class="m"&gt;83&lt;/span&gt;.17        &lt;span class="m"&gt;63&lt;/span&gt;.96     &lt;span class="m"&gt;539970&lt;/span&gt;     &lt;span class="m"&gt;415252&lt;/span&gt;

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           &lt;span class="m"&gt;3&lt;/span&gt;.03    &lt;span class="m"&gt;0&lt;/span&gt;.00    &lt;span class="m"&gt;0&lt;/span&gt;.00    &lt;span class="m"&gt;0&lt;/span&gt;.00    &lt;span class="m"&gt;0&lt;/span&gt;.00   &lt;span class="m"&gt;96&lt;/span&gt;.97

Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn
sda               &lt;span class="m"&gt;0&lt;/span&gt;.00         &lt;span class="m"&gt;0&lt;/span&gt;.00         &lt;span class="m"&gt;0&lt;/span&gt;.00          &lt;span class="m"&gt;0&lt;/span&gt;          &lt;span class="m"&gt;0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The command line invocation is a bit strange. The &lt;code&gt;5 2&lt;/code&gt; part says "aggregate IO data for five seconds and show me two reports". The idea is that you can get continuous report output every five seconds. But I need only one report. The first one is a default one, which shows aggregated data for I'm not sure what period. But the second one is interesting. Notice &lt;code&gt;kB_read/s&lt;/code&gt; and &lt;code&gt;kB_wrtn/s&lt;/code&gt;. They're zeros. So it's all quiet. I now run &lt;code&gt;disksort&lt;/code&gt; and run the same command.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ iostat &lt;span class="m"&gt;5&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;
Linux &lt;span class="m"&gt;4&lt;/span&gt;.4.0-31-generic &lt;span class="o"&gt;(&lt;/span&gt;petko-VirtualBox&lt;span class="o"&gt;)&lt;/span&gt;       &lt;span class="m"&gt;11&lt;/span&gt;/16/2016      _x86_64_        &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; CPU&lt;span class="o"&gt;)&lt;/span&gt;

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
          &lt;span class="m"&gt;15&lt;/span&gt;.32    &lt;span class="m"&gt;0&lt;/span&gt;.17   &lt;span class="m"&gt;40&lt;/span&gt;.33    &lt;span class="m"&gt;0&lt;/span&gt;.05    &lt;span class="m"&gt;0&lt;/span&gt;.00   &lt;span class="m"&gt;44&lt;/span&gt;.14

Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn
sda               &lt;span class="m"&gt;5&lt;/span&gt;.04        &lt;span class="m"&gt;73&lt;/span&gt;.65        &lt;span class="m"&gt;59&lt;/span&gt;.42     &lt;span class="m"&gt;540254&lt;/span&gt;     &lt;span class="m"&gt;435868&lt;/span&gt;

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
          &lt;span class="m"&gt;26&lt;/span&gt;.81    &lt;span class="m"&gt;0&lt;/span&gt;.00   &lt;span class="m"&gt;73&lt;/span&gt;.19    &lt;span class="m"&gt;0&lt;/span&gt;.00    &lt;span class="m"&gt;0&lt;/span&gt;.00    &lt;span class="m"&gt;0&lt;/span&gt;.00

Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn
sda               &lt;span class="m"&gt;0&lt;/span&gt;.80         &lt;span class="m"&gt;0&lt;/span&gt;.00       &lt;span class="m"&gt;157&lt;/span&gt;.64          &lt;span class="m"&gt;0&lt;/span&gt;        &lt;span class="m"&gt;588&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Notice how &lt;code&gt;kB_wrtn/s&lt;/code&gt; spiked up. &lt;code&gt;kB_read&lt;/code&gt; is zero and I assume that's because of the &lt;a href="http://www.tldp.org/LDP/sag/html/buffer-cache.html"&gt;buffer cache&lt;/a&gt;. After all, I'm reading the same file again and again.&lt;/p&gt;
&lt;p&gt;Another command that we can use is &lt;code&gt;iotop&lt;/code&gt;. &lt;code&gt;iotop&lt;/code&gt; is similar to &lt;code&gt;top&lt;/code&gt;, but shows I/O stats. We'll run it using &lt;code&gt;iotop -oa&lt;/code&gt;. The &lt;code&gt;-o&lt;/code&gt; parameter makes it show only processes that do I/O. The &lt;code&gt;-a&lt;/code&gt; flag aggregates the data during the time this command is running. So after running it for a few seconds I'm seeing this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Total DISK READ :       0.00 B/s | Total DISK WRITE :      83.77 K/s
Actual DISK READ:       0.00 B/s | Actual DISK WRITE:       0.00 B/s
  TID  PRIO  USER     DISK READ  DISK WRITE  SWAPIN     IO&amp;gt;    COMMAND                                                                                                                                                       
  545 be/3 root          0.00 B      4.00 K  0.00 %  0.08 % [jbd2/sda1-8]
 7717 be/4 root          0.00 B      0.00 B  0.00 %  0.01 % [kworker/u2:3]
 7865 be/4 root          0.00 B      0.00 B  0.00 %  0.01 % [kworker/u2:1]
 7714 be/4 petko         0.00 B   1144.00 K  0.00 %  0.00 % ./disksort 150000
 7097 be/4 root          0.00 B      0.00 B  0.00 %  0.00 % [kworker/u2:2]
 7758 be/4 root          0.00 B      0.00 B  0.00 %  0.00 % [kworker/u2:0]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Notice how &lt;code&gt;disksort&lt;/code&gt; with pid of &lt;code&gt;7714&lt;/code&gt; is well ahead of everything else shown.&lt;/p&gt;
&lt;p&gt;So that's it, happy debugging.&lt;/p&gt;</content></entry></feed>