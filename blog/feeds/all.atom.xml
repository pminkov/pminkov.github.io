<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Petko's Coding Blog</title><link href="http://pminkov.github.io/blog/" rel="alternate"></link><link href="http://pminkov.github.io/blog/feeds/all.atom.xml" rel="self"></link><id>http://pminkov.github.io/blog/</id><updated>2017-08-09T17:30:00-07:00</updated><entry><title>Simple guide to SSH</title><link href="http://pminkov.github.io/blog/simple-guide-to-ssh.html" rel="alternate"></link><published>2017-08-09T17:30:00-07:00</published><updated>2017-08-09T17:30:00-07:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2017-08-09:/blog/simple-guide-to-ssh.html</id><summary type="html">&lt;div class="toc"&gt;&lt;span class="toctitle"&gt;Table of contents:&lt;/span&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#what-is-ssh-for"&gt;What is SSH for?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#the-key-pair"&gt;The key pair&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#how-does-ssh-work"&gt;How does SSH work?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#the-ssh-command"&gt;The ssh command&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#the-ssh-agent-daemon"&gt;The ssh-agent daemon&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tips-and-tricks"&gt;Tips and tricks&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#manually-verifying-a-private-key"&gt;Manually verifying a private key&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id="what-is-ssh-for"&gt;What is SSH for?&lt;/h2&gt;
&lt;p&gt;SSH is used to communicate securely between a client and a server. Some examples that most people are …&lt;/p&gt;</summary><content type="html">&lt;div class="toc"&gt;&lt;span class="toctitle"&gt;Table of contents:&lt;/span&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#what-is-ssh-for"&gt;What is SSH for?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#the-key-pair"&gt;The key pair&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#how-does-ssh-work"&gt;How does SSH work?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#the-ssh-command"&gt;The ssh command&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#the-ssh-agent-daemon"&gt;The ssh-agent daemon&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tips-and-tricks"&gt;Tips and tricks&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#manually-verifying-a-private-key"&gt;Manually verifying a private key&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2 id="what-is-ssh-for"&gt;What is SSH for?&lt;/h2&gt;
&lt;p&gt;SSH is used to communicate securely between a client and a server. Some examples that most people are familiar with are SSH-ing to a remote server or using GitHub.&lt;/p&gt;
&lt;h2 id="the-key-pair"&gt;The key pair&lt;/h2&gt;
&lt;p&gt;To establish an SSH connection you need a &lt;strong&gt;private key&lt;/strong&gt; and a &lt;strong&gt;public key&lt;/strong&gt;. You keep the private key in a safe place (usually in &lt;code&gt;~/.ssh/&lt;/code&gt;) and upload the public key to any server that you want to securely connect to. Encryption with a private key and a public key is called &lt;a href="https://en.wikipedia.org/wiki/Public-key_cryptography"&gt;assymetric encryption&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;How do you create a key pair. Like this:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
$ ssh-keygen -t rsa -b 4096 -C "myemail@gmail.com"
Generating public/private rsa key pair.
Enter file in which to save the key (/home/petko/.ssh/id_rsa): ./mykey
Enter passphrase (empty for no passphrase): 
Enter same passphrase again: 
Your identification has been saved in ./mykey.
Your public key has been saved in ./mykey.pub.
The key fingerprint is:
SHA256:0/zlEZZj0R6yM4uHVD+xJWoLOx3+TormCRcyWt3c53o myemail@gmail.com
The key's randomart image is:
+---[RSA 4096]----+
|              .. |
|             o.=o|
|            ..Xo=|
|         +.++B *.|
|        S **=oB o|
|       o +o=+= + |
|      . . ..o.o .|
|         o.o o..E|
|         o+ ..o. |
+----[SHA256]-----+
$ ls -l
total 8
-rw------- 1 petko petko 3243 Aug  9 16:24 mykey
-rw-r--r-- 1 petko petko  743 Aug  9 16:24 mykey.pub&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;How do the public and private key look like. They look like this (I have removed some of the output to keep you from scrolling too much):&lt;/p&gt;
&lt;p&gt;```bash
$ cat ./mykey
-----BEGIN RSA PRIVATE KEY-----
MIIJKQIBAAKCAgEA2FGlZybznkcHQG530bj+DlrY74nTh+shP1uyJA25BrkAyOz9
xc8Tvlk3QfBcGFfQKc1OowV80XtNyXXnOeFTqlh8B8DS1Mul165wgb+pJDROvI0J
...
3vZfDPXo9w2XwAwN7hLimCVWdqr0JI8BmbussW4ZrJRcra1rvsLj6sip9Ry3oP+9
PIUEPwDY/YUVRZV2De4cBdBnwTmj9RoXOW63mW6sL8lfeYjJQwQys+jVVjRi
-----END RSA PRIVATE KEY-----&lt;/p&gt;
&lt;p&gt;$ cat ./mykey.pub 
ssh-rsa AAAAB3NzaC ... +PAAKfQ== myemail@gmail.com
```&lt;/p&gt;
&lt;p&gt;So that's it. A private key and a public key. Nothing else. Keep the private key secret, upload the public key.&lt;/p&gt;
&lt;h2 id="how-does-ssh-work"&gt;How does SSH work?&lt;/h2&gt;
&lt;p&gt;Great question. If you have a key pair you can encrypt a message with one of the keys and decrypt it with the other key. But that's not how data is exchanged with an SSH connection. SSH is actually using &lt;a href="https://en.wikipedia.org/wiki/Symmetric-key_algorithm"&gt;symmetric key encryption&lt;/a&gt;. The private and public keys are used to securely exchange a temporary symmetric key used to encrypt the data between two machines. The symmetric key crosses the wire in encrypted form, so an attacked can't find out what the key is.&lt;/p&gt;
&lt;p&gt;Dig into this excellent &lt;a href="https://superuser.com/questions/383732/how-does-ssh-encryption-work"&gt;stackoverflow question&lt;/a&gt; to learn more about this.&lt;/p&gt;
&lt;h2 id="the-ssh-command"&gt;The ssh command&lt;/h2&gt;
&lt;p&gt;We now know what's involved in SSH communication. Let's look at the commands that are used. &lt;/p&gt;
&lt;p&gt;We'll start with a clean example. I have an AWS EC2 instance on which I have installed a public key. The private key is located in my &lt;code&gt;~/.ssh/&lt;/code&gt; directory. It's called &lt;code&gt;aws-laptop&lt;/code&gt;, because I use it from my laptop.&lt;/p&gt;
&lt;p&gt;Let's try to ssh into the instance:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
~/.ssh$ ssh ubuntu@35.165.19.203
Permission denied (publickey).&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Doesn't work. Well, of course - ssh doesn't know what private key to use. We have to point to it using the &lt;code&gt;-i&lt;/code&gt; option.&lt;/p&gt;
&lt;p&gt;```bash
~/.ssh$ ssh -i ./aws-laptop ubuntu@35.165.19.203
The authenticity of host '35.165.19.203 (35.165.19.203)' can't be established.
ECDSA key fingerprint is SHA256: 3w+LlpD/HH .......
Are you sure you want to continue connecting (yes/no)? yes
Enter passphrase for key './aws-laptop':  [Here I entered a passphrase]
Welcome to Ubuntu 16.04.2 LTS (GNU/Linux 4.4.0-1022-aws x86_64)
...
Last login: Wed Aug  9 23:09:13 2017 from 76.102.141.14&lt;/p&gt;
&lt;p&gt;ubuntu@ip-172-31-13-46:~$
```&lt;/p&gt;
&lt;p&gt;Hooray, I'm in! What happened in the meantime is that the ssh command saved an entry into the &lt;code&gt;known_hosts&lt;/code&gt; file, so next time I ssh it won't ask me again to confirm the authenticity of the remote host.&lt;/p&gt;
&lt;p&gt;However, I'll still need to point to the private key and enter the passphrase for it. Very inconvenient.&lt;/p&gt;
&lt;h2 id="the-ssh-agent-daemon"&gt;The ssh-agent daemon&lt;/h2&gt;
&lt;p&gt;The solution to the above problem is the &lt;code&gt;ssh-agent&lt;/code&gt; daemon. &lt;code&gt;ssh-agent&lt;/code&gt; is a program that you start when you first login and you can add private keys to it so that next time you ssh into a server, you don't have to point to them.&lt;/p&gt;
&lt;p&gt;How does ssh-agent know which private key to use? When you run &lt;code&gt;ssh -v ubuntu@35.165.19.203&lt;/code&gt; you can see that there's a bit of back and forth where &lt;code&gt;ssh&lt;/code&gt; seems to be trying out private keys from &lt;code&gt;ssh-agent&lt;/code&gt;. So I guess that's how it's done:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
debug1: Offering RSA public key: /home/petko/.ssh/id_rsa
debug1: Authentications that can continue: publickey
debug1: Offering RSA public key: ./aws-laptop
debug1: Server accepts key: pkalg rsa-sha2-512 blen 279&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;We can list the keys in ssh-agent with this command:
&lt;code&gt;bash
$ ssh-add -l
The agent has no identities.&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;No keys. So let's add the key that we were using.
&lt;code&gt;bash
$ ssh-add ./aws-laptop
Enter passphrase for ./aws-laptop: [I entered passphrase]
Identity added: ./aws-laptop (./aws-laptop)
$ ssh-add -l
2048 SHA256:tU++v7cfD8... ./aws-laptop (RSA)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The private key is now saved! I can now ssh without pointing to it:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
$ ssh ubuntu@35.165.19.203
Welcome to Ubuntu 16.04.2 LTS (GNU/Linux 4.4.0-1022-aws x86_64)
...
ubuntu@ip-172-31-13-46:~$&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Great.&lt;/p&gt;
&lt;h2 id="tips-and-tricks"&gt;Tips and tricks&lt;/h2&gt;
&lt;h3 id="manually-verifying-a-private-key"&gt;Manually verifying a private key&lt;/h3&gt;
&lt;p&gt;Today I was trying again and again to connect to a remote machine using the wrong private key. I was able to connect to that machine from my laptop, but not from my Ubuntu VM.&lt;/p&gt;
&lt;p&gt;I was running the following command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
$ ssh -i ./somekey.pem  ubuntu@35.165.19.203
Permission denied (publickey).&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;How did I debug this? I ssh-ed into the server from my laptop and looked up the public key in &lt;code&gt;~/.ssh/authorized_keys&lt;/code&gt;. I then generated the public key from my private key, like this:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
$ ssh-keygen -y -f  ./somekey.pem
ssh-rsa AAAAB3....KY1&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;And sure enough, the public keys were not matching. I then found the correct private key and was able to connect with it.&lt;/p&gt;
&lt;p&gt;If you're following carefully, you'll notice that I did something here that's considered a bad practice. I reused my private key from my laptop on my VirtualBox. I should generate a new key pair and add the public key to the &lt;code&gt;authorized_keys&lt;/code&gt; file on the server.&lt;/p&gt;
&lt;p&gt;So that's it so far. One thing that I didn't cover is how to start the ssh agent automatically. I have some commands in my &lt;code&gt;bash_profile&lt;/code&gt; to do that that I digged from Stack Overflow. Here's a &lt;a href="http://www.snailbook.com/faq/about-agent.auto.html"&gt;great description&lt;/a&gt; that can aid in starting &lt;code&gt;ssh-agent&lt;/code&gt;.&lt;/p&gt;</content></entry><entry><title>Socket Programming in Linux</title><link href="http://pminkov.github.io/blog/socket-programming-in-linux.html" rel="alternate"></link><published>2017-08-02T12:10:00-07:00</published><updated>2017-08-02T12:10:00-07:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2017-08-02:/blog/socket-programming-in-linux.html</id><summary type="html">&lt;p&gt;Some time last year I wanted to learn more about network programming and multi threading and wrote a &lt;a href="https://github.com/pminkov/webserver/"&gt;webserver&lt;/a&gt; in C. A few days ago I decided that my learning in network programming is not quite complete without writing a client as well, so I wrote &lt;a href="https://github.com/pminkov/webserver/blob/master/client.c"&gt;a client&lt;/a&gt; too. It's …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Some time last year I wanted to learn more about network programming and multi threading and wrote a &lt;a href="https://github.com/pminkov/webserver/"&gt;webserver&lt;/a&gt; in C. A few days ago I decided that my learning in network programming is not quite complete without writing a client as well, so I wrote &lt;a href="https://github.com/pminkov/webserver/blob/master/client.c"&gt;a client&lt;/a&gt; too. It's now time to write a bit about how all of this works.&lt;/p&gt;
&lt;p&gt;Programming sockets in Linux is similar to all system programming in C. It's easy to make errors, so you have to be careful. It's difficult to comprehend the complexity and intricacy if you're just copying and pasting code from Stack Overflow. &lt;a href="http://man7.org/tlpi/"&gt;The Linux Programming Interface&lt;/a&gt; is a book that has several chapters dedicated to socket programming and it describes it very well, as well as throwing in a lot of information about how networks work and an excellent concise description of the TCP protocol. I highly recommend that book and I might write more about it in the future.&lt;/p&gt;
&lt;p&gt;So let's talk a bit about how to write a webserver and a client for it in C.&lt;/p&gt;
&lt;p&gt;Let's start with the server. The full code is in &lt;a href="https://github.com/pminkov/webserver/blob/master/server.c"&gt;server.c&lt;/a&gt;, but I'll summarize the imporatnt points:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Create a socket with &lt;code&gt;socket()&lt;/code&gt;. The code looks like  this:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;c
int sockfd = socket(AF_INET, SOCK_STREAM, 0);&lt;/code&gt;
&lt;code&gt;SOCK_STREAM&lt;/code&gt; means that we're creating a stream socket (TCP socket).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bind the socket to an address. The key lines are:
&lt;code&gt;c
1: struct sockaddr_in serv_addr;
2: uint16_t port = 8000;
...
3: serv_addr.sin_family = AF_INET;
4: serv_addr.sin_port = htons(port);
5: serv_addr.sin_addr.s_addr = htonl(INADDR_ANY);
...
6: bind(sockfd, (struct sockaddr *) &amp;amp;serv_addr, sizeof(serv_addr))&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We're creating an address &lt;code&gt;serv_addr&lt;/code&gt; and binding it to the socket we created above. Note that we use &lt;code&gt;INADDR_ANY&lt;/code&gt; as the IP address on which the socket is listening. This is the so-called IPv4 wildcard address. It binds your server to all interfaces available on your machine. That's more useful for me than binding to &lt;code&gt;INADDR_LOOPBACK&lt;/code&gt; (127.0.0.1), because I'm running my code in a VM and accessing the server from my MacBook. Run &lt;code&gt;ifconfig&lt;/code&gt; on your box to see the network interfaces that are available on it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Great, we have a socket and it's assigned to an address. This socket can now be used as as passive socket (it's listening for connections) or an active socket (it's used to connect to a peer socket). We want a passive socket. We mark it as a passive socket by calling the &lt;code&gt;listen&lt;/code&gt; function. The code looks like this:
&lt;code&gt;c
if (listen(sockfd, SOMAXCONN) &amp;lt; 0) error("Couldn't listen");&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The socket is now ready to accept connections. This can happen in a loop that looks like this:
```c
struct sockaddr_in client_addr;
int cli_len = sizeof(client_addr);&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;while (1) {
    int newsockfd = accept(sockfd, (struct sockaddr &lt;em&gt;) &amp;amp;client_addr, 
        (socklen_t &lt;/em&gt;) &amp;amp;cli_len);
    if (newsockfd &amp;lt; 0) error("Error on accept");
    // newsockfd is a file descriptor. 
    // Handle the connection by reading from and writing to this descriptor.
    ...
}
```&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;accept&lt;/code&gt; function blocks until a connection request is received and creates a new socket when that happens. After that, it's your call how you'll handle this socket. You can fork a new process, create a new thread or in my case I have a thred pool of pre-forked threads which just pull these sockets from a queue and do what's necessary to handle a web server request.&lt;/p&gt;
&lt;p&gt;That's the server. Now let's look at the client. Full code is in &lt;a href="https://github.com/pminkov/webserver/blob/master/client.c"&gt;client.c&lt;/a&gt;. It's a pretty simple client that connects to localhost (127.0.0.1). So you can't use it if the server is running remotely.&lt;/p&gt;
&lt;p&gt;You start by creating a socket with &lt;code&gt;socket()&lt;/code&gt; and then calling &lt;code&gt;connect()&lt;/code&gt; and passing the address to which you want to connect:
```c
int sockfd = socket(AF_INET, SOCK_STREAM, 0);
if (sockfd == -1) {
    error("socket");
}&lt;/p&gt;
&lt;p&gt;uint16_t port = 8000;&lt;/p&gt;
&lt;p&gt;struct sockaddr_in serv_addr;
serv_addr.sin_family = AF_INET;
serv_addr.sin_port = htons(port);
serv_addr.sin_addr.s_addr = htonl(INADDR_LOOPBACK);&lt;/p&gt;
&lt;p&gt;if (connect(sockfd, (struct sockaddr *)&amp;amp;serv_addr, sizeof(struct sockaddr_in)) == -1) {
    error("connect");
}
```&lt;/p&gt;
&lt;p&gt;If the connection is successful, you can just send your request to the server using the &lt;code&gt;write()&lt;/code&gt; system call and read the response with the &lt;code&gt;read()&lt;/code&gt; call.&lt;/p&gt;
&lt;p&gt;So that's a simple web server and a client. The code still has a lot of bugs (the client will buffer overflow if I pass a request string longer than 512 chars, I'm not closing the connection explicitly, etc.), but it gets the job done.&lt;/p&gt;
&lt;p&gt;A final interesting thing to do is to run Wireshark and see what packets are going between the client and the server. To do this, I started the server on my Virtual box Ubuntu (192.168.1.135) and ran &lt;code&gt;curl&lt;/code&gt; from my MacBook (192.168.1.86). Here's what I saw in Wireshark:&lt;/p&gt;
&lt;p&gt;&lt;center&gt;&lt;img alt="Wireshark" src="http://pminkov.github.io/blog/images/wireshark.png" /&gt;&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;You can see the three way TCP handshake in the beginning (&lt;code&gt;SYN&lt;/code&gt; followed by &lt;code&gt;SYN,ACK&lt;/code&gt; followed by &lt;code&gt;ACK&lt;/code&gt;) and everything else in between. It's definitely something interesting to try out.&lt;/p&gt;</content></entry><entry><title>Versioning Docker Images</title><link href="http://pminkov.github.io/blog/versioning-docker-images.html" rel="alternate"></link><published>2017-07-30T21:57:00-07:00</published><updated>2017-07-30T21:57:00-07:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2017-07-30:/blog/versioning-docker-images.html</id><summary type="html">&lt;p&gt;If you're running Docker containers in the cloud, you're probably uploading them into a registry. If you're using Google Cloud, that would be &lt;a href="https://cloud.google.com/container-registry/"&gt;gcr.io &lt;/a&gt;(Google Container Registry).&lt;/p&gt;
&lt;p&gt;As you're iterating on your application, you'll need to push new Docker images to the registry. A natural questions that comes is …&lt;/p&gt;</summary><content type="html">&lt;p&gt;If you're running Docker containers in the cloud, you're probably uploading them into a registry. If you're using Google Cloud, that would be &lt;a href="https://cloud.google.com/container-registry/"&gt;gcr.io &lt;/a&gt;(Google Container Registry).&lt;/p&gt;
&lt;p&gt;As you're iterating on your application, you'll need to push new Docker images to the registry. A natural questions that comes is how to version these images? You don't want to overwrite images using the same tag and it's cumbersome to keep track of increasing version numbers. A good versioning scheme is to use a &lt;a href="https://blog.thoughtram.io/git/2014/11/18/the-anatomy-of-a-git-commit.html"&gt;git commit hash&lt;/a&gt;. So your image name might looks like this: &lt;code&gt;gcr.io/kubeproject-172120/simple:88d38d9&lt;/code&gt;. If you take your git repository at this hash, you'll find the files that produced this exact image.&lt;/p&gt;
&lt;p&gt;This sounds simple to implement. You get the last commit's hash, build the image using the hash as a tag and push it to the registry. There's one big inconvinience to this scheme though - you have to commit each change if you want to use a new hash (and you do, you don't want to overwrite your production image) and when you're iterating on an image, that gets tiresome quickly. One possible solution would be to commit "debug" images. These images might be tagged with something like this &lt;code&gt;88d38d9-debug&lt;/code&gt;. This is an image produced by taking the git repo at the &lt;code&gt;88d38d9&lt;/code&gt; hash and making some modifications. You'll know not to include these images in your production files and it's ok to overwrite them as you're iterating.&lt;/p&gt;
&lt;p&gt;So let's look at how all of this can be implemented. Let's say you're putting all your images in one directory. The contents of this directory might look like this:&lt;/p&gt;
&lt;p&gt;```bash
$ tree
.
├── build-image.sh
└── simple
    ├── app.py
    ├── Dockerfile
    └── requirements.txt&lt;/p&gt;
&lt;p&gt;1 directory, 4 files
```&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;build-image.sh&lt;/code&gt; script builds the Docker image and pushes it to &lt;code&gt;gcr.io&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The script itself looks like this:&lt;/p&gt;
&lt;p&gt;```bash&lt;/p&gt;
&lt;h1 id="binbash"&gt;!/bin/bash&lt;/h1&gt;
&lt;p&gt;if [ -z "$1" ]; then
  echo "Usage: $0 &lt;image_dir&gt; [--debug]"
  exit 1
fi&lt;/p&gt;
&lt;p&gt;IMAGE_NAME=$1&lt;/p&gt;
&lt;p&gt;if [ "$2" == "--debug" ]; then
  # If we're debugging, we can push code that's not committed.
  APPEND="-debug"
else
  IMAGE_PATH=/$IMAGE_NAME/&lt;/p&gt;
&lt;p&gt;if git status . --porcelain | grep $IMAGE_PATH &amp;gt; /dev/null; then
    echo "You have uncommited changes to your Docker image. Please commit them"
    echo "before building and populating. This helps ensure that all docker images"
    echo "are traceable back to a git commit."
    echo
    echo "Or if you're just building a debug image, use the --debug flag."
    exit 1
  fi
fi&lt;/p&gt;
&lt;h1 id="set-image-tag"&gt;Set image tag.&lt;/h1&gt;
&lt;p&gt;GIT_REV=$(git log -n 1 --pretty=format:%h -- ./$IMAGE_NAME/)&lt;/p&gt;
&lt;p&gt;if [ ! $GIT_REV ]; then
  echo "You're trying to build an image that has never been committed." \
    "You need to commit at least one version."
  exit 1
fi&lt;/p&gt;
&lt;p&gt;TAG="$GIT_REV""$APPEND"&lt;/p&gt;
&lt;h1 id="set-image-repo"&gt;Set image repo.&lt;/h1&gt;
&lt;p&gt;PROJECT_ID=$(gcloud config get-value project 2&amp;gt;/dev/null)
DOCKER_REPO="gcr.io/$PROJECT_ID"&lt;/p&gt;
&lt;h1 id="full-image-name"&gt;Full image name.&lt;/h1&gt;
&lt;p&gt;IMAGE_SPEC="$DOCKER_REPO/$IMAGE_NAME:$TAG"&lt;/p&gt;
&lt;p&gt;cd $IMAGE_NAME&lt;/p&gt;
&lt;p&gt;if [ ! -f $DOCKERFILE ]; then
  echo "No such file: $IMAGE_NAME/$DOCKERFILE"
  exit 1
fi&lt;/p&gt;
&lt;p&gt;echo $IMAGE_SPEC&lt;/p&gt;
&lt;p&gt;docker build -t $IMAGE_SPEC .
gcloud docker -- push $IMAGE_SPEC&lt;/p&gt;
&lt;p&gt;echo "Pushed $IMAGE_SPEC"
```&lt;/p&gt;
&lt;p&gt;One thing to pay attention to is that the hash that we're using is the hash of the last commit to the directory that contains the container files. This way, if you want to push a production ready image (non-debug), you can only commit the files inside this directory and if you're still working on others outside of it, you can continue doing so.&lt;/p&gt;
&lt;p&gt;Let's run the &lt;code&gt;build-image.sh&lt;/code&gt; script:
&lt;code&gt;bash
$ ./build-image.sh simple
gcr.io/kubehub-172120/simple:12430ce
Sending build context to Docker daemon 4.096 kB
Step 1/9 : FROM ubuntu:latest
 ---&amp;gt; 14f60031763d
Step 2/9 : MAINTAINER Petko Minkov "pminkov@gmail.com"
 ---&amp;gt; Using cache
 ---&amp;gt; 5a371036a9e3
Step 3/9 : RUN apt-get update -y
 ---&amp;gt; Using cache
 ---&amp;gt; 8992277faa20
Step 4/9 : RUN apt-get install -y python-pip python-dev build-essential
 ---&amp;gt; Using cache
 ---&amp;gt; 9c0937facaf0
Step 5/9 : COPY . /app
 ---&amp;gt; Using cache
 ---&amp;gt; dd9f289c1f55
Step 6/9 : WORKDIR /app
 ---&amp;gt; Using cache
 ---&amp;gt; d93c62ac371a
Step 7/9 : RUN pip install --upgrade pip
 ---&amp;gt; Using cache
 ---&amp;gt; cb2f0a65c93f
Step 8/9 : RUN pip install -r requirements.txt
 ---&amp;gt; Using cache
 ---&amp;gt; d8fd659127d9
Step 9/9 : CMD python app.py
 ---&amp;gt; Using cache
 ---&amp;gt; 8493c8ad1a01
Successfully built 8493c8ad1a01
The push refers to a repository [gcr.io/kubehub-172120/simple]
dacb974e8350: Layer already exists 
6c4d57527510: Layer already exists 
5348dff0fc19: Layer already exists 
738da70fc9f8: Layer already exists 
f665434eb0ee: Layer already exists 
26b126eb8632: Layer already exists 
220d34b5f6c9: Layer already exists 
8a5132998025: Layer already exists 
aca233ed29c3: Layer already exists 
e5d2f035d7a4: Layer already exists 
12430ce: digest: sha256:51cd80db604d1ffa5230289c1f3fe40d19b3b8dc2afb0a0c003713360b07d2c6 size: 2411
Pushed gcr.io/kubehub-172120/simple:12430ce&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Great, now the image is pushed. But I always like to use a "trust but verify" policy, so let's see how can we dig into what's going on at the registry.&lt;/p&gt;
&lt;p&gt;My image's name is this &lt;code&gt;gcr.io/kubehub-172120/simple&lt;/code&gt;. Here's how I see the tags I have uploaded to &lt;code&gt;gcr.io&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
$ gcloud beta container images list-tags gcr.io/kubehub-172120/simple
DIGEST        TAGS                   TIMESTAMP
9b424f849df2  88d38d9-debug,e8bc006  2017-07-30T23:03:14
51cd80db604d  12430ce                2017-07-30T23:06:42&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;If you want to inspect the contents of the image, you can just run a shell, like this:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
$ gcloud docker -- run -i -t gcr.io/kubehub-172120/simple:12430ce /bin/bash
root@27cfb042d947:/app# ls
Dockerfile  app.py  requirements.txt
root@27cfb042d947:/app#&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;I've used this workflow when working with a Kubernetes deployment and it worked well for me. Hope it's useful for someone else too. Enjoy.&lt;/p&gt;</content></entry><entry><title>Visualizing algorithms with Jupyter notebooks</title><link href="http://pminkov.github.io/blog/visualizing-algorithms-with-jupyter-notebooks.html" rel="alternate"></link><published>2017-04-24T21:10:00-07:00</published><updated>2017-04-24T21:10:00-07:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2017-04-24:/blog/visualizing-algorithms-with-jupyter-notebooks.html</id><summary type="html">&lt;p&gt;Last couple of days I was looking into some old implementation of k-means clustering that I wrote. At that time I didn't know how to use matplotlib and to display the clusters that were generated and I was printing commands that I was plugging into R. Since then, I've learned …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Last couple of days I was looking into some old implementation of k-means clustering that I wrote. At that time I didn't know how to use matplotlib and to display the clusters that were generated and I was printing commands that I was plugging into R. Since then, I've learned how to use Jupyter, so I sat down and imported the code into a Jupyter notebook that's visualizing the algorithm.&lt;/p&gt;
&lt;p&gt;Here's the &lt;a href="http://nbviewer.jupyter.org/github/pminkov/notebooks/blob/master/k-means%20clustering.ipynb"&gt;Jupyter notebook&lt;/a&gt;. Overall, I quite enjoy how this format mixes the results of code execution with Markdown segments.&lt;/p&gt;</content></entry><entry><title>Removing a node from a Kubernetes cluster on GKE (Google Container Engine)</title><link href="http://pminkov.github.io/blog/removing-a-node-from-a-kubernetes-cluster-on-gke-google-container-engine.html" rel="alternate"></link><published>2017-03-30T16:17:00-07:00</published><updated>2017-03-30T16:17:00-07:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2017-03-30:/blog/removing-a-node-from-a-kubernetes-cluster-on-gke-google-container-engine.html</id><summary type="html">&lt;p&gt;In this post, I'll describe how to remove a particular node from a Kubernetes cluster on GKE. Why would you want to do that? In my case, I'm running jupyterhub and I need to do that as part of implementing cluster scaling. That's probably a rare need, but it helped …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In this post, I'll describe how to remove a particular node from a Kubernetes cluster on GKE. Why would you want to do that? In my case, I'm running jupyterhub and I need to do that as part of implementing cluster scaling. That's probably a rare need, but it helped me understand more about the GCE structures behind a Kubernetes cluster.&lt;/p&gt;
&lt;p&gt;So let's start. The first thing you need to do is:&lt;/p&gt;
&lt;h3 id="drain-your-node"&gt;Drain your node&lt;/h3&gt;
&lt;p&gt;Let's look at my nodes:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
$ kl get nodes
NAME                                      STATUS    AGE
gke-jcluster-default-pool-9cc4e660-rx9p   Ready     1d
gke-jcluster-default-pool-9cc4e660-xr4z   Ready     2d&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;I want to remove rx9p. I'll first &lt;a href="https://kubernetes.io/docs/tasks/administer-cluster/safely-drain-node/"&gt;drain&lt;/a&gt; it:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
$ kl drain gke-jcluster-default-pool-9cc4e660-rx9p  --force
node "gke-jcluster-default-pool-9cc4e660-rx9p" cordoned
error: pods with local storage (use --delete-local-data to override): jupyter-petko-1&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Great, the node is now drained. Next is:&lt;/p&gt;
&lt;h3 id="removing-the-gce-vm"&gt;Removing the GCE VM&lt;/h3&gt;
&lt;p&gt;Your Kubernetes cluster runs in an &lt;a href="https://cloud.google.com/compute/docs/instance-groups/"&gt;instance group&lt;/a&gt;. We'll need to know what this group is. Here's how to do it from the command line.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
$ export GROUP_ID=$(gcloud container clusters describe jcluster --format json | jq  --raw-output '.instanceGroupUrls[0]' | rev | cut -d'/' -f 1 | rev)
$ echo $GROUP_ID
gke-jcluster-default-pool-9cc4e660-grp&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Let's check my instances:
&lt;code&gt;bash
$ gcloud compute instances list
NAME                                     ZONE           MACHINE_TYPE   PREEMPTIBLE  INTERNAL_IP  EXTERNAL_IP      STATUS
gke-jcluster-default-pool-9cc4e660-rx9p  us-central1-b  n1-standard-1               10.128.0.2   104.198.174.222  RUNNING
gke-jcluster-default-pool-9cc4e660-xr4z  us-central1-b  n1-standard-1               10.128.0.4   104.197.237.135  RUNNING&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;If I just run &lt;code&gt;gcloud compute instances delete&lt;/code&gt; that won't work! That's because I have an instance group of size 2 and if I delete one of the machines, GCE will start a new one. I have to use the &lt;code&gt;gcloud compute  instance-groups managed delete-instances&lt;/code&gt; command, followed by &lt;code&gt;gcloud compute instance-groups managed wait-until-stable&lt;/code&gt; if I want to wait until the job is done.&lt;/p&gt;
&lt;p&gt;Let's see how that looks like:&lt;/p&gt;
&lt;p&gt;```bash
$ gcloud compute instance-groups managed delete-instances $GROUP_ID --instances=gke-jcluster-default-pool-9cc4e660-rx9p
Updated [https://www.googleapis.com/compute/v1/projects/myhub-161019/zones/us-central1-b/instanceGroupManagers/gke-jcluster-default-pool-9cc4e660-grp].&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;baseInstanceName: gke-jcluster-default-pool-9cc4e660
creationTimestamp: '2017-03-25T02:52:22.040-07:00'
currentActions:
  abandoning: 0
  creating: 0
  creatingWithoutRetries: 0
  deleting: 1
  none: 1
  recreating: 0
  refreshing: 0
  restarting: 0
fingerprint: kUg7ggCEudY=
id: '6475008099735012154'
instanceGroup: gke-jcluster-default-pool-9cc4e660-grp
instanceTemplate: gke-jcluster-default-pool-9cc4e660
kind: compute#instanceGroupManager
name: gke-jcluster-default-pool-9cc4e660-grp
selfLink: https://www.googleapis.com/compute/v1/projects/myhub-161019/zones/us-central1-b/instanceGroupManagers/gke-jcluster-default-pool-9cc4e660-grp
targetSize: 1
zone: us-central1-b
$ gcloud compute instance-groups managed wait-until-stable $GROUP_ID
Waiting for group to become stable, current operations: deleting: 1
...
Waiting for group to become stable, current operations: deleting: 1
Group is stable
```&lt;/p&gt;
&lt;p&gt;And indeed, we only have one node left now:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
$ kl get nodes
gcloud compute instanceNAME                                      STATUS    AGE
gke-jcluster-default-pool-9cc4e660-xr4z   Ready     2d
$ gcloud compute instances list
NAME                                     ZONE           MACHINE_TYPE   PREEMPTIBLE  INTERNAL_IP  EXTERNAL_IP      STATUS
gke-jcluster-default-pool-9cc4e660-xr4z  us-central1-b  n1-standard-1               10.128.0.4   104.197.237.135  RUNNING&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;So that's it. Regardless of whether you need to delete individual nodes, it's interesting to take a look at how you can do that.&lt;/p&gt;</content></entry><entry><title>Starting with Kubernetes on Google Container Engine</title><link href="http://pminkov.github.io/blog/starting-with-kubernetes-on-google-container-engine.html" rel="alternate"></link><published>2017-03-07T12:42:00-08:00</published><updated>2017-03-07T12:42:00-08:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2017-03-07:/blog/starting-with-kubernetes-on-google-container-engine.html</id><summary type="html">&lt;p&gt;This is a tutorial of how to run a simple Kubernetes app on &lt;a href="https://cloud.google.com/container-engine/"&gt;GKE&lt;/a&gt; (Google Container Engine).&lt;/p&gt;
&lt;p&gt;&lt;a href="https://kubernetes.io/"&gt;Kubernetes&lt;/a&gt; is a container orchestration software that started at Google. Right now it's an open source project maintained by &lt;a href="https://www.cncf.io/"&gt;Cloud Native Computing Foundation&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;So what's Kubernetes all about? Roughly, it's about managing a …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is a tutorial of how to run a simple Kubernetes app on &lt;a href="https://cloud.google.com/container-engine/"&gt;GKE&lt;/a&gt; (Google Container Engine).&lt;/p&gt;
&lt;p&gt;&lt;a href="https://kubernetes.io/"&gt;Kubernetes&lt;/a&gt; is a container orchestration software that started at Google. Right now it's an open source project maintained by &lt;a href="https://www.cncf.io/"&gt;Cloud Native Computing Foundation&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;So what's Kubernetes all about? Roughly, it's about managing a cluster (a set of machines) on which we have containers running. &lt;/p&gt;
&lt;h3 id="why-containers"&gt;Why containers?&lt;/h3&gt;
&lt;p&gt;Well, that's a question that probably has a lot of answers, but containers are very lightweight virtual machines more or less. The technology under them is different than virtual machines though. We can orchestrate a set of VMs, but containers are much easier to work with. For example I have one VM running on my MacBook - it eats a lot of memory, it's managed by VirtualBox, it has a lot of stuff installed on it. I can't imagine having to run a bunch of these. Containers though, they're much easier to setup (you just write a text file that describes them - the Dockerfile) and much more lightweight. Their memory footprint can be pretty low. Containers can run on different OSs, some of which are very lightweight. Ok, enough about containers - back to Kubernetes.&lt;/p&gt;
&lt;h3 id="whats-in-a-cluster"&gt;What's in a cluster?&lt;/h3&gt;
&lt;p&gt;I mentioned clusters. But what's a cluster. A cluster has a set of nodes (think computers) on which we have pods, where each pod is a unit that contains several containers. That's the basic structure.&lt;/p&gt;
&lt;h3 id="running-a-simple-kubernetes-app-on-gke"&gt;Running a simple Kubernetes app on GKE.&lt;/h3&gt;
&lt;p&gt;Alright, let's roll our sleeves. Google has its own &lt;a href="https://cloud.google.com/container-engine/docs/quickstart"&gt;Quickstart&lt;/a&gt; tutorial, but what I don't like about it is that it doesn't describe how to create your own container and it doesn't talk about the Kubernetes dashboard. But a lot of the steps here you can see in Google's tutorial as well.&lt;/p&gt;
&lt;p&gt;So let's start.&lt;/p&gt;
&lt;h3 id="create-a-project"&gt;Create a project.&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Go to the &lt;a href="https://console.cloud.google.com"&gt;Cloud Console&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Create a project. Mine is called "mykube". Every project has an id that you're mostly working with. Mine is &lt;code&gt;mykube-160819&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="install-necessary-tools-and-initialize-them"&gt;Install necessary tools and initialize them.&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Install the &lt;a href="https://cloud.google.com/sdk/downloads"&gt;Google Cloud SDK&lt;/a&gt;. There's a web interface for working with the SDK, called Google Cloud Shell, but I like having the tools installed locally.&lt;/li&gt;
&lt;li&gt;Initialize gcloud by running &lt;code&gt;gcloud init&lt;/code&gt;. You'll be asked for the name of your project.&lt;/li&gt;
&lt;li&gt;Set a &lt;a href="https://cloud.google.com/compute/docs/regions-zones/regions-zones#available"&gt;Compute Engine zone&lt;/a&gt;, like this:
&lt;code&gt;bash
gcloud config set compute/zone us-central1-b&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;That's it. You can view your configuration:
```bash
$ gcloud config list
Your active configuration is: [mykube]&lt;/p&gt;
&lt;p&gt;[compute]
zone = us-central1-b
[core]
account = pminkov@gmail.com
disable_usage_reporting = False
project = mykube-160819
```&lt;/p&gt;
&lt;p&gt;Let's authenticate gcloud too:
&lt;code&gt;bash
gcloud auth application-default login&lt;/code&gt;&lt;/p&gt;
&lt;h3 id="run-a-container-image"&gt;Run a container image.&lt;/h3&gt;
&lt;p&gt;Our container is going to be a node.js application that we'll build ourselves. I wanted to experiment with an app that takes a bit more memory, so here's how my code looks like:&lt;/p&gt;
&lt;p&gt;```js
$ cat ./server.js 
function randomInt(n) {
  return Math.floor(Math.random() * n);
}&lt;/p&gt;
&lt;p&gt;var http = require('http');&lt;/p&gt;
&lt;p&gt;var N = 20000000;
var nums = new Array(N);&lt;/p&gt;
&lt;p&gt;for (var i = 0; i &amp;lt; N; i++) {
  nums[i] = randomInt(N) * 10;
}&lt;/p&gt;
&lt;p&gt;var handleRequest = function(request, response) {
  console.log('Received request for URL: ' + request.url);
  response.writeHead(200);
  var index = randomInt(N);
  response.write('Returning element at index ' + index + ': ' + nums[index] + '\n');
  response.end('Hello World!');
};
var www = http.createServer(handleRequest);&lt;/p&gt;
&lt;p&gt;console.log('Listening on port 8080');
www.listen(8080);
```&lt;/p&gt;
&lt;p&gt;We also need a Dockerfile:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
$ cat ./Dockerfile 
FROM node:4
EXPOSE 8080
COPY server.js .
CMD node server.js&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;In order to run a container on GKE, we need to upload it to &lt;a href="https://cloud.google.com/container-registry/"&gt;Google Container Registry&lt;/a&gt;. Let's do it:&lt;/p&gt;
&lt;p&gt;```bash
$ export PROJECT_ID=mykube-160819
$ docker build -t gcr.io/$PROJECT_ID/myserver .
Sending build context to Docker daemon 3.584 kB
Step 1/4 : FROM node:4
 ---&amp;gt; d7efee1f035d
Step 2/4 : EXPOSE 8080
 ---&amp;gt; Using cache
 ---&amp;gt; 147e7888542d
Step 3/4 : COPY server.js .
 ---&amp;gt; Using cache
 ---&amp;gt; b610e7975d20
Step 4/4 : CMD node server.js
 ---&amp;gt; Using cache
 ---&amp;gt; 4e15133cdab2
Successfully built 4e15133cdab2
$ gcloud docker -- push gcr.io/$PROJECT_ID/myserver
The push refers to a repository [gcr.io/mykube-160819/myserver]&lt;/p&gt;
&lt;h1 id="note-that-i-already-have-a-project-called-hikube-which-has-the-same-docker-image"&gt;Note that I already have a project called "hikube" which has the same docker image.&lt;/h1&gt;
&lt;h1 id="the-mykube-project-is-something-i-created-for-this-tutorial"&gt;The "mykube" project is something I created for this tutorial.&lt;/h1&gt;
&lt;p&gt;1bcf3881e79d: Mounted from hikube-160719/myserver 
65e403c25ee9: Mounted from hikube-160719/myserver 
4732c3666dd7: Mounted from hikube-160719/myserver 
a1fbf6fa923f: Mounted from hikube-160719/myserver 
1b8ef9ac5116: Mounted from hikube-160719/myserver 
41ef8cc0bccb: Mounted from hikube-160719/myserver 
100396c46221: Mounted from hikube-160719/myserver 
7b4b54c74241: Mounted from hikube-160719/myserver 
d17d48b2382a: Mounted from hikube-160719/myserver 
latest: digest: sha256:4ad68f056e870938823f6c9555355c149cf7c42a213d7243d915f1a4bcfb9cb1 size: 2213
```&lt;/p&gt;
&lt;p&gt;If you go to the Google Cloud Console and open the Google Container Registry, you'll see the container uploaded:&lt;/p&gt;
&lt;p&gt;&lt;center&gt;&lt;img alt="Google Container Registry" src="http://pminkov.github.io/blog/images/k8s-intro/k1-registry.png" /&gt;&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;Now let's create a cluster that we'll be deploying our server to:
&lt;code&gt;$ gcloud container clusters create example-cluster
Creating cluster example-cluster...done.                                                                                                                                               
Created [https://container.googleapis.com/v1/projects/mykube-160819/zones/us-central1-b/clusters/example-cluster].
kubeconfig entry generated for example-cluster.
NAME             ZONE           MASTER_VERSION  MASTER_IP       MACHINE_TYPE   NODE_VERSION  NUM_NODES  STATUS
example-cluster  us-central1-b  1.5.3           104.198.190.52  n1-standard-1  1.5.3         3          RUNNING&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Congratulations! We have a cluster running.&lt;/p&gt;
&lt;p&gt;A little segway. kubectl has a config that determines which cluster you're working with. You can switch between different clusters. Try it:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
$ kubectl config current-context
gke_mykube-160819_us-central1-b_example-cluster&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;We're good here - our context is for the "mykube" cluster. The cluster is empty, we can verify it like this:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
$ kubectl get pods
No resources found.&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Now let's start out server finally:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
$ kubectl run myserver --image=gcr.io/$PROJECT_ID/myserver --port=8080
deployment "myserver" created&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;We have created a deployment that contains a pod. Let's see what pods we have now:
&lt;code&gt;bash
$ kubectl get pods
NAME                        READY     STATUS              RESTARTS   AGE
myserver-3430466764-04b36   0/1       ContainerCreating   0          17s&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Nice, our container is getting spinned. We wait for a bit and we see:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
$ kubectl get pods
NAME                        READY     STATUS    RESTARTS   AGE
myserver-3430466764-04b36   1/1       Running   0          58s&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;We can now expose the container:
&lt;code&gt;bash
$ kubectl expose deployment myserver --type="LoadBalancer"
service "myserver" exposed&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This will also take some time:
&lt;code&gt;bash
$ kubectl get service myserver
NAME       CLUSTER-IP   EXTERNAL-IP   PORT(S)          AGE
myserver   10.3.247.6   &amp;lt;pending&amp;gt;     8080:31574/TCP   34s&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Aaand, it's done:
&lt;code&gt;bash
$ kubectl get service myserver
NAME       CLUSTER-IP   EXTERNAL-IP      PORT(S)          AGE
myserver   10.3.247.6   104.155.177.47   8080:31574/TCP   1m&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;If we go to &lt;code&gt;http://104.155.177.47:8080/&lt;/code&gt;, we'll see:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
Returning element at index 6110645: 116527640
Hello World!&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Now, the tedious part is over. Let's have some fun. We can monitor our cluster through the Kubernetes dashboard. For a reason unclear to me, this dashboard is not available on the Google website. You have to run a proxy to do it. Like this:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
$ kubectl proxy
Starting to serve on 127.0.0.1:8001&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;We can see the dashboard at &lt;code&gt;localhost:8001/ui&lt;/code&gt;. It looks like this:&lt;/p&gt;
&lt;p&gt;&lt;center&gt;&lt;img alt="Kubernetes Dashboard" src="http://pminkov.github.io/blog/images/k8s-intro/k2-dashboard.png" /&gt;&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;This dashboard is a lot of fun. You can dig into everything available in it. You can probably see everything it shows through kubectl as well, but it's easier to do it by using an UI.&lt;/p&gt;
&lt;p&gt;Here's something else that's fun. Your cluster doesn't run on thin air. It runs on Google Compute Engine instances (I believe this is equivalent to AWS' EC2). In your cloud console, you can navigate to your instances and you can even SSH to an instance from the web UI (I wow-ed the first time I did this, much easier than setting up ssh access on AWS).&lt;/p&gt;
&lt;p&gt;Our cluster has three nodes.
&lt;code&gt;bash
$ kubectl get nodes
NAME                                             STATUS    AGE
gke-example-cluster-default-pool-2567fc65-1h40   Ready     21m
gke-example-cluster-default-pool-2567fc65-g7lc   Ready     21m
gke-example-cluster-default-pool-2567fc65-n0cp   Ready     21m&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;These are three GCE instances. Where is our pod running at?&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
$ kubectl get pods -o wide
NAME                        READY     STATUS    RESTARTS   AGE       IP         NODE
myserver-3430466764-04b36   1/1       Running   0          18m       10.0.1.5   gke-example-cluster-default-pool-2567fc65-g7lc&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;It's running on &lt;code&gt;gke-example-cluster-default-pool-2567fc65-g7lc&lt;/code&gt;. Now I can navigate to the web page for this instance and ssh to it. Here's a screenshot of how that looks like:&lt;/p&gt;
&lt;p&gt;&lt;center&gt;&lt;img alt="Compute Engine SSH" src="http://pminkov.github.io/blog/images/k8s-intro/k3-compute-engine.png" /&gt;&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;I ran &lt;code&gt;ps aux --sort '%mem'&lt;/code&gt; to see which process takes most memory. Since my server uses a lot of memory, it's at the top. It's using 179MB of resident memory.&lt;/p&gt;
&lt;p&gt;It's pretty nice that you're able to nagivate from a high level system like Kubernetes all the way down to ssh-ing to a machine that runs your containers. When you're ssh-ed you can execute &lt;code&gt;docker ps&lt;/code&gt; to see what containers are running, run &lt;code&gt;top&lt;/code&gt; to see what's going on on the machine and do all of the other systems debugging tasks that you can think of.&lt;/p&gt;
&lt;p&gt;And finally, let's delete our cluster:&lt;/p&gt;
&lt;p&gt;```bash
$ gcloud container clusters delete example-cluster
The following clusters will be deleted.
 - [example-cluster] in [us-central1-b]&lt;/p&gt;
&lt;p&gt;Do you want to continue (Y/n)?  &lt;/p&gt;
&lt;p&gt;Deleting cluster example-cluster...done.                                                                                                                                             &lt;br /&gt;
Deleted [https://container.googleapis.com/v1/projects/mykube-160819/zones/us-central1-b/clusters/example-cluster].
```&lt;/p&gt;
&lt;p&gt;That's all for today - enjoy.&lt;/p&gt;</content></entry><entry><title>Examining a process in Linux.</title><link href="http://pminkov.github.io/blog/examining-a-process-in-linux.html" rel="alternate"></link><published>2017-03-01T12:26:00-08:00</published><updated>2017-03-01T12:26:00-08:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2017-03-01:/blog/examining-a-process-in-linux.html</id><summary type="html">&lt;p&gt;I've been thinking about writing a blog post about Linux tools and commands related to processes. Let's take a look at some of them.&lt;/p&gt;
&lt;p&gt;The process that we'll be looking at is a &lt;a href="https://github.com/pminkov/webserver"&gt;webserver&lt;/a&gt; that I wrote some time ago to practice my C and write some code that does …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've been thinking about writing a blog post about Linux tools and commands related to processes. Let's take a look at some of them.&lt;/p&gt;
&lt;p&gt;The process that we'll be looking at is a &lt;a href="https://github.com/pminkov/webserver"&gt;webserver&lt;/a&gt; that I wrote some time ago to practice my C and write some code that does network related work. This webserver runs a &lt;a href="https://github.com/pminkov/threadpool"&gt;threadpool&lt;/a&gt; where N threads are waiting for server requests that they're going to execute.&lt;/p&gt;
&lt;p&gt;So let's start the server:
&lt;code&gt;bash
$ ./server
Running on port: 8000&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Great. So which process is this server running as? We can use the &lt;code&gt;pidof&lt;/code&gt; command to find that out. Its output looks like this:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
$ pidof server
8876&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;If we had other processes which were running an executable with that name, we'd see more process ids, but since we only have one, we see one process id.&lt;/p&gt;
&lt;p&gt;What next? Let's see how the process is layed out in memory. To do this, we can use the &lt;code&gt;pmap&lt;/code&gt; command. Its output looks like this:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
$ sudo pmap -p 8876
8876:   ./server
0000000000400000     16K r-x-- /home/petko/work/github/webserver/server
0000000000603000      4K r---- /home/petko/work/github/webserver/server
0000000000604000      4K rw--- /home/petko/work/github/webserver/server
000000000110f000    132K rw---   [ anon ]
00007fd5ca731000      4K -----   [ anon ]
00007fd5ca732000   8192K rw---   [ anon ]
00007fd5caf32000      4K -----   [ anon ]
00007fd5caf33000   8192K rw---   [ anon ]
00007fd5cb733000      4K -----   [ anon ]
00007fd5cb734000   8192K rw---   [ anon ]
00007fd5cbf34000      4K -----   [ anon ]
00007fd5cbf35000   8192K rw---   [ anon ]
00007fd5cc735000   1792K r-x-- /lib/x86_64-linux-gnu/libc-2.23.so
00007fd5cc8f5000   2044K ----- /lib/x86_64-linux-gnu/libc-2.23.so
00007fd5ccaf4000     16K r---- /lib/x86_64-linux-gnu/libc-2.23.so
00007fd5ccaf8000      8K rw--- /lib/x86_64-linux-gnu/libc-2.23.so
00007fd5ccafa000     16K rw---   [ anon ]
00007fd5ccafe000     96K r-x-- /lib/x86_64-linux-gnu/libpthread-2.23.so
00007fd5ccb16000   2044K ----- /lib/x86_64-linux-gnu/libpthread-2.23.so
00007fd5ccd15000      4K r---- /lib/x86_64-linux-gnu/libpthread-2.23.so
00007fd5ccd16000      4K rw--- /lib/x86_64-linux-gnu/libpthread-2.23.so
00007fd5ccd17000     16K rw---   [ anon ]
00007fd5ccd1b000    152K r-x-- /lib/x86_64-linux-gnu/ld-2.23.so
00007fd5ccf22000     12K rw---   [ anon ]
00007fd5ccf3e000      8K rw---   [ anon ]
00007fd5ccf40000      4K r---- /lib/x86_64-linux-gnu/ld-2.23.so
00007fd5ccf41000      4K rw--- /lib/x86_64-linux-gnu/ld-2.23.so
00007fd5ccf42000      4K rw---   [ anon ]
00007ffca0861000    132K rw---   [ stack ]
00007ffca09eb000      8K r----   [ anon ]
00007ffca09ed000      8K r-x--   [ anon ]
ffffffffff600000      4K r-x--   [ anon ]
total            39316K&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;What you see here are virtual memory addresses. For example, let's take a look at this line:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;00007fd5cc735000   1792K r-x-- /lib/x86_64-linux-gnu/libc-2.23.so&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This is the code for &lt;code&gt;libc&lt;/code&gt;, which is the C standard library. This code is shared between processes that need it. We can see the &lt;code&gt;x&lt;/code&gt; flag, which means that this is executable memory. The size if roughly the same as the size of this &lt;code&gt;so&lt;/code&gt; file. This library is memory mapped into a region starting at address &lt;code&gt;00007fd5cc735000&lt;/code&gt;, but in physical memory it's only stored in one place. To learn more about memory in Linux, here's a &lt;a href="https://techtalk.intersec.com/2013/07/memory-part-1-memory-types/"&gt;great post&lt;/a&gt; going into detail about it.&lt;/p&gt;
&lt;p&gt;Another interesting command is &lt;code&gt;lsof&lt;/code&gt;. &lt;code&gt;lsof&lt;/code&gt; stands for "list of open files". Let's see its output:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
$ sudo lsof -p 8876
COMMAND  PID  USER   FD   TYPE DEVICE SIZE/OFF    NODE NAME
server  8876 petko  cwd    DIR    8,1     4096  262299 /home/petko/work/github/webserver
server  8876 petko  rtd    DIR    8,1     4096       2 /
server  8876 petko  txt    REG    8,1    25536  306491 /home/petko/work/github/webserver/server
server  8876 petko  mem    REG    8,1  1864888 1184834 /lib/x86_64-linux-gnu/libc-2.23.so
server  8876 petko  mem    REG    8,1   138744 1184980 /lib/x86_64-linux-gnu/libpthread-2.23.so
server  8876 petko  mem    REG    8,1   162632 1184806 /lib/x86_64-linux-gnu/ld-2.23.so
server  8876 petko    0u   CHR  136,9      0t0      12 /dev/pts/9
server  8876 petko    1u   CHR  136,9      0t0      12 /dev/pts/9
server  8876 petko    2u   CHR  136,9      0t0      12 /dev/pts/9
server  8876 petko    3u  IPv4  81993      0t0     TCP *:8000 (LISTEN)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;As you can see, we have file descriptors 0,1 and 2, which are stdin, stdout and stderr. They are linked to the terminal in which the process is running in. You can write to that terminal btw. Just type &lt;code&gt;echo "hello world" &amp;gt; /dev/pts/9&lt;/code&gt; and you'll see that text in the terminal where your webserver is running. File descriptor number 3 is our socket which accepts connections.&lt;/p&gt;
&lt;p&gt;Another interesting way to inspect processes is the ps command. Its basic output looks like this:
&lt;code&gt;bash
$ ps --pid 8876
  PID TTY          TIME CMD
 8876 pts/9    00:00:00 server&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This is simple. We can also show the threads inside a process, like this:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
$ ps  m --pid 8876 -o pid,tid,cmd
  PID   TID CMD
 8876     - ./server
    -  8876 -
    -  8877 -
    -  8878 -
    -  8879 -
    -  8880 -&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;We have five threads here. One is our main thread and the other four are the threadpool threads. The &lt;code&gt;m&lt;/code&gt; option tells ps to show the threads of a process. The &lt;code&gt;-o&lt;/code&gt; option specifies fields to output. We can even get fancy and output the addresses of the threads' stack pointers and instruction pointers, like this:
&lt;code&gt;bash
$ ps  m --pid 8876 -o pid,tid,cmd,esp,eip
  PID   TID CMD                              ESP      EIP
 8876     - ./server                           -        -
    -  8876 -                           a0880b70 ccb0e7ad
    -  8877 -                           cc733ec0 ccb0b3a0
    -  8878 -                           cbf32ec0 ccb0b3a0
    -  8879 -                           cb731ec0 ccb0b3a0
    -  8880 -                           caf30ec0 ccb0b3a0&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;So all the threads are at the same instruction, but they have different stack pointers, which makes sense. If I execute something on one of the threads, both the &lt;code&gt;ESP&lt;/code&gt; and &lt;code&gt;EIP&lt;/code&gt; can possibly change.&lt;/p&gt;
&lt;p&gt;A lot of data about processes lives in the &lt;code&gt;proc&lt;/code&gt; filesytem, located in &lt;code&gt;/proc&lt;/code&gt;. For each running process, there's a subdirectory of &lt;code&gt;/proc&lt;/code&gt; named after the process id. For example, for our process &lt;code&gt;8876&lt;/code&gt;, there's a &lt;code&gt;status&lt;/code&gt; file which lists various information about the process. Let's look at it:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
$ cat /proc/8876/status
Name:   server
State:  S (sleeping)
Tgid:   8876
Ngid:   0
Pid:    8876
PPid:   2604
TracerPid:      0
Uid:    1000    1000    1000    1000
Gid:    1000    1000    1000    1000
FDSize: 256
Groups: 4 24 27 30 46 113 128 999 1000 
NStgid: 8876
NSpid:  8876
NSpgid: 8876
NSsid:  2604
VmPeak:    39316 kB
VmSize:    39316 kB
VmLck:         0 kB
VmPin:         0 kB
VmHWM:       800 kB
VmRSS:       800 kB
VmData:    32988 kB
VmStk:       136 kB
VmExe:        16 kB
VmLib:      2040 kB
VmPTE:        48 kB
VmPMD:        12 kB
VmSwap:        0 kB
HugetlbPages:          0 kB
Threads:        5
SigQ:   0/7848
SigPnd: 0000000000000000
ShdPnd: 0000000000000000
SigBlk: 0000000000000000
SigIgn: 0000000000000000
SigCgt: 0000000180000000
CapInh: 0000000000000000
CapPrm: 0000000000000000
CapEff: 0000000000000000
CapBnd: 0000003fffffffff
CapAmb: 0000000000000000
Seccomp:        0
Cpus_allowed:   1
Cpus_allowed_list:      0
Mems_allowed:   00000000,00000001
Mems_allowed_list:      0
voluntary_ctxt_switches:        3
nonvoluntary_ctxt_switches:     2&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;There's a lot of data in here, but remember how we used &lt;code&gt;ps&lt;/code&gt; to count the number of threads in this process. That's also available here on the line saying &lt;code&gt;Threads:    5&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Our last command is &lt;code&gt;pidstat&lt;/code&gt;. &lt;code&gt;pidstat&lt;/code&gt; shows statistics about a running process, which can be updated at a regular time interval. A possible invocation can be:&lt;/p&gt;
&lt;p&gt;```bash
$ pidstat -p 8876 1
Linux 4.4.0-64-generic (virtbox)        03/01/2017      &lt;em&gt;x86_64&lt;/em&gt;        (1 CPU)&lt;/p&gt;
&lt;p&gt;12:22:00 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
12:22:01 PM  1000      8876    0.00    0.00    0.00    0.00     0  server
12:22:02 PM  1000      8876    0.00    0.00    0.00    0.00     0  server
```&lt;/p&gt;
&lt;p&gt;Our server is not doing anything right now, so you see a lot of zeroes.&lt;/p&gt;
&lt;p&gt;There are many other interesting commands that you can look to figure out what processes are doing. &lt;code&gt;strace&lt;/code&gt; shows system calls run by a process. &lt;code&gt;ltrace&lt;/code&gt; shows dynamic library calls. &lt;code&gt;tcpdump&lt;/code&gt; can be used to show traffic going in and out of a process.&lt;/p&gt;
&lt;p&gt;So, that's all for today. Happy running of processes.&lt;/p&gt;</content></entry><entry><title>The Linux init system.</title><link href="http://pminkov.github.io/blog/the-linux-init-system.html" rel="alternate"></link><published>2017-02-13T21:09:00-08:00</published><updated>2017-02-13T21:09:00-08:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2017-02-13:/blog/the-linux-init-system.html</id><summary type="html">&lt;p&gt;I decided that I'll dig down into &lt;a href="https://en.wikipedia.org/wiki/Init"&gt;init systems&lt;/a&gt; in Linux and learn more about them. I'm running Ubuntu 16.04, so this might look different on other distributions.&lt;/p&gt;
&lt;p&gt;The init system in Linux is mainly responsible for starting essential service processes, mounting file systems and possibly other tasks. The …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I decided that I'll dig down into &lt;a href="https://en.wikipedia.org/wiki/Init"&gt;init systems&lt;/a&gt; in Linux and learn more about them. I'm running Ubuntu 16.04, so this might look different on other distributions.&lt;/p&gt;
&lt;p&gt;The init system in Linux is mainly responsible for starting essential service processes, mounting file systems and possibly other tasks. The main init systems are systemd, System V init and Upstart. Ubuntu uses systemd.&lt;/p&gt;
&lt;p&gt;The init system starts after the Kernel starts its first user space process - init. Indeed, let's see what's running with PID 1:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
$ ps 1
  PID TTY      STAT   TIME COMMAND
    1 ?        Ss     0:04 /sbin/init splash&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;It's &lt;code&gt;/sbin/init&lt;/code&gt;. Let's see what this file is:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
$ ls -l /sbin/init
lrwxrwxrwx 1 root root 20 Sep 28 18:40 /sbin/init -&amp;gt; /lib/systemd/systemd&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;From this output, we can figure out that Ubuntu is using systemd. systemd is a fairly new project (initial release was 6 years ago), but it looks like its widely adopted now. systemd would take care of running various services like your ssh server, your web server and various other ones which are more "under the hood" oriented.&lt;/p&gt;
&lt;p&gt;systemd organizes itself with unit files which contain the description of various units and their dependencies. The units are organized in configuration files, which live in various directories. The main directories are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;System unit directory: &lt;code&gt;/usr/lib/systemd/&lt;/code&gt;. Your distribution maintains this, so don't edit it.&lt;/li&gt;
&lt;li&gt;System configuration directory: &lt;code&gt;/etc/systemd&lt;/code&gt;. Make your local changes here.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Well, these are not all directories that contain unit files. Here's the full set of paths that systemd uses:
&lt;code&gt;bash
$ systemctl -p UnitPath show
UnitPath=/etc/systemd/system /run/systemd/system /run/systemd/generator /usr/local/lib/systemd/system /lib/systemd/system /usr/lib/systemd/system /run/systemd/generator.late&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;I won't go into details about what the unit files contain, but instead look at two services that I was curious about - ssh and apache. Who runs them? When are they run? How can I verify that they are running?&lt;/p&gt;
&lt;p&gt;Let's start with ssh. The main command to interface with systemd is &lt;code&gt;systemctl&lt;/code&gt;. We can use it to list all services that are running, by calling &lt;code&gt;systemctl list-units&lt;/code&gt;. Let's look for ssh in here:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
$ systemctl list-units | grep ssh
ssh.service                                                                              loaded active running   OpenBSD Secure Shell server&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Indeed, we have ssh running. Now, let's look at its status and its config file.&lt;/p&gt;
&lt;p&gt;```bash
$ systemctl status ssh
● ssh.service - OpenBSD Secure Shell server
   Loaded: loaded (/lib/systemd/system/ssh.service; enabled; vendor preset: enabled)
   Active: active (running) since Thu 2017-02-09 19:27:57 PST; 4 days ago
 Main PID: 786 (sshd)
    Tasks: 1
   Memory: 6.4M
      CPU: 199ms
   CGroup: /system.slice/ssh.service
           └─786 /usr/sbin/sshd -D&lt;/p&gt;
&lt;p&gt;Feb 12 18:23:50 virtbox sshd[5791]: Accepted password for petko from 192.168.1.86 port 57805 ssh2
Feb 12 18:23:50 virtbox sshd[5791]: pam_unix(sshd:session): session opened for user petko by (uid=0)
...
```&lt;/p&gt;
&lt;p&gt;So here it is. The ssh service is running as process 786. We can see that this process is listening on port 22:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
$ sudo netstat -tulpn | grep 786
tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      786/sshd        
tcp6       0      0 :::22                   :::*                    LISTEN      786/sshd&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Indeed, it is. &lt;code&gt;systemctl&lt;/code&gt; has another useful command that allows us to print the configuration file for a unit. It works like this:&lt;/p&gt;
&lt;p&gt;```bash
$ systemctl cat ssh&lt;/p&gt;
&lt;h1 id="libsystemdsystemsshservice"&gt;/lib/systemd/system/ssh.service&lt;/h1&gt;
&lt;p&gt;[Unit]
Description=OpenBSD Secure Shell server
After=network.target auditd.service
ConditionPathExists=!/etc/ssh/sshd_not_to_be_run&lt;/p&gt;
&lt;p&gt;[Service]
EnvironmentFile=-/etc/default/ssh
ExecStart=/usr/sbin/sshd -D $SSHD_OPTS
ExecReload=/bin/kill -HUP $MAINPID
KillMode=process
Restart=on-failure
RestartPreventExitStatus=255
Type=notify&lt;/p&gt;
&lt;p&gt;[Install]
WantedBy=multi-user.target
Alias=sshd.service
```&lt;/p&gt;
&lt;p&gt;So here you can see where is the configuration file located.&lt;/p&gt;
&lt;p&gt;Alright, enough ssh. Let's move on to apache. First, a little history though. Before systemd, apparently the main init system in Linux was System V. System V is different than systemd, because it executes services in sequential order, while systemd can be parallel. System V also can't start services on "as-needed" basis. So I guess that's why systemd was implemented. systemd has its config files in &lt;code&gt;/etc/init.d&lt;/code&gt;. That's where Apache installs its command files as well - it doesn't create systemd unit files. However, systemd knows how to execute the System V init files. I won't go into details of how System V init works, but basically it executes commands on different runlevels and at each runlevel they are executed in sequential order.&lt;/p&gt;
&lt;p&gt;Let's see how apache looks like in systemd:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
$ systemctl list-units | grep apache
apache2.service                                                                          loaded active running   LSB: Apache2 web server&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;It's running. Now let's get its status:&lt;/p&gt;
&lt;p&gt;```bash
$ systemctl status apache2
● apache2.service - LSB: Apache2 web server
   Loaded: loaded (/etc/init.d/apache2; bad; vendor preset: enabled)
  Drop-In: /lib/systemd/system/apache2.service.d
           └─apache2-systemd.conf
   Active: active (running) since Mon 2017-02-13 12:49:55 PST; 8h ago
     Docs: man:systemd-sysv-generator(8)
    Tasks: 55
   Memory: 6.5M
      CPU: 17.042s
   CGroup: /system.slice/apache2.service
           ├─9097 /usr/sbin/apache2 -k start
           ├─9100 /usr/sbin/apache2 -k start
           └─9101 /usr/sbin/apache2 -k start&lt;/p&gt;
&lt;p&gt;Feb 13 12:49:54 virtbox systemd[1]: Starting LSB: Apache2 web server...
Feb 13 12:49:54 virtbox apache2[9071]:  * Starting Apache httpd web server apache2
Feb 13 12:49:54 virtbox apache2[9071]: AH00558: apache2: Could not reliably determine the server's fully qualified domain name, using 127.0.1.1. Set the 'ServerName' directive globall
Feb 13 12:49:55 virtbox apache2[9071]:  *
Feb 13 12:49:55 virtbox systemd[1]: Started LSB: Apache2 web server.
```&lt;/p&gt;
&lt;p&gt;Look at something interesting here. The file responsible for starting apache is listed as &lt;code&gt;/etc/init.d/apache2&lt;/code&gt;. That's the file indeed. It's adapted into systemd by using the &lt;code&gt;systemd-sysv-generator&lt;/code&gt;. So that is systemd running. We can run a cat to see that:&lt;/p&gt;
&lt;p&gt;```bash
$ systemctl cat apache2&lt;/p&gt;
&lt;h1 id="runsystemdgeneratorlateapache2service"&gt;/run/systemd/generator.late/apache2.service&lt;/h1&gt;
&lt;h1 id="automatically-generated-by-systemd-sysv-generator"&gt;Automatically generated by systemd-sysv-generator&lt;/h1&gt;
&lt;p&gt;[Unit]
Documentation=man:systemd-sysv-generator(8)
SourcePath=/etc/init.d/apache2
Description=LSB: Apache2 web server
Before=multi-user.target
Before=multi-user.target
Before=multi-user.target
Before=graphical.target
Before=shutdown.target
After=local-fs.target
After=remote-fs.target
After=network-online.target
After=systemd-journald-dev-log.socket
After=nss-lookup.target
Wants=network-online.target
Conflicts=shutdown.target&lt;/p&gt;
&lt;p&gt;[Service]
Type=forking
Restart=no
TimeoutSec=5min
IgnoreSIGPIPE=no
KillMode=process
GuessMainPID=no
RemainAfterExit=yes
ExecStart=/etc/init.d/apache2 start
ExecStop=/etc/init.d/apache2 stop
ExecReload=/etc/init.d/apache2 reload&lt;/p&gt;
&lt;h1 id="libsystemdsystemapache2servicedapache2-systemdconf"&gt;/lib/systemd/system/apache2.service.d/apache2-systemd.conf&lt;/h1&gt;
&lt;p&gt;[Service]
Type=forking
RemainAfterExit=no
```&lt;/p&gt;
&lt;p&gt;This is the file that systemd created in order to integrate the System V init command into its system.&lt;/p&gt;
&lt;p&gt;What are some other interesting systemctl commands? Let's list them:&lt;/p&gt;
&lt;p&gt;```bash&lt;/p&gt;
&lt;h1 id="start-stop-restart-a-service"&gt;Start / stop /restart a service.&lt;/h1&gt;
&lt;p&gt;$ sudo systemctl restart apache2&lt;/p&gt;
&lt;h1 id="list-all-services"&gt;List all services:&lt;/h1&gt;
&lt;p&gt;$ systemctl list-units --type=service&lt;/p&gt;
&lt;h1 id="list-dependencies"&gt;List dependencies:&lt;/h1&gt;
&lt;p&gt;$ systemctl list-dependencies sshd.service&lt;/p&gt;
&lt;h1 id="see-low-level-properties-of-a-unit"&gt;See low level properties of a unit:&lt;/h1&gt;
&lt;p&gt;$ systemctl show sshd.service
```&lt;/p&gt;
&lt;p&gt;And one last cool command:
&lt;code&gt;bash
$ systemd-analyze
Startup finished in 3.989s (kernel) + 7.673s (userspace) = 11.663s&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This command prints the time it took to startup our system.&lt;/p&gt;
&lt;p&gt;So that's all for today. There's definitely more to explore in systemd land - the syntax of unit files, how systemd executes them and so on. I'll leave that for some other time.&lt;/p&gt;</content></entry><entry><title>How to shut down and restore an Elastic Beanstalk environment.</title><link href="http://pminkov.github.io/blog/how-to-shut-down-and-restore-an-elastic-beanstalk-environment.html" rel="alternate"></link><published>2017-01-30T12:07:00-08:00</published><updated>2017-01-30T12:07:00-08:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2017-01-30:/blog/how-to-shut-down-and-restore-an-elastic-beanstalk-environment.html</id><summary type="html">&lt;p&gt;Let's say you're running an &lt;a href="https://aws.amazon.com/elasticbeanstalk/"&gt;Elastic Beanstalk&lt;/a&gt; application. You might want to stop it so that you're not paying money for it. There's one way to do this by running commands. You can use &lt;code&gt;eb terminate&lt;/code&gt; and &lt;code&gt;eb restore&lt;/code&gt;, but if you terminate a setup with a database and you …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Let's say you're running an &lt;a href="https://aws.amazon.com/elasticbeanstalk/"&gt;Elastic Beanstalk&lt;/a&gt; application. You might want to stop it so that you're not paying money for it. There's one way to do this by running commands. You can use &lt;code&gt;eb terminate&lt;/code&gt; and &lt;code&gt;eb restore&lt;/code&gt;, but if you terminate a setup with a database and you restore it, the contents of the database won't be restored. You can also only restore an environment that has been terminated within the last 6 weeks.&lt;/p&gt;
&lt;p&gt;Let's see how we can terminate and restore without the 6 weeks restriction and let's also see how does the database backup and restore look like.&lt;/p&gt;
&lt;p&gt;The first thing that you have to do is to save your environment, which pretty much consists of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Elastic Beanstalk &lt;a href="http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/environment-configuration-savedconfig.html"&gt;configuration&lt;/a&gt;. This is located in the &lt;code&gt;.elasticbeanstalk&lt;/code&gt; directory.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/ebextensions.html"&gt;Environment customizations&lt;/a&gt;. They're located in the &lt;code&gt;.ebextensions&lt;/code&gt; directory.&lt;/li&gt;
&lt;li&gt;Your source code. Located in your base directory.&lt;/li&gt;
&lt;li&gt;A database (optional).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;My particular app is a single instance Python/Django application with a MySQL database hosted in RDS.&lt;/p&gt;
&lt;p&gt;So let's get started.&lt;/p&gt;
&lt;h2 id="backing-up-your-environment"&gt;Backing up your environment.&lt;/h2&gt;
&lt;p&gt;First, get the name of your environment. Mine is &lt;code&gt;neatlinks-dev&lt;/code&gt;. Run the following commands after that:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;``bash
export EB_DATE_LABEL=&lt;/code&gt;date +"D%F-T%H-%M-%S"`&lt;/p&gt;
&lt;h1 id="name-of-saved-config"&gt;Name of saved config.&lt;/h1&gt;
&lt;p&gt;export EB_CONFIG=saved-$EB_DATE_LABEL&lt;/p&gt;
&lt;h1 id="name-of-database-snapshot"&gt;Name of database snapshot.&lt;/h1&gt;
&lt;p&gt;export EB_SNAPSHOT_NAME=snapshot-$EB_DATE_LABEL&lt;/p&gt;
&lt;h1 id="instance-id-for-our-current-database"&gt;Instance id for our current database.&lt;/h1&gt;
&lt;p&gt;export EB_DB="aaeag9ndvxonft"&lt;/p&gt;
&lt;h1 id="save-the-environment-cname-well-need-it-later"&gt;Save the environment cname, we'll need it later.&lt;/h1&gt;
&lt;p&gt;export EB_CNAME='neatlinks-dev-www'&lt;/p&gt;
&lt;h1 id="save-current-config"&gt;Save current config.&lt;/h1&gt;
&lt;p&gt;eb config save neatlinks-dev --cfg $EB_CONFIG&lt;/p&gt;
&lt;h1 id="create-and-wait-for-database-snapshot"&gt;Create and wait for database snapshot.&lt;/h1&gt;
&lt;p&gt;aws rds create-db-snapshot \
    --db-instance-identifier $EB_DB \
    --db-snapshot-identifier $EB_SNAPSHOT_NAME
time aws rds wait db-snapshot-completed \
    --db-instance-identifier $EB_DB \
    --db-snapshot-identifier $EB_SNAPSHOT_NAME
```&lt;/p&gt;
&lt;p&gt;So we did two things:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;We saved the environment configuration. You can list your saved configurations by running &lt;code&gt;eb config list&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;We created a snapshot of the database.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;At this point we can terminate our environment by calling &lt;code&gt;eb terminate&lt;/code&gt;. And that's it - Amazon is not charging you anymore - your EC2 instance, RDS instance, load balancers, etc. are down. I don't have a load balancer, but I can verify that everything else is gone.&lt;/p&gt;
&lt;p&gt;You should now commit your configs to your source control so that you have them saved when you come back.&lt;/p&gt;
&lt;p&gt;Now, your application is sitting safely saved for a while and you decide to restore it.&lt;/p&gt;
&lt;h2 id="restoring-your-environment"&gt;Restoring your environment.&lt;/h2&gt;
&lt;p&gt;If you have deleted your application, you'll need to run &lt;code&gt;eb init&lt;/code&gt;. After that, we'll run the following commands:&lt;/p&gt;
&lt;p&gt;```bash&lt;/p&gt;
&lt;h1 id="create-environment-its-important-to-specify-a-cname-so-that-we-dont-have-to"&gt;Create environment. It's important to specify a cname, so that we don't have to&lt;/h1&gt;
&lt;h1 id="change-our-dns-config-this-takes-a-lot-of-time-so-i-bump-the-timeout"&gt;change our DNS config. This takes a lot of time, so I bump the timeout.&lt;/h1&gt;
&lt;h1 id="this-command-will-print-the-name-of-your-new-database-instance"&gt;This command will print the name of your new database instance.&lt;/h1&gt;
&lt;p&gt;time eb create neatlinks-dev --cfg $EB_CONFIG --cname $EB_CNAME --timeout 30&lt;/p&gt;
&lt;h1 id="get-this-id-from-the-printed-output-of-eb-create"&gt;Get this id from the printed output of "eb create".&lt;/h1&gt;
&lt;p&gt;export EB_NEW_DB="aa1q3no37rzd407"&lt;/p&gt;
&lt;h1 id="delete-db-instance-well-replace-it-with-the-snapshot"&gt;Delete DB instance. We'll replace it with the snapshot.&lt;/h1&gt;
&lt;p&gt;aws rds delete-db-instance --db-instance-identifier $EB_NEW_DB --skip-final-snapshot
aws rds wait db-instance-deleted --db-instance-identifier $EB_NEW_DB&lt;/p&gt;
&lt;h1 id="restore-from-snapshot"&gt;Restore from snapshot.&lt;/h1&gt;
&lt;p&gt;aws rds restore-db-instance-from-db-snapshot \
        --db-instance-identifier $EB_NEW_DB \
        --db-snapshot-identifier $EB_SNAPSHOT_NAME
aws rds wait db-instance-available --db-instance-identifier $EB_NEW_DB
```&lt;/p&gt;
&lt;p&gt;Your production setup is ready now! Your application probably won't work though, because your DB endpoint is different. Edit your source code or your own configuration files so that your application connects to the new database. Once done, call &lt;code&gt;eb deploy&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;That's it. Your application should be running now. You can use this procedure to rename your Elastic Beanstalk application and environment as well, which is a feature that's missing from the &lt;code&gt;eb&lt;/code&gt; CLI app.&lt;/p&gt;</content></entry><entry><title>What happens when you run out of memory in Linux?</title><link href="http://pminkov.github.io/blog/what-happens-when-you-run-out-of-memory-in-linux.html" rel="alternate"></link><published>2017-01-15T12:50:00-08:00</published><updated>2017-01-15T12:50:00-08:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2017-01-15:/blog/what-happens-when-you-run-out-of-memory-in-linux.html</id><summary type="html">&lt;p&gt;I've always been curious to figure out what happens when you run out of memory in Linux and recently I was experimenting with something that helped me figure it out. &lt;/p&gt;
&lt;p&gt;I was trying out &lt;a href="http://dhbox.org/"&gt;dhbox&lt;/a&gt; deployment on an EC2 machine. dhbox allows you to start a virtual environment in which …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've always been curious to figure out what happens when you run out of memory in Linux and recently I was experimenting with something that helped me figure it out. &lt;/p&gt;
&lt;p&gt;I was trying out &lt;a href="http://dhbox.org/"&gt;dhbox&lt;/a&gt; deployment on an EC2 machine. dhbox allows you to start a virtual environment in which you can try out various data science tools. These virtual environments are run on Docker containers. These Docker containers take a lot of memory, so you can't run too many on a single machine. So far so good. But let's see what actually happens.&lt;/p&gt;
&lt;p&gt;Before we start, &lt;a href="http://techblog.netflix.com/2015/11/linux-performance-analysis-in-60s.html"&gt;here&lt;/a&gt; is a great document from the Netflix Eng blog that describes the tools that can be used to debug a slow Linux box. &lt;/p&gt;
&lt;p&gt;I deployed DHBox on an Ubuntu image in EC2 with 1GB of memory and no swap file. Yes, no swap file. Why? It seems like that's done, because having a swap file might incur a lot of EBS IO, which leads to high pricing. But still, this makes for an interesting debugging scenario, so let's continue.&lt;/p&gt;
&lt;p&gt;Here's what our free memory situation is in the beginnging:
&lt;code&gt;bash
$ free -m
              total        used        free      shared  buff/cache   available
Mem:            990          78         518           4         392         867
Swap:             0           0           0&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Notice how we have 392MB in "buff/cache". What is this? &lt;a href="http://www.tldp.org/LDP/sag/html/buffer-cache.html"&gt;Here&lt;/a&gt; is a good explanation of it. The buffer cache is caching (in RAM) data that's on disk. For example, the "ls" command, or the glibc library are things that are often used and are good candidates for caching.&lt;/p&gt;
&lt;p&gt;The first thing I do is to start the Python web app for DHBox. It's a simple Flask app running on &lt;a href="http://gunicorn.org/"&gt;gunicorn&lt;/a&gt;. After I start it, this is what &lt;code&gt;free&lt;/code&gt; is showing:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
$ free -m
              total        used        free      shared  buff/cache   available
Mem:            990         127         453           4         410         818
Swap:             0           0           0&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Reasonable. We are using a bit more memory, we have cached a bit more data from disk.&lt;/p&gt;
&lt;p&gt;Now, I'll start running vmstat and run four virtual labs. This seems to be enough to take 1GB of memory and pretty much bring down the machine. One other tool we're going to use is &lt;code&gt;vmstat&lt;/code&gt;. &lt;code&gt;vmstat&lt;/code&gt; is great, it's outputting a lot of useful information. Let's see how it looks like before we start running the Docker containers:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
$ vmstat 5
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0      0 463880  51328 369012    0    0   635    32   94  231  2  1 95  1  1
 0  0      0 463356  51336 369044    0    0     0     2   36   68  0  0 100  0  0
 0  0      0 462884  51372 369116    0    0    14     2   46   69  1  0 99  0  0
 0  0      0 462380  51372 369116    0    0     0     0   43  101  0  0 100  0  0&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The telling part here is the &lt;code&gt;id&lt;/code&gt; column. That's the percentage which the CPU spends being idle. As you can see, the CPU is pretty idle. Not much to do.&lt;/p&gt;
&lt;p&gt;We're then starting the first Docker container. Things spike up for a while. Let's observe vmstat:&lt;/p&gt;
&lt;p&gt;```bash
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0      0 462380  51372 369116    0    0     0     0   43  101  0  0 100  0  0&lt;/p&gt;
&lt;h1 id="heres-when-we-start-the-docker-container"&gt;Here's when we start the Docker container.&lt;/h1&gt;
&lt;p&gt;2  0      0 185252  56072 497736    0    0  9159  8016 2126 7829 22 14 43 21  0
 1  0      0  95416  56576 525740    0    0  1924  1036  396 1467 51 13 30  7  0
 1  0      0 147764  56616 527408    0    0   336   630  117  307  1  1 96  1  0
 0  0      0  65604  56664 537452    0    0     0    82   81  494  3  3 94  0  0
 0  0      0  65556  56676 537500    0    0     0    59   59  181  0  0 99  1  0
 0  0      0  65524  56684 537504    0    0     0    58   56  179  0  0 99  1  0
 0  0      0  65400  56692 537552    0    0     0  4928  138  231  0  0 98  2  0
 0  0      0  65400  56700 537552    0    0     0  3187  107  201  0  0 98  2  0
```&lt;/p&gt;
&lt;p&gt;Interesting. As you can see the &lt;code&gt;id&lt;/code&gt; column value decreases. Less idleness, we're starting things. But after a while, the Docker container has started and we're back to things being quiet.&lt;/p&gt;
&lt;p&gt;Let's see what &lt;code&gt;free&lt;/code&gt; is saying:
&lt;code&gt;bash
$ free -m
              total        used        free      shared  buff/cache   available
Mem:            990         350          59          10         580         569
Swap:             0           0           0&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;So, &lt;code&gt;used&lt;/code&gt; went up from 127MB to 350MB. The buffer cache also went up. Less available memory.&lt;/p&gt;
&lt;p&gt;Let's start the second Docker container. We're looking at vmstat again.
```bash
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0      0  61304  56740 537872    0    0     0    56   83  227  0  0 99  1  0&lt;/p&gt;
&lt;h1 id="starting-second-container-here"&gt;Starting second container here.&lt;/h1&gt;
&lt;p&gt;1  1      0 126516  59292 341252    0    0  7109  8100  823 3255 22 15 56  6  0
 1  0      0  47572  59904 337152    0    0  9186  7515  882 2316 51 13 17 19  0
 0  1      0 153212  59940 307720    0    0  1094  2122  214  557  2  3 92  3  0
 0  0      0  92848  59996 303368    0    0   556   149  147  690  2  3 93  1  0
 0  0      0  92848  60004 303368    0    0     0   108   91  311  0  0 99  0  0
 0  0      0  92724  60012 303376    0    0     0   102   94  326  0  0 98  1  0
 0  0      0  88296  60028 305048    0    0   320   102  147  424  2  1 96  2  0
 0  0      0  77228  60364 314520    0    0  1876   144  306  868 28  4 64  4  0
 0  0      0  86800  60372 304968    0    0    26   387  111  372  1  1 97  1  0
 0  0      0  86032  60780 305120    0    0   110   119  150  399  0  0 98  2  0
```&lt;/p&gt;
&lt;p&gt;Similar situation. A spike in io, a spike in non-idle CPU percentage, followed by quiet. Let's look at &lt;code&gt;free&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
$ free -m
              total        used        free      shared  buff/cache   available
Mem:            990         549          84          17         356         371
Swap:             0           0&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;More used memory. But notice how this time the &lt;code&gt;buff/cache&lt;/code&gt; section went down. Why? Well, because our running processes are using more memory and this memory has to come from somewhere. The kernel is freeing memory from the buffer cache and giving it to processes. Again, reasonable behavior.&lt;/p&gt;
&lt;p&gt;Let's start the third and fourth Docker containers and see how &lt;code&gt;vmstat&lt;/code&gt; looks after that.&lt;/p&gt;
&lt;p&gt;```bash
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0      0  46052  11188 160564    0    0     0   151  153  532  0  1 97  2  0
 0  0      0  39828  11336 166664    0    0  1246   141  235  634  1  1 95  4  0
 0  0      0  39704  11344 166664    0    0     0   149  158  542  0  1 97  2  0&lt;/p&gt;
&lt;h1 id="after-we-start-the-fourth-container"&gt;After we start the fourth container.&lt;/h1&gt;
&lt;p&gt;6  3      0  18840  11668 179484    0    0 18678  7726 2711 7721  5  8 46 41  0
 1  4      0   8964   2796 103108    0    0 38137  2508 4198 4872 37 21  0 41  1
 0 11      0   9576    588 101548    0    0 68988   485 4097 6006  1 10  0 88  0
 0  8      0   9352    152 100752    0    0 67797   250 2463 4497  0  8  0 90  1&lt;/p&gt;
&lt;p&gt;....&lt;/p&gt;
&lt;p&gt;1 18      0   9508    248 100560    0    0 63568   138 1700 3935  0  8  0 91  1
 0 14      0   8656    400 100436    0    0 63154    68 1580 3766  0  8  0 91  1
 0 19      0   8852    288 100552    0    0 63711   128 1606 3705  0  8  0 92  1
 1 47      0  10232    372  98616    0    0 63410    94 1720 4316  0  7  0 91  1
 2 50      0   9648    420  99604    0    0 63126    77 1696 4425  0  8  0 91  1
 0 40      0  10028    272  99432    0    0 63692    74 1681 4506  0  7  0 91  1
 0 75      0   9944    160  98220    0    0 63342    59 1724 5150  0 10  0 89  1
 3 34      0   8952    296 100400    0    0 63575   110 1958 4663  0  8  0 91  1
 1  5      0   9004   1716 117640    0    0 62704   123 2674 5329  3  9  0 88  1
```&lt;/p&gt;
&lt;p&gt;This is where things start to get bad! The box becomes very unresponsive. Typing a simple command like &lt;code&gt;ls&lt;/code&gt; takes seconds to execute. Let's take a peek at &lt;code&gt;free&lt;/code&gt; and we'll continue to our analysis after that:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
$ free -m
              total        used        free      shared  buff/cache   available
Mem:            990         851          20          24         119          54
Swap:             0           0           0&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;As you can see, we barely have any free memory and the buffer cache has shrunk even more. But notice what's going on in &lt;code&gt;vmstat&lt;/code&gt;. The &lt;code&gt;bi&lt;/code&gt; (blocks received from a block device) is stuck at a constant high value. This means we're doing a lot of disk reads. Why is that, are our processes doing a lot of disk operations? No. Our many processes are executables that are located on disk. When the kernel executes them, it has to read instructions. If we have enough buffer cache, we can store these instruction in memory and not have to read them again. However, our buffer cache is small now. So when processes run, the kernel needs to pull their instructions from disk. It probably stores them in the buffer cache, but when the next process is running, it tries to store in the cache again and evicts what's stored from the old process. &lt;/p&gt;
&lt;p&gt;Are we done? Not yet. When this whole sad mess happens, the kernel will run something called &lt;a href="https://linux-mm.org/OOM_Killer"&gt;OOM killer&lt;/a&gt;. How do we know this is what's going on? We can use &lt;code&gt;dmesg&lt;/code&gt; and view the system messages:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
$ dmesg | grep "Out of memory"
[ 3635.537538] Out of memory: Kill process 21580 (jupyter-noteboo) score 37 or sacrifice child
[ 3636.822607] Out of memory: Kill process 22714 (jupyter-noteboo) score 37 or sacrifice child
[ 3643.006328] Out of memory: Kill process 24976 (jupyter-noteboo) score 37 or sacrifice child
[ 3654.916468] Out of memory: Kill process 26118 (jupyter-noteboo) score 37 or sacrifice child
[ 3658.712286] Out of memory: Kill process 28364 (jupyter-noteboo) score 35 or sacrifice child
[ 3666.654763] Out of memory: Kill process 30603 (jupyter-noteboo) score 36 or sacrifice child
[ 3685.390829] Out of memory: Kill process 30620 (jupyter-noteboo) score 36 or sacrifice child&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The strange thing here is that it keeps killing these &lt;a href="http://jupyter.org/"&gt;Jupyter&lt;/a&gt; processes for a long time. My guess here is that something restarts them after they're killed.&lt;/p&gt;
&lt;p&gt;The best thing to do here is to simply kill all the running Docker containers so that the box is usable again:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;bash
docker kill $(docker ps -q)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Things would look different if there was a swap partition on the disk. I might try such a setup as well. If you think about it, the swap would allow some of the memory used by processes to be transferred to disk. That's a great win, because some parts of memory might be very rarely if at all accessed. However, without a swap, there's no such option.&lt;/p&gt;</content></entry><entry><title>The Cloud Infrastructure Landscape</title><link href="http://pminkov.github.io/blog/the-cloud-infrastructure-landscape.html" rel="alternate"></link><published>2017-01-15T12:10:00-08:00</published><updated>2017-01-15T12:10:00-08:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2017-01-15:/blog/the-cloud-infrastructure-landscape.html</id><summary type="html">&lt;p&gt;I'm taking a &lt;a href="https://www.edx.org/course/introduction-cloud-infrastructure-linuxfoundationx-lfs151-x"&gt;Cloud Infrastructure&lt;/a&gt; class on EdX and I have found it to be a really nice overview of the cloud space. It's missing anything related to Hadoop and data analytics, but it describes probably all the tools related to running applications in the cloud. Of course, since the …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I'm taking a &lt;a href="https://www.edx.org/course/introduction-cloud-infrastructure-linuxfoundationx-lfs151-x"&gt;Cloud Infrastructure&lt;/a&gt; class on EdX and I have found it to be a really nice overview of the cloud space. It's missing anything related to Hadoop and data analytics, but it describes probably all the tools related to running applications in the cloud. Of course, since the class describes so many tools, it can't do so in depth, but you can pick whatever is interesting to you and learn more about it.&lt;/p&gt;
&lt;p&gt;Here's a list of all the tools described in it, which list I might use as a future reference for myself. I'd say that knowing a bit about such a big amount of products definitely helps when you're trying to come up with a cloud infrastructure for a project.&lt;/p&gt;
&lt;p&gt;So, big list, based on the course contents:&lt;/p&gt;
&lt;h3 id="virtualization"&gt;Virtualization&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://www.linux-kvm.org/page/Main_Page"&gt;KVM&lt;/a&gt;&lt;br&gt;
&lt;a href="https://www.virtualbox.org/wiki/VirtualBox"&gt;VirtualBox&lt;/a&gt;&lt;br&gt;
&lt;a href="https://www.vagrantup.com/"&gt;Vagrant&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;I use VirtualBox to run Linux on Mac OS X and highly recommend it. Mac OS X is not good if you're trying to learn Linux, too many differences.&lt;/p&gt;
&lt;h3 id="infrastructure-as-a-service-iaas"&gt;Infrastructure as a Service (IaaS)&lt;br&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://aws.amazon.com/ec2/"&gt;Amazon EC2&lt;/a&gt;&lt;br&gt;
&lt;a href="https://azure.microsoft.com/en-us/services/virtual-machines/?b=16.51a"&gt;Azure Virtual Machines&lt;/a&gt;&lt;br&gt;
&lt;a href="https://www.digitalocean.com/"&gt;Digital Ocean&lt;/a&gt;&lt;br&gt;
&lt;a href="https://cloud.google.com/compute/"&gt;Google Compute Engine&lt;/a&gt;&lt;br&gt;
&lt;a href="https://www.openstack.org/"&gt;OpenStack&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;I've only tried EC2 out of these, but it's pretty simple and I like the fact that you can do so many things through the UI, it makes it easier to start with it.&lt;/p&gt;
&lt;h3 id="platform-as-a-sevice-paas"&gt;Platform as a Sevice (PaaS)&lt;br&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://www.cloudfoundry.org/learn/features/"&gt;Cloud Foundry&lt;/a&gt;&lt;br&gt;
&lt;a href="https://www.openshift.com/"&gt;OpenShift&lt;/a&gt;&lt;br&gt;
&lt;a href="https://www.heroku.com/"&gt;Heroku&lt;/a&gt;&lt;br&gt;
&lt;a href="https://deis.com/"&gt;Deis&lt;/a&gt;&lt;br&gt;
&lt;a href="https://aws.amazon.com/elasticbeanstalk/"&gt;AWS Elastic Beanstalk&lt;/a&gt; (my addition)&lt;br&gt;&lt;/p&gt;
&lt;p&gt;I've used Elastic Beanstalk and it's a good way to abstract configuration of load balancers, Apache instances and so on.&lt;/p&gt;
&lt;h3 id="containers"&gt;Containers&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://linuxcontainers.org/"&gt;LXC (Linux Containers)&lt;/a&gt;&lt;br&gt;
&lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Docker is the leader here. I'm surprised that companies like Google or VMWare haven't come up with their own solution. Maybe soon.&lt;/p&gt;
&lt;h3 id="micro-oses-for-containers"&gt;Micro OSes for Containers&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://www.projectatomic.io/"&gt;Atomic Host&lt;/a&gt;&lt;br&gt;
&lt;a href="https://www.coreos.com/"&gt;CoreOS&lt;/a&gt;&lt;br&gt;
&lt;a href="https://vmware.github.io/photon/"&gt;VMWare Photon&lt;/a&gt;&lt;br&gt;
&lt;a href="http://rancher.com/rancher-os/"&gt;RancherOS&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Pretty neat concept of building a minimal OS that's targeted towards running containers.&lt;/p&gt;
&lt;h3 id="container-orchestration"&gt;Container Orchestration&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://www.docker.com/products/docker-swarm"&gt;Docker Swarm&lt;/a&gt;&lt;br&gt;
&lt;a href="https://kubernetes.io/"&gt;Kubernetes&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id="unikernels"&gt;Unikernels&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/emc-advanced-dev/unik"&gt;Unik&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id="container-as-a-service-caas"&gt;Container as a Service (CaaS)&lt;br&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://www.docker.com/products/docker-datacenter"&gt;Docker Datacenter&lt;/a&gt;&lt;br&gt;
&lt;a href="https://wiki.openstack.org/wiki/Magnum"&gt;Project Magnum on OpenStack&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id="software-defined-storage-and-storage-management-for-containers"&gt;Software Defined Storage and Storage Management for Containers&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://ceph.com/"&gt;Ceph&lt;/a&gt;&lt;br&gt;
&lt;a href="https://www.gluster.org/"&gt;Gluster&lt;/a&gt;&lt;br&gt;
&lt;a href="https://storpool.com/"&gt;StorPool&lt;/a&gt; (My addition)&lt;br&gt; &lt;/p&gt;
&lt;h3 id="continuous-integration-continuous-delivery"&gt;Continuous Integration / Continuous Delivery&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://jenkins.io/"&gt;Jenkins&lt;/a&gt;&lt;br&gt;
&lt;a href="https://drone.io/"&gt;Drone&lt;/a&gt;&lt;br&gt;
&lt;a href="https://travis-ci.com/getting_started"&gt;Travis CI&lt;/a&gt;&lt;br&gt;
&lt;a href="https://app.shippable.com/"&gt;Shippable&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;These are very easy to try out if you have projects on GitHub. Here's &lt;a href="https://github.com/pminkov/webserver"&gt;one&lt;/a&gt; on which I slapped the Drone badge.&lt;/p&gt;
&lt;h3 id="tools-for-configuration-management"&gt;Tools for Configuration Management&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://www.ansible.com/"&gt;Ansible&lt;/a&gt;&lt;br&gt;
&lt;a href="https://puppet.com/"&gt;Puppet&lt;/a&gt;&lt;br&gt;
&lt;a href="https://docs.saltstack.com/en/latest/"&gt;SaltStack&lt;/a&gt;&lt;br&gt;
&lt;a href="https://www.chef.io/"&gt;Chef&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Useful tools for running commands on multiple servers.&lt;/p&gt;
&lt;h3 id="build-and-release-tools"&gt;Build and Release Tools&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://www.terraform.io/docs/providers/"&gt;Terraform&lt;/a&gt;&lt;br&gt;
&lt;a href="https://bosh.io"&gt;BOSH&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id="key-value-pair-stores"&gt;Key-Value Pair Stores&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://coreos.com/etcd/"&gt;etcd&lt;/a&gt;&lt;br&gt;
&lt;a href="https://www.consul.io/"&gt;Consul&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id="building-images"&gt;Building Images&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://www.packer.io/"&gt;Packer&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Pretty neat. Just describe your instance and build a VM / Amazon image / Docker container. I can see that being pretty useful when you're building AMIs for AWS. Better than building it manually and not being able to reproduce it on another platform.&lt;/p&gt;
&lt;h3 id="debugging-logging-monitoring"&gt;Debugging, Logging, Monitoring&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://www.sysdig.com/"&gt;Sysdig&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/google/cadvisor"&gt;cAdvisor&lt;/a&gt;&lt;br&gt;
&lt;a href="http://www.fluentd.org/"&gt;Fluentd&lt;/a&gt;&lt;br&gt;
&lt;a href="https://www.datadoghq.com/"&gt;Datadog&lt;/a&gt;&lt;br&gt;&lt;/p&gt;</content></entry><entry><title>How to install collectd on Ubuntu.</title><link href="http://pminkov.github.io/blog/how-to-install-collectd-on-ubuntu.html" rel="alternate"></link><published>2017-01-05T14:46:00-08:00</published><updated>2017-01-05T14:46:00-08:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2017-01-05:/blog/how-to-install-collectd-on-ubuntu.html</id><summary type="html">&lt;p&gt;Some time ago I found out about &lt;a href="https://collectd.org/"&gt;collectd&lt;/a&gt; and I was curious to see what it does. collectd collects statistics about the machine its running on - cpu, disk, memory, processes, battery, etc. &lt;/p&gt;
&lt;p&gt;Here's how to install it on Ubuntu and visualize the data it has collected.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id="step-1-install-the-collectd-package"&gt;Step 1: Install the …&lt;/h3&gt;</summary><content type="html">&lt;p&gt;Some time ago I found out about &lt;a href="https://collectd.org/"&gt;collectd&lt;/a&gt; and I was curious to see what it does. collectd collects statistics about the machine its running on - cpu, disk, memory, processes, battery, etc. &lt;/p&gt;
&lt;p&gt;Here's how to install it on Ubuntu and visualize the data it has collected.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id="step-1-install-the-collectd-package"&gt;Step 1: Install the collectd package.&lt;/h3&gt;
&lt;p&gt;Easy, just install the package:&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sudo apt-get install collectd&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id="step-2-make-sure-collectd-and-apache-are-running"&gt;Step 2: Make sure collectd and apache are running.&lt;/h3&gt;
&lt;p&gt;If you have installed apache, you should have both collectd and apache running
&lt;code&gt;bash
$ sudo service --status-all | egrep "collectd|apache2"
 [ + ]  apache2
 [ + ]  collectd&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;If collectd is not running, run &lt;code&gt;sudo service collectd start&lt;/code&gt;. For me at least, it was running after installation.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id="step-3-install-collectds-web-app-for-generating-graphs"&gt;Step 3: Install collectd's web app for generating graphs.&lt;/h3&gt;
&lt;p&gt;Ok, now we have collectd running. collectd is mostly about collecting data and it allows other frontends to display it. However, it comes with a simple set of cgi scripts that can be used to see some graphs.&lt;/p&gt;
&lt;p&gt;In the &lt;code&gt;/usr/share/doc/collectd/examples/&lt;/code&gt; directory, you'll find a directory named &lt;code&gt;collection3&lt;/code&gt;. Copy the entire directory to &lt;code&gt;/var/www/html&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$ sudo cp -r ./collection3 /var/www/html&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id="step-4-enable-apache-to-run-cgi-scripts"&gt;Step 4: Enable apache to run CGI scripts.&lt;/h3&gt;
&lt;p&gt;Great, you can now access the cgi scripts by going to this url: &lt;code&gt;http://localhost/collection3/bin/index.cgi&lt;/code&gt;. However, you'll be served a text file, since apache doesn't know to run these cgi scripts. There's is a &lt;a href="http://httpd.apache.org/docs/2.2/howto/cgi.html"&gt;simple manual&lt;/a&gt; explaining cgi scripts in Apache.&lt;/p&gt;
&lt;p&gt;You'll have to do two things.&lt;/p&gt;
&lt;p&gt;First, you need to install the cgi module. So, go to &lt;code&gt;/etc/apache2/mods-enabled&lt;/code&gt; and run this: &lt;code&gt;$ sudo ln -s ../mods-available/cgi.load&lt;/code&gt;. You have now enabled the &lt;code&gt;cgi&lt;/code&gt; module.&lt;/p&gt;
&lt;p&gt;Next you'll have to change &lt;code&gt;apache2.conf&lt;/code&gt;, located in &lt;code&gt;/etc/apache2&lt;/code&gt; (Ubuntu doesn't use &lt;code&gt;httpd.conf&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;Add these lines to it:
&lt;code&gt;text
&amp;lt;Directory /var/www/&amp;gt;
        Options +ExecCGI
        AddHandler cgi-script .cgi
&amp;lt;/Directory&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;And - you're done! If you go to &lt;code&gt;http://localhost/cgi-bin/collection3/bin/index.cgi&lt;/code&gt;, you should see some graphs.&lt;/p&gt;</content></entry><entry><title>Thoughts on C programming.</title><link href="http://pminkov.github.io/blog/thoughts-on-c-programming.html" rel="alternate"></link><published>2017-01-01T17:58:00-08:00</published><updated>2017-01-01T17:58:00-08:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2017-01-01:/blog/thoughts-on-c-programming.html</id><summary type="html">&lt;p&gt;I recently wrote a &lt;a href="https://github.com/pminkov/webserver"&gt;webserver&lt;/a&gt; in C and wanted to share my thoughts on writing code in C. This was practically my first somewhat substantial C project. I've had two jobs in which I was writing C++, but I never programmed in C.&lt;/p&gt;
&lt;p&gt;So, in no particular order, here are …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I recently wrote a &lt;a href="https://github.com/pminkov/webserver"&gt;webserver&lt;/a&gt; in C and wanted to share my thoughts on writing code in C. This was practically my first somewhat substantial C project. I've had two jobs in which I was writing C++, but I never programmed in C.&lt;/p&gt;
&lt;p&gt;So, in no particular order, here are my thoughts on C.
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h3 id="the-language-is-simple"&gt;The language is simple.&lt;/h3&gt;
&lt;p&gt;C is a pretty simple language. Unlike complicated languages like Scala, C has a very limited set of language features. There's a good side to that - you can start faster with C and I appreciate the simplicity coming from working with a more limited language. On the other hand, you have to write more code to do certain things.
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h3 id="lack-of-object-oriented-programming-makes-writing-code-more-difficult"&gt;Lack of object oriented programming makes writing code more difficult.&lt;/h3&gt;
&lt;p&gt;It's difficult to organize code when you don't have classes. It seems like your option is to just put pieces of code in separate files if you want to do that. But then, function names will still have to be different. So you end up with a lot of functions containing the name of the type they're supposed to operate on, like maybe &lt;code&gt;add_to_tree&lt;/code&gt; and then &lt;code&gt;remove_from_tree&lt;/code&gt; instead of simple &lt;code&gt;add&lt;/code&gt; and &lt;code&gt;remove&lt;/code&gt; methods on a &lt;code&gt;Tree&lt;/code&gt; class.
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h3 id="not-knowing-the-size-of-arrays-and-strings-in-advance-is-difficult"&gt;Not knowing the size of arrays and strings in advance is difficult.&lt;/h3&gt;
&lt;p&gt;Unlike C++, C doesn't have its STL library, so if you're allocating arrays or strings, you often have to know their size in advance. Imagine running a process with &lt;code&gt;popen&lt;/code&gt; and having to store its output to a string. You can't know the size of the output in advance, so you have to allocate a buffer of a certain size, expecting it to be big enough in all cases. That's of course impossible, so you'll need to code your own variable size string.&lt;/p&gt;
&lt;p&gt;C library functions are also not immune to this problem. For example, the &lt;code&gt;getcwd&lt;/code&gt; is a function that gets the current working directory. It receives a buffer of a certain size and writes the directory name to it. If the buffer is smaller than the directory name, the function will return NULL.&lt;/p&gt;
&lt;p&gt;Luckily, in a lot of cases, you'd know the size of the data in advance, but writing code that has to do with strings and arrays is still more difficult than just using a STL &lt;code&gt;vector&lt;/code&gt; or a &lt;code&gt;stack&lt;/code&gt;.
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h3 id="you-have-to-be-meticulous-in-checking-return-codes-of-standard-library-functions"&gt;You have to be meticulous in checking return codes of standard library functions.&lt;/h3&gt;
&lt;p&gt;Most of the functions in the C standard library return something that indicates the success or failure of the function. Unlike languages that have exceptions, if you don't check the return values, it's entirely possible that your code will continue to execute and ignore some errors. Since often times you'll find yourself thinking "I doubt this can fail", writing good C code requires an extra level of discipline.&lt;/p&gt;</content></entry><entry><title>How to fix order-violation bugs with condition variables.</title><link href="http://pminkov.github.io/blog/how-to-fix-order-violation-bugs-with-condition-variables.html" rel="alternate"></link><published>2016-11-29T11:22:00-08:00</published><updated>2016-11-29T11:22:00-08:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2016-11-29:/blog/how-to-fix-order-violation-bugs-with-condition-variables.html</id><summary type="html">&lt;p&gt;Let's look at the following code and try to find the bug in it.&lt;/p&gt;
&lt;p&gt;```
Thread 1:
void init() {
  ...
  mThread = PR_CreateThread(mMain, ...)
  ...
}&lt;/p&gt;
&lt;p&gt;Thread 2:
void mMain(...) {
  ...
  mState = mThread-&amp;gt;State;
  ...
}
```&lt;/p&gt;
&lt;p&gt;The problem is that if thread two executes before thread one, it can access &lt;code&gt;mThread&lt;/code&gt; which is not initialized. We need to …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Let's look at the following code and try to find the bug in it.&lt;/p&gt;
&lt;p&gt;```
Thread 1:
void init() {
  ...
  mThread = PR_CreateThread(mMain, ...)
  ...
}&lt;/p&gt;
&lt;p&gt;Thread 2:
void mMain(...) {
  ...
  mState = mThread-&amp;gt;State;
  ...
}
```&lt;/p&gt;
&lt;p&gt;The problem is that if thread two executes before thread one, it can access &lt;code&gt;mThread&lt;/code&gt; which is not initialized. We need to make thread two wait for thread one. This is done with condition variables. But let's see how we're going to implement it.&lt;/p&gt;
&lt;h3 id="solution-1-incorrect-simple-wait-and-signal"&gt;Solution 1 (Incorrect) - Simple wait and signal&lt;/h3&gt;
&lt;p&gt;Let's say that we're not giving this a lot of thought and just put a wait and signal in the code. We have this code:&lt;/p&gt;
&lt;p&gt;```
pthread_mutex_t mtLock = PTHREAD_MUTEX_INITIALIZER;
pthread_cond_t mtCond = PTHREAD_COND_INITIALIZER;&lt;/p&gt;
&lt;p&gt;Thread 1:
void init() {
  ...
  mThread = PR_CreateThread(mMain, ...)
  pthread_mutex_lock(&amp;amp;mtLock);
  pthread_cond_signal(&amp;amp;mtCond);
  pthread_mutex_unlock(&amp;amp;mtLock);
  ...
}&lt;/p&gt;
&lt;p&gt;Thread 2:
void mMain(...) {
  ...
  pthread_mutex_lock(&amp;amp;mtLock);
  pthread_cond_wait(&amp;amp;mtCond, &amp;amp;mtLock);
  pthread_mutex_unlock(&amp;amp;mtLock);
  mState = mThread-&amp;gt;State;
  ...
}
```&lt;/p&gt;
&lt;p&gt;The problem here is that thread one can execute before thread two. In this case, thread one will signal on the condition variable, but nobody is waiting on it. Once thread two executes, it will start waiting and nobody is going to signal on the condition variable. Thus, thread two will stay in block state.&lt;/p&gt;
&lt;h3 id="solution-2-correct-using-a-synchronization-variable"&gt;Solution 2 (Correct) - Using a synchronization variable.&lt;/h3&gt;
&lt;p&gt;```
  pthread_mutex_t mtLock = PTHREAD_MUTEX_INITIALIZER;
  pthread_cond_t mtCond = PTHREAD_COND_INITIALIZER;
  int mtInit = 0;&lt;/p&gt;
&lt;p&gt;Thread 1:
  void init() {
    ...
1   mThread = PR_CreateThread(mMain, ...)
2   pthread_mutex_lock(&amp;amp;mtLock);
3   mtInit = 1;
4   pthread_cond_signal(&amp;amp;mtCond);
5   pthread_mutex_unlock(&amp;amp;mtLock);
    ...
  }&lt;/p&gt;
&lt;p&gt;Thread 2:
  void mMain(...) {
    ...
6   pthread_mutex_lock(&amp;amp;mtLock);
7   if (mtInit == 0)
8     pthread_cond_wait(&amp;amp;mtCond, &amp;amp;mtLock);
9   pthread_mutex_unlock(&amp;amp;mtLock);
10  mState = mThread-&amp;gt;State;
    ...
  }
```&lt;/p&gt;
&lt;p&gt;Here we have used the &lt;code&gt;mtInit&lt;/code&gt; variable to prevent the bug in Solution 1 from hapenning. Let's try to reproduce the conditions that led to a bug in out first solution. Let's say thread one executes before thread two. When thread two runs, it will see that &lt;code&gt;mtInit&lt;/code&gt; is 1 and it won't wait. That basically solves our problem. Let's trace things more carfully with two possible scenarios. Of course, there are other possibilities too, but with these two I have enough confidence in the correctness of the solution.&lt;/p&gt;
&lt;p&gt;```
Scenario 1 - Thread 1 before Thread 2.&lt;/p&gt;
&lt;p&gt;Line   T1    T2   COMMENT
       1
       2          Locked mutex
             6    Blocked, because mutex is locked.
       3
       4          Signals on the condition variable.
       5          Unblocks mutex.
             6    Continues, mutex was unblocked.
             7    False, jump to line 9.
             9    Unlock mutex, done
```&lt;/p&gt;
&lt;p&gt;So in this scenario, thread one obtains the lock first and the solution is correct.&lt;/p&gt;
&lt;p&gt;```
Scenario 2 - Thread 2 before Thread 1.&lt;/p&gt;
&lt;p&gt;Line   T1    T2   COMMENT
             6    Locked mutex.
             7
             8    Unlocks mutex, waiting on condition variable.
       1    &lt;br /&gt;
       2          Locks mutex.
       3    &lt;br /&gt;
       4          Signals, but mutex is still locked, so thread two doesn't do anything.
       5          Unlocks mutex. Now thread two can continue.
             8    Returns from wait(), locks mutex.
             9    Unlocks mutex.
```&lt;/p&gt;
&lt;p&gt;This scenario works too.&lt;/p&gt;
&lt;p&gt;There's one change that we should do though. Instead of an if statement in line 7, we should use a while. Why? Because when thread two wakes up in line 7 and obtains a lock on the mutex, it should re-verify that the condition that made it wait is not true anymore. While not a problem in this code segment, this can be a problem in other cases.&lt;/p&gt;</content></entry><entry><title>Pitfalls of POSIX condition variables.</title><link href="http://pminkov.github.io/blog/pitfalls-of-posix-condition-variables.html" rel="alternate"></link><published>2016-11-24T20:23:00-08:00</published><updated>2016-11-24T20:23:00-08:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2016-11-24:/blog/pitfalls-of-posix-condition-variables.html</id><summary type="html">&lt;p&gt;I'm reading this awesome &lt;a href="http://pages.cs.wisc.edu/~remzi/OSTEP/"&gt;book&lt;/a&gt; about operating systems. I find that with OSs, you can't understand things by just reading the text.
You have to write code, write out things on paper and read certain passages multiple times. That's the difference between learning and reading. Hopefully I'm learning something.&lt;/p&gt;
&lt;p&gt;So …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I'm reading this awesome &lt;a href="http://pages.cs.wisc.edu/~remzi/OSTEP/"&gt;book&lt;/a&gt; about operating systems. I find that with OSs, you can't understand things by just reading the text.
You have to write code, write out things on paper and read certain passages multiple times. That's the difference between learning and reading. Hopefully I'm learning something.&lt;/p&gt;
&lt;p&gt;So this book has a nice chapter on &lt;a href="https://computing.llnl.gov/tutorials/pthreads/#ConditionVariables"&gt;condition variables&lt;/a&gt;. The way condition variables operate is fairly clear, but I found two pitfalls that I had to dig deeper into in order to see what's going on.&lt;/p&gt;
&lt;p&gt;First, a crash course in how condition variables operate. I'm using shortened function names for readability. A condition variable is a variable that you can use to make a thread wait for some condition to be true. So roughly, it looks like this:&lt;/p&gt;
&lt;p&gt;```
// Thread one.
lock(mutex);
wait(condition, mutex);
unlock(mutex);&lt;/p&gt;
&lt;p&gt;// Thread two.
lock(mutex);
signal(condition);
unlock(mutex);
```&lt;/p&gt;
&lt;p&gt;Let's say that the first thing that happens here is that thread one obtains the mutex. Thread two runs and blocks on its call to &lt;code&gt;lock&lt;/code&gt;. Now thread one proceeds and calls &lt;code&gt;wait(condition, mutex)&lt;/code&gt;. What happens here is that mutex is unlocked and thread one goes to sleep. It's waiting for the condition to become true. Thread two is able to obtain the lock and it then signals to thread one that the condition is satisfied. Thread one obtains a lock on the mutex again and finishes its job.&lt;/p&gt;
&lt;p&gt;Now that this is out of the way, let's look at the pitfalls.&lt;/p&gt;
&lt;h4 id="pitfall-1"&gt;Pitfall 1&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;When a thread signals a condition, if the thread holds a lock on the mutex, a waiting thread returns from &lt;code&gt;wait()&lt;/code&gt; only after the first thread unlocks the mutex.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Looking at our example, intuitively it looks like when we call &lt;code&gt;signal()&lt;/code&gt;, the first thread should return from wait. After all, the signal has been sent. But that's not the case. If thread two has more work to do after the signal, all of this will be done and just once &lt;code&gt;unlock()&lt;/code&gt; is called, that's when thread one will return from the wait.
Thread one will then lock the mutex and once it's done with its work, it will unlock it. This is way more logical than the mess that would happen if &lt;code&gt;signal()&lt;/code&gt; makes &lt;code&gt;wait()&lt;/code&gt; return immediately.&lt;/p&gt;
&lt;h4 id="pitfall-2"&gt;Pitfall 2&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;Calling &lt;code&gt;signal()&lt;/code&gt; doesn't necessarily unblock all threads waiting on this signal.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Well this one caused me to scratch my head when I was going through one of the exercises in the book. I assumed a call to &lt;code&gt;signal()&lt;/code&gt; simply unblocks all the waiting threads. No, it possibly unblocks only one of them. Apparently there's a &lt;code&gt;pthread_cond_broadcast&lt;/code&gt; &lt;a href="https://linux.die.net/man/3/pthread_cond_signal"&gt;function&lt;/a&gt; that can unblock all waiting threads.&lt;/p&gt;
&lt;p&gt;So that's it. Happy coding.&lt;/p&gt;</content><category term="Concurrency"></category></entry><entry><title>Implementing a fast multi-threaded counter.</title><link href="http://pminkov.github.io/blog/implementing-a-fast-multi-threaded-counter.html" rel="alternate"></link><published>2016-11-23T11:02:00-08:00</published><updated>2016-11-23T11:02:00-08:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2016-11-23:/blog/implementing-a-fast-multi-threaded-counter.html</id><summary type="html">&lt;p&gt;Today I'll write a bit about implementing a simple thread safe counter and improving its speed.&lt;/p&gt;
&lt;p&gt;Implementing a basic mutli-threaded counter is a fairly easy task. Using pthreads, you just need to wrap the counter increment in a lock.&lt;/p&gt;
&lt;p&gt;The code (&lt;a href="https://github.com/pminkov/wip/tree/master/mt-counters"&gt;github link&lt;/a&gt;) looks like this:&lt;/p&gt;
&lt;p&gt;```&lt;/p&gt;
&lt;h1 id="include-mythreadsh"&gt;include "mythreads.h"&lt;/h1&gt;
&lt;p&gt;struct …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Today I'll write a bit about implementing a simple thread safe counter and improving its speed.&lt;/p&gt;
&lt;p&gt;Implementing a basic mutli-threaded counter is a fairly easy task. Using pthreads, you just need to wrap the counter increment in a lock.&lt;/p&gt;
&lt;p&gt;The code (&lt;a href="https://github.com/pminkov/wip/tree/master/mt-counters"&gt;github link&lt;/a&gt;) looks like this:&lt;/p&gt;
&lt;p&gt;```&lt;/p&gt;
&lt;h1 id="include-mythreadsh"&gt;include "mythreads.h"&lt;/h1&gt;
&lt;p&gt;struct counter_t {
  int value;
  pthread_mutex_t lock;
};&lt;/p&gt;
&lt;p&gt;static struct counter_t counter;&lt;/p&gt;
&lt;p&gt;void init(struct counter_t *c) {
  c-&amp;gt;value = 0;
  pthread_mutex_init(&amp;amp;c-&amp;gt;lock, NULL);
}&lt;/p&gt;
&lt;p&gt;void increment_by(struct counter_t *c, int by) {
  Pthread_mutex_lock(&amp;amp;c-&amp;gt;lock);
  c-&amp;gt;value += by;
  Pthread_mutex_unlock(&amp;amp;c-&amp;gt;lock);
}&lt;/p&gt;
&lt;p&gt;void increment(struct counter_t *c) {
  increment_by(c, 1);
}&lt;/p&gt;
&lt;p&gt;int get(struct counter_t *c) {
  Pthread_mutex_lock(&amp;amp;c-&amp;gt;lock);
  int rc = c-&amp;gt;value;
  Pthread_mutex_unlock(&amp;amp;c-&amp;gt;lock);
  return rc;
}
```&lt;/p&gt;
&lt;p&gt;Nothing complicated. Let's say that we want to increment this counter 1,000,000 times. And let's do this with an increasing amount of threads, each thread incrementing the counter 1,000,000 times. I get the following timings for this exercise.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;1 thread:  0.064s real time.
2 threads: 9.930s
4 threads: 23.971s&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This counter is really slow. Also, it doesn't scale well, since at the moment more than one thread starts to use it, it becomes so much slower. Why is this? Well, it's a bit difficult to tell without knowing how mutexes are implemented, but since we're using a single mutex that has to switch between two threads, it looks like there's a lot of overhead in this. The core operation - the increment, is also not parallel, since it can be done by only one thread at a time. But judging from the single threaded timing, this operation by itself is not the bottleneck here. So the synchronization must be.&lt;/p&gt;
&lt;p&gt;How can we improve this? We can use what's called a sloppy counter. The sloppy counter is also fairly easy to understand. Each thread has its own counter and when that counter becomes bigger than a certain value, its current value is transferred into a global counter. Here's how the code for that looks like:&lt;/p&gt;
&lt;p&gt;```&lt;/p&gt;
&lt;h1 id="include"&gt;include &lt;string.h&gt;&lt;/h1&gt;
&lt;h1 id="include_1"&gt;include &lt;stdlib.h&gt;&lt;/h1&gt;
&lt;h1 id="define-mina-b-a-b-a-b"&gt;define min(a, b) ((a) &amp;lt; (b) ? (a) : (b))&lt;/h1&gt;
&lt;p&gt;const uint64_t SLOTS_COUNT = 101;&lt;/p&gt;
&lt;p&gt;struct sloppy_counter_t {
  int value;&lt;/p&gt;
&lt;p&gt;struct counter_t gcounter;&lt;/p&gt;
&lt;p&gt;// A hash table for per-thread counters. Since we're unlikely to run too many threads at the same time,
  // chances for collision are low. If that's not the case, we can always use a per-counter mutex.
  int lcounters[SLOTS_COUNT];
};&lt;/p&gt;
&lt;p&gt;static struct sloppy_counter_t sloppy_counter;&lt;/p&gt;
&lt;p&gt;void sloppy_init(struct sloppy_counter_t *c) {
  for (int i = 0; i &amp;lt; SLOTS_COUNT; i++) {
    c-&amp;gt;lcounters[i] = 0;
  }&lt;/p&gt;
&lt;p&gt;init(&amp;amp;c-&amp;gt;gcounter);
}&lt;/p&gt;
&lt;p&gt;int slot_id(pthread_t thread_id) {
  uint64_t ptid = 0;
  memcpy(&amp;amp;ptid, &amp;amp;thread_id, min(sizeof(thread_id), sizeof(ptid)));&lt;/p&gt;
&lt;p&gt;int sid = ptid % SLOTS_COUNT;
  return sid;
}&lt;/p&gt;
&lt;p&gt;void sloppy_increment(struct sloppy_counter_t *c, pthread_t thread_id) {
  int sid = slot_id(thread_id);&lt;/p&gt;
&lt;p&gt;c-&amp;gt;lcounters[sid]++;
  if (c-&amp;gt;lcounters[sid] &amp;gt; 128) {
    increment_by(&amp;amp;c-&amp;gt;gcounter, c-&amp;gt;lcounters[sid]);
    c-&amp;gt;lcounters[sid] = 0;
  }
}&lt;/p&gt;
&lt;p&gt;void sloppy_flush(struct sloppy_counter_t *c, pthread_t thread_id) {
  int sid = slot_id(thread_id);
  if (c-&amp;gt;lcounters[sid] &amp;gt; 0) {
    increment_by(&amp;amp;c-&amp;gt;gcounter, c-&amp;gt;lcounters[sid]);
  }
}&lt;/p&gt;
&lt;p&gt;int sloppy_get(struct sloppy_counter_t *counter) {
  return get(&amp;amp;counter-&amp;gt;gcounter);
}
```&lt;/p&gt;
&lt;p&gt;Now let's time this counter.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;1 thread:  0.026s
2 threads: 0.050s
4 threads: 0.164s&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Much better! This counter, just like the first one, is thread safe. It's not as accurate, but the inaccuracy is small (at most 128 * number of threads) and we can use the flush function if we want accurate counts.&lt;/p&gt;</content><category term="Concurrency"></category><category term="Linux"></category></entry><entry><title>Monitoring Disk I/O on Linux.</title><link href="http://pminkov.github.io/blog/monitoring-disk-io-on-linux.html" rel="alternate"></link><published>2016-11-16T14:59:00-08:00</published><updated>2016-11-16T14:59:00-08:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2016-11-16:/blog/monitoring-disk-io-on-linux.html</id><summary type="html">&lt;p&gt;Today I wrote a little piece of code that generates a random array of numbers, stores it into disk and sorts it on disk, using bubble sort. This uses O(1) memory, but it's obviously very slow. I did this for fun mostly. The code is &lt;a href="https://github.com/pminkov/wip/blob/master/os/disksort.c"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I wanted to …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Today I wrote a little piece of code that generates a random array of numbers, stores it into disk and sorts it on disk, using bubble sort. This uses O(1) memory, but it's obviously very slow. I did this for fun mostly. The code is &lt;a href="https://github.com/pminkov/wip/blob/master/os/disksort.c"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I wanted to know, if I'm running this code, what Linux tools are going to show an increase in disk I/O.&lt;/p&gt;
&lt;p&gt;So, I run this:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$ ./disksort 150000&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This starts the sorting. It takes a long time to sort 150k numbers on disk, at least with that algorithm.&lt;/p&gt;
&lt;p&gt;So the first command that we can run is &lt;code&gt;iostat&lt;/code&gt;. Let's see what it is outputting before I start &lt;code&gt;disksort&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;```
$ sudo iostat 5 2
Linux 4.4.0-31-generic (petko-VirtualBox)       11/16/2016      &lt;em&gt;x86_64&lt;/em&gt;        (1 CPU)&lt;/p&gt;
&lt;p&gt;avg-cpu:  %user   %nice %system %iowait  %steal   %idle
          14.68    0.19   38.34    0.05    0.00   46.73&lt;/p&gt;
&lt;p&gt;Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn
sda               5.60        83.17        63.96     539970     415252&lt;/p&gt;
&lt;p&gt;avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           3.03    0.00    0.00    0.00    0.00   96.97&lt;/p&gt;
&lt;p&gt;Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn
sda               0.00         0.00         0.00          0          0
```&lt;/p&gt;
&lt;p&gt;The command line invocation is a bit strange. The &lt;code&gt;5 2&lt;/code&gt; part says "aggregate IO data for five seconds and show me two reports". The idea is that you can get continuous report output every five seconds. But I need only one report. The first one is a default one, which shows aggregated data for I'm not sure what period. But the second one is interesting. Notice &lt;code&gt;kB_read/s&lt;/code&gt; and &lt;code&gt;kB_wrtn/s&lt;/code&gt;. They're zeros. So it's all quiet. I now run &lt;code&gt;disksort&lt;/code&gt; and run the same command.&lt;/p&gt;
&lt;p&gt;```
$ iostat 5 2
Linux 4.4.0-31-generic (petko-VirtualBox)       11/16/2016      &lt;em&gt;x86_64&lt;/em&gt;        (1 CPU)&lt;/p&gt;
&lt;p&gt;avg-cpu:  %user   %nice %system %iowait  %steal   %idle
          15.32    0.17   40.33    0.05    0.00   44.14&lt;/p&gt;
&lt;p&gt;Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn
sda               5.04        73.65        59.42     540254     435868&lt;/p&gt;
&lt;p&gt;avg-cpu:  %user   %nice %system %iowait  %steal   %idle
          26.81    0.00   73.19    0.00    0.00    0.00&lt;/p&gt;
&lt;p&gt;Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn
sda               0.80         0.00       157.64          0        588
```&lt;/p&gt;
&lt;p&gt;Notice how &lt;code&gt;kB_wrtn/s&lt;/code&gt; spiked up. &lt;code&gt;kB_read&lt;/code&gt; is zero and I assume that's because of the &lt;a href="http://www.tldp.org/LDP/sag/html/buffer-cache.html"&gt;buffer cache&lt;/a&gt;. After all, I'm reading the same file again and again.&lt;/p&gt;
&lt;p&gt;Another command that we can use is &lt;code&gt;iotop&lt;/code&gt;. &lt;code&gt;iotop&lt;/code&gt; is similar to &lt;code&gt;top&lt;/code&gt;, but shows I/O stats. We'll run it using &lt;code&gt;iotop -oa&lt;/code&gt;. The &lt;code&gt;-o&lt;/code&gt; parameter makes it show only processes that do I/O. The &lt;code&gt;-a&lt;/code&gt; flag aggregates the data during the time this command is running. So after running it for a few seconds I'm seeing this:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Total DISK READ :       0.00 B/s | Total DISK WRITE :      83.77 K/s
Actual DISK READ:       0.00 B/s | Actual DISK WRITE:       0.00 B/s
  TID  PRIO  USER     DISK READ  DISK WRITE  SWAPIN     IO&amp;gt;    COMMAND                                                                                                                                                       
  545 be/3 root          0.00 B      4.00 K  0.00 %  0.08 % [jbd2/sda1-8]
 7717 be/4 root          0.00 B      0.00 B  0.00 %  0.01 % [kworker/u2:3]
 7865 be/4 root          0.00 B      0.00 B  0.00 %  0.01 % [kworker/u2:1]
 7714 be/4 petko         0.00 B   1144.00 K  0.00 %  0.00 % ./disksort 150000
 7097 be/4 root          0.00 B      0.00 B  0.00 %  0.00 % [kworker/u2:2]
 7758 be/4 root          0.00 B      0.00 B  0.00 %  0.00 % [kworker/u2:0]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Notice how &lt;code&gt;disksort&lt;/code&gt; with pid of &lt;code&gt;7714&lt;/code&gt; is well ahead of everything else shown.&lt;/p&gt;
&lt;p&gt;So that's it, happy debugging.&lt;/p&gt;</content></entry><entry><title>Using pandas to read a table from an HTML page.</title><link href="http://pminkov.github.io/blog/using-pandas-to-read-a-table-from-an-html-page.html" rel="alternate"></link><published>2016-10-31T13:56:00-07:00</published><updated>2016-10-31T13:56:00-07:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2016-10-31:/blog/using-pandas-to-read-a-table-from-an-html-page.html</id><summary type="html">&lt;p&gt;Today I wanted to write a bit of simple code to try out a hypothesis I had about stock prices. I found historical data at &lt;a href="http://www.multpl.com/s-p-500-historical-prices/table/by-year"&gt;multpl.com&lt;/a&gt;. At first I thought I'd have to write my own code using Python's &lt;a href="https://docs.python.org/2/library/htmlparser.html"&gt;HTMLParser&lt;/a&gt;. As much as I like to write code, I …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Today I wanted to write a bit of simple code to try out a hypothesis I had about stock prices. I found historical data at &lt;a href="http://www.multpl.com/s-p-500-historical-prices/table/by-year"&gt;multpl.com&lt;/a&gt;. At first I thought I'd have to write my own code using Python's &lt;a href="https://docs.python.org/2/library/htmlparser.html"&gt;HTMLParser&lt;/a&gt;. As much as I like to write code, I decided to save myself some time and find something that already does this. To my surprise, &lt;a href="http://pandas.pydata.org/"&gt;pandas&lt;/a&gt;, already has a &lt;a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_html.html"&gt;function&lt;/a&gt; that reads data from HTML tables. Great. Let's see how it works.&lt;/p&gt;
&lt;p&gt;First, I installed pandas, lxml and a bunch of other requirements in a &lt;a href="http://pminkov.github.io/why-i-always-use-virtualenv-to-try-out-new-libraries.html"&gt;virtual environment&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To read the tables from the webpage, I used the following lines of code:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
  tables = pandas.read_html('http://www.multpl.com/s-p-500-historical-prices/table/by-month', header=0)
  assert len(tables) == 1
  table = tables[0]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;header&lt;/code&gt; parameter, says that we should use the first row in a table as the dataframe's column names. Spefically for this table, one of the columns was getting a somewhat wrong name, but it was easy to fix it with this line of code:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
table.columns = ['Date', 'Price']&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;There we go, we have read historical stock prices into a pandas dataframe. To iterate and print them, we can do it like this:&lt;/p&gt;
&lt;p&gt;```python&lt;/p&gt;
&lt;p&gt;for (idx, row) in table.iterrows():
   date = row['Date']
   price = row['Price']
   print date, price
```&lt;/p&gt;</content></entry><entry><title>What I learned from reading Dive into Python.</title><link href="http://pminkov.github.io/blog/what-i-learned-from-reading-dive-into-python.html" rel="alternate"></link><published>2016-06-15T09:57:00-07:00</published><updated>2016-06-15T09:57:00-07:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2016-06-15:/blog/what-i-learned-from-reading-dive-into-python.html</id><summary type="html">&lt;p&gt;I recently started reading &lt;a href="http://www.diveintopython.net/toc/index.html"&gt;Dive into Python&lt;/a&gt;. I've been meaning to fill some gaps in my Python knowledge, since I've used the language for about ten years, but feel like I have just picked whatever parts I needed to do my work and don't have a very solid base.&lt;/p&gt;
&lt;p&gt;I'll …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I recently started reading &lt;a href="http://www.diveintopython.net/toc/index.html"&gt;Dive into Python&lt;/a&gt;. I've been meaning to fill some gaps in my Python knowledge, since I've used the language for about ten years, but feel like I have just picked whatever parts I needed to do my work and don't have a very solid base.&lt;/p&gt;
&lt;p&gt;I'll summarize some of the new things I learned from this book:&lt;/p&gt;
&lt;h3 id="chapter-2-your-first-python-program"&gt;Chapter 2 (Your First Python Program)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;sys.path&lt;/code&gt; contains the list of directories that Python uses to lookup module imports.&lt;/li&gt;
&lt;li&gt;One use of the &lt;code&gt;__name__&lt;/code&gt; attribute is to write testing code. When a module is imported &lt;code&gt;__name__&lt;/code&gt; is the name of the module. When a module python file is executed from the command line &lt;code&gt;__name__&lt;/code&gt; is equal to &lt;code&gt;__main__&lt;/code&gt;. Personally this feels like a bit of a hack to me, since you can use something like say Django's unit testing platform, but it might come handy sometime.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="chapter-3-native-datatypes"&gt;Chapter 3 (Native Datatypes)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Here's a cool trick mentioned in this chapter:
&lt;code&gt;python
(MONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY, SATURDAY, SUNDAY) = range(7)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="chapter-4-the-power-of-introspection"&gt;Chapter 4 (The Power Of Introspection):&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Some useful functions are mentioned: &lt;code&gt;dir&lt;/code&gt; (try on a module or an object instance), &lt;code&gt;callable&lt;/code&gt;, &lt;code&gt;getattr&lt;/code&gt;, &lt;code&gt;__doc__&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So you can do something interesting, like this:
```
class Sum:
  """Sums numbers"""
  member = 3&lt;/p&gt;
&lt;p&gt;def sum2(self, a, b):
    """Sum two numbers"""
    return a + b&lt;/p&gt;
&lt;p&gt;def sum3(self, a, b, c):
    """Sum three numbers"""
    return a + b + c&lt;/p&gt;
&lt;p&gt;if &lt;strong&gt;name&lt;/strong&gt; == '&lt;strong&gt;main&lt;/strong&gt;':
  methods = [f for f in dir(Sum) if callable(getattr(Sum, f))]
  docs = '\n'.join(["%s %s" % (f, getattr(Sum, f).&lt;strong&gt;doc&lt;/strong&gt;) for f in methods])
  print docs
```&lt;/p&gt;
&lt;p&gt;And run it:
&lt;code&gt;bash
$ python ./sum.py
sum2 Sum two numbers
sum3 Sum three numbers&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The "and-or trick"&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;python
is_mammal = use_rpc and remote_check_is_mammal(animal) or DEFAULT_IS_MAMMAL&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;That's like &lt;code&gt;?:&lt;/code&gt; in C++. I think I did well with creating a good example here :).&lt;/p&gt;
&lt;h3 id="chapter-5-objects-and-object-orientation"&gt;Chapter 5 (Objects and Object-Orientation)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;var1 is var2&lt;/code&gt; checks for object identity. Here's a good &lt;a href="http://stackoverflow.com/questions/13650293/understanding-pythons-is-operator"&gt;stackoverflow&lt;/a&gt; article that gives examples.&lt;/li&gt;
&lt;li&gt;You can change a class variable using &lt;code&gt;self.__class__.variable_name = new_value&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;You can create your own dictionary by inheriting from &lt;code&gt;UserDict&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;If you call &lt;code&gt;x["hello"] = 3&lt;/code&gt;, this calls the &lt;code&gt;__setitem__&lt;/code&gt; method. There are other similar methods, like &lt;code&gt;__getitem__&lt;/code&gt;, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="chapter-6-exceptions-and-file-handling"&gt;Chapter 6 (Exceptions and file handling)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;You can use &lt;code&gt;else&lt;/code&gt; in exceptions code. Like this:
```python
class RPC:
  def remote_call(self):
    pass&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;def find_function(name):
  try:
    a = getattr(RPC, name)
  except AttributeError:
    print 'No such function.'
  else:
    print 'Function was found.'
  finally:
    print 'Enough lookups.'
    print&lt;/p&gt;
&lt;p&gt;find_function('func')
find_function('remote_call')
```&lt;/p&gt;
&lt;p&gt;Output:
```bash
python ./ex.py 
No such function.
Enough lookups.&lt;/p&gt;
&lt;p&gt;Function was found.
Enough lookups.
```&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;When you open a file, you have a variety of functions and attributes on the file object, like &lt;code&gt;seek&lt;/code&gt;, &lt;code&gt;read&lt;/code&gt;, &lt;code&gt;mode&lt;/code&gt;, &lt;code&gt;name&lt;/code&gt;. For example, to see how big a file is you can just call &lt;code&gt;f.seek(0, 2)&lt;/code&gt; to seek until the end and then &lt;code&gt;f.tell()&lt;/code&gt; to output the number of bytes.&lt;/li&gt;
&lt;li&gt;A class' module is accessible by calling &lt;code&gt;ClassName.__module__&lt;/code&gt;. All imported modules are in the &lt;code&gt;sys.modules&lt;/code&gt; dictionary. Example:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;```python&lt;/p&gt;
&lt;blockquote&gt;
&lt;blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;from sum import Sum
import sys
sys.modules[Sum.&lt;strong&gt;module&lt;/strong&gt;]
&lt;module 'sum' from 'sum.py'&gt;
getattr(sys.modules[Sum.&lt;strong&gt;module&lt;/strong&gt;], 'Sum')
&lt;class sum.Sum at 0x109535a10&gt;
```&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;h3 id="chapter-7-regular-expressions"&gt;Chapter 7 (Regular Expressions)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;\\b&lt;/code&gt; matches a word boundary. This can be so useful.&lt;/li&gt;
&lt;li&gt;Verbose regular expressions. Again, very useful. Example:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;```python
import re&lt;/p&gt;
&lt;p&gt;raw_regex = r"""
  (\d{3})
  \D&lt;em&gt;
  (\d{3})
  \D&lt;/em&gt;
  (\d{4})
"""&lt;/p&gt;
&lt;p&gt;examples = [
  "4153125633",
  "415-312-5633",
  "415 312 5633",
  "work 415 312 5633",
  "(415) - 312 - 5633",
  "1 415 312 5633",
]&lt;/p&gt;
&lt;p&gt;phone_re = re.compile(raw_regex, re.VERBOSE)&lt;/p&gt;
&lt;p&gt;for example in examples:
  groups = phone_re.search(example).groups()
  assert groups == ('415', '312', '5633')
```&lt;/p&gt;</content></entry><entry><title>Why I always use virtualenv to try out new libraries.</title><link href="http://pminkov.github.io/blog/why-i-always-use-virtualenv-to-try-out-new-libraries.html" rel="alternate"></link><published>2016-05-24T18:14:00-07:00</published><updated>2016-05-24T18:14:00-07:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2016-05-24:/blog/why-i-always-use-virtualenv-to-try-out-new-libraries.html</id><summary type="html">&lt;p&gt;One thing that I always do with virtualenv is to install new Python libraries in a new virtualenv before I install them into the one I'm currently working with.&lt;/p&gt;
&lt;p&gt;Here's how I do this:&lt;/p&gt;
&lt;p&gt;```
$ virtualenv venv
New python executable in /Users/petko/work/post/venv/bin/python
Installing setuptools, pip …&lt;/p&gt;</summary><content type="html">&lt;p&gt;One thing that I always do with virtualenv is to install new Python libraries in a new virtualenv before I install them into the one I'm currently working with.&lt;/p&gt;
&lt;p&gt;Here's how I do this:&lt;/p&gt;
&lt;p&gt;```
$ virtualenv venv
New python executable in /Users/petko/work/post/venv/bin/python
Installing setuptools, pip, wheel...done.&lt;/p&gt;
&lt;p&gt;$ . ./venv/bin/activate
(venv) &lt;/p&gt;
&lt;p&gt;$ pip install cryptography
... lengthy install log ...&lt;/p&gt;
&lt;p&gt;$ pip install pipdeptree # Awesome tool, more in a bit.&lt;/p&gt;
&lt;p&gt;$ pipdeptree
Warning!!! Possibly conflicting dependencies found:
* cryptography==1.3.2
 - setuptools [required: &amp;gt;=11.3, installed: &lt;unknown&gt;]&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;wheel==0.26.0
wsgiref==0.1.2
cryptography==1.3.2
  - setuptools [required: &amp;gt;=11.3]
  - enum34 [installed: 1.1.6]
  - ipaddress [installed: 1.0.16]
  - pyasn1 [required: &amp;gt;=0.1.8, installed: 0.1.9]
  - six [required: &amp;gt;=1.4.1, installed: 1.10.0]
  - idna [required: &amp;gt;=2.0, installed: 2.1]
  - cffi [required: &amp;gt;=1.4.1, installed: 1.6.0]
    - pycparser [installed: 2.14]
(venv) 
```&lt;/p&gt;
&lt;p&gt;That's it! Now I can experiment with a new library without worrying that it'll pollute my work virtualenv. Another thing that I do is using pipdeptree to see the dependencies that a new library will bring with it. If a library brings in too many dependencies, I'll be thinking twice about my need to use it, or I'll look for alternatives.&lt;/p&gt;</content></entry><entry><title>Using mustache templates with Django.</title><link href="http://pminkov.github.io/blog/using-mustache-templates-with-django.html" rel="alternate"></link><published>2016-05-23T22:13:00-07:00</published><updated>2016-05-23T22:13:00-07:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2016-05-23:/blog/using-mustache-templates-with-django.html</id><summary type="html">&lt;p&gt;There are various reasons why you might want to use client side templates in a Django app. 
For example, you might want to make your initial page load faster, return some of your data in json format and postpone some template rendering until the user needs it.&lt;/p&gt;
&lt;p&gt;Let's see how …&lt;/p&gt;</summary><content type="html">&lt;p&gt;There are various reasons why you might want to use client side templates in a Django app. 
For example, you might want to make your initial page load faster, return some of your data in json format and postpone some template rendering until the user needs it.&lt;/p&gt;
&lt;p&gt;Let's see how we can easily include &lt;a href="https://mustache.github.io/"&gt;mustache&lt;/a&gt; templates in Django. &lt;a href="http://mustache.github.io/mustache.5.html"&gt;This&lt;/a&gt; page explains the mustache syntax quite well.&lt;/p&gt;
&lt;p&gt;The most optimized way to include a client side template in your code would be to compile it on deployment and include the compiled JavaScript file as part of your static files.
However, that seemed like too much work and I wanted something that I can implement faster.&lt;/p&gt;
&lt;p&gt;If you're not shipping compiled JavaScript, then your other option would be to have the template text somewhere and compile it client side. I have one main requirement though - I don't want my template code to be in a string which editors will display without HTML syntax highlighting.&lt;/p&gt;
&lt;p&gt;So, working with these constraints, let's see what we can come up with.&lt;/p&gt;
&lt;p&gt;First, let's say our template code is in &lt;code&gt;person.html&lt;/code&gt; and it looks like this:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;html
&amp;lt;div&amp;gt;
  {{#person}}
    The user's name is {{name}}.
  {{/person}}
  {{^person}}
    There's no user defined.
  {{/person}}
&amp;lt;/div&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Now, we can include this template in the html page returned by our initial page load, like this:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;html
&amp;lt;script&amp;gt;
  var person_template_text = `{% include "myapp/templates/person.html" %}`
&amp;lt;/script&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;In this case, &lt;code&gt;person_template_text&lt;/code&gt; is a &lt;a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals"&gt;template literal&lt;/a&gt;. Template literals are JavaScript strings that can span multiple lines.&lt;/p&gt;
&lt;p&gt;Now, we just need to compile the template so that it's ready to be rendered. We'll use &lt;a href="http://twitter.github.io/hogan.js/"&gt;hogan.js&lt;/a&gt;, since it's advertised as faster and smaller than mustache and it fully supports mustache syntax. Let's say we're also using jQuery. We can do something along these lines:&lt;/p&gt;
&lt;p&gt;```javascript&lt;/p&gt;
&lt;p&gt;function App() {
  this.person_template = Hogan.compile(person_template_text);
}&lt;/p&gt;
&lt;p&gt;App.prototype.renderPerson = function(personDict) {
  return this.person_template.render(personDict);
}&lt;/p&gt;
&lt;p&gt;var app;&lt;/p&gt;
&lt;p&gt;$(document).ready(function() {
  app = new App();
});
```&lt;/p&gt;
&lt;p&gt;And that's it. There are many other ways to do this, which will be more optimized, but this one seems like an easy one to start with.&lt;/p&gt;</content><category term="Python"></category><category term="Django"></category></entry><entry><title>Type checking in Python?</title><link href="http://pminkov.github.io/blog/type-checking-in-python.html" rel="alternate"></link><published>2016-05-18T10:39:00-07:00</published><updated>2016-05-18T10:39:00-07:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2016-05-18:/blog/type-checking-in-python.html</id><summary type="html">&lt;p&gt;Since Python is a dynamically typed language, it doesn't offer type checking out of the box. There are workarounds around this though.
One that I use in my projects is the following:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
def T(val, t):
  assert type(val) == t, '(%s) %s != %s' % (str(val), type(val), t)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Here's …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Since Python is a dynamically typed language, it doesn't offer type checking out of the box. There are workarounds around this though.
One that I use in my projects is the following:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
def T(val, t):
  assert type(val) == t, '(%s) %s != %s' % (str(val), type(val), t)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Here's an example of how to use this:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
def sum(a, b):
  T(a, int)
  T(b, int)
  return a + b&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Let's say that you call the function incorrectly, like this:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
a = "hello"
b = 5
s = sum(a, b)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;You'll get the following exception:
```&lt;/p&gt;
&lt;blockquote&gt;
&lt;blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;sum(a, b)
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
  File "&lt;stdin&gt;", line 2, in sum
  File "&lt;stdin&gt;", line 2, in T
AssertionError: (hello) &lt;type 'str'&gt; != &lt;type 'int'&gt;
```&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;p&gt;So that's it - pretty simple. I use the &lt;code&gt;T&lt;/code&gt; function every once in a while, to guard against type errors.&lt;/p&gt;</content></entry><entry><title>How much does it cost to run a Django app on AWS using Elastic Beanstalk?</title><link href="http://pminkov.github.io/blog/how-much-does-it-cost-to-run-a-django-app-on-aws-using-elastic-beanstalk.html" rel="alternate"></link><published>2016-04-20T13:56:00-07:00</published><updated>2016-04-20T13:56:00-07:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2016-04-20:/blog/how-much-does-it-cost-to-run-a-django-app-on-aws-using-elastic-beanstalk.html</id><summary type="html">&lt;p&gt;I've been running a Django app on &lt;a href="http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create-deploy-python-django.html"&gt;Elastic Beanstalk&lt;/a&gt; for a couple of months and I have a decent idea now of the costs involved and the pros and cons of this approach. My goal was to get something going as soon as possible and I'd say Elastic Beanstalk is …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've been running a Django app on &lt;a href="http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create-deploy-python-django.html"&gt;Elastic Beanstalk&lt;/a&gt; for a couple of months and I have a decent idea now of the costs involved and the pros and cons of this approach. My goal was to get something going as soon as possible and I'd say Elastic Beanstalk is good for that purpose. There are a few things that took me more time to figure out and I might write about them too, but overall everything is running smoothly now.&lt;/p&gt;
&lt;p&gt;Let's first describe what my setup is. Elastic Beanstalk is AWS's PaaS offering. I use a MySQL database running on RDS, a load balancer, a single EC2 instance and I have a DNS setup on Route 53. And that's more or less what I'm paying for. My bill was &lt;strong&gt;$42.58&lt;/strong&gt; last month. Breaking it down, here are the three major components it has:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;EC2&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I'm running a &lt;a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/t2-instances.html"&gt;t2.micro&lt;/a&gt; instance. It costs $0.013 per hour and I paid for 745 hours. Total: &lt;strong&gt;$9.69&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Load balancing&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Load balancing is not cheap. It costs $0.025 per hour and for 744 hours shown, that comes down to &lt;strong&gt;$18.60&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;RDS&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;RDS costs $0.017 per RDS T2 Micro instance hour and for 743 hours shown, I paid &lt;strong&gt;$12.63&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;If we sum these three, it comes down to &lt;strong&gt;$40.92&lt;/strong&gt;. I also paid the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$0.56 for RDS service storage.&lt;/li&gt;
&lt;li&gt;$0.45 for &lt;a href="https://aws.amazon.com/ebs/"&gt;EBS&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;$0.51 for Route 53.&lt;/li&gt;
&lt;li&gt;$0.07 for data transfer (my site being served to places around the world, but my site is not popular yet).&lt;/li&gt;
&lt;li&gt;$0.05 for S3 costs.&lt;/li&gt;
&lt;li&gt;$0.01 for data processed by the load balancer.&lt;/li&gt;
&lt;li&gt;$0.01 for SES.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These are minimal costs. Some of these are going to increase if my site becomes popular, but right now they are minimal.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How can I bring these costs down?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;It's possible to do all of this with a single EC2 instance and avoid paying for load balancing and RDS. What I get from these components right now is convenience and scalability. I don't really need scalability, since I don't operate at scale and might not come to that point. Convenience can be traded for the learning experience of settings up things manually. AWS has an &lt;a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/install-LAMP.html"&gt;article&lt;/a&gt; on how to install a LAMP setup on EC2. It doesn't look too complicated. Supposedly my bill will be around $10 per month for my 1GB RAM t2.micro machine.&lt;/p&gt;
&lt;p&gt;Another option would be to use &lt;a href="https://www.digitalocean.com/pricing/"&gt;Digital Ocean&lt;/a&gt;. They're basically offering something similar to EC2 instances, but I haven't looked too much in detail. Digital Ocean is an IaaS provider, you need to do some manual setup. Their cost is pretty similar. An offering with 1GB of RAM costs $10 per month too. That's a very rough comparison, but it seems like we're in the same ballpark if we're not pushing the limits on disk space or bandwidth.&lt;/p&gt;
&lt;p&gt;It should also be possibe to continue to use Elastic Beanstalk, but run a MySQL server directly on the EC2 instance. Here's a long &lt;a href="http://d0.awsstatic.com/whitepapers/rdbms-in-the-cloud-sql-server-on-aws.pdf"&gt;white paper&lt;/a&gt; that talks about this.&lt;/p&gt;</content><category term="AWS"></category><category term="Elastic Beanstalk"></category><category term="Python"></category><category term="Django"></category></entry><entry><title>How to generate user activation links in Django.</title><link href="http://pminkov.github.io/blog/how-to-generate-user-activation-links-in-django.html" rel="alternate"></link><published>2016-04-05T17:03:00-07:00</published><updated>2016-04-05T17:03:00-07:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2016-04-05:/blog/how-to-generate-user-activation-links-in-django.html</id><summary type="html">&lt;p&gt;Imagine the following simple user registration flow:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;User registers by setting an e-mail and a password.&lt;/li&gt;
&lt;li&gt;The server sends an e-mail containing an activation link to the user.&lt;/li&gt;
&lt;li&gt;The user clicks on the activation link and activates their account.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let's focus on step 2. How do we generate this activation …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Imagine the following simple user registration flow:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;User registers by setting an e-mail and a password.&lt;/li&gt;
&lt;li&gt;The server sends an e-mail containing an activation link to the user.&lt;/li&gt;
&lt;li&gt;The user clicks on the activation link and activates their account.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let's focus on step 2. How do we generate this activation link?&lt;/p&gt;
&lt;p&gt;One way to implement this is to generate single use tokens and save them in a database table. Our url then looks like &lt;code&gt;http://sitename.com/activate?token=mytoken&lt;/code&gt;. That solution has the benefit of being able to track that a token has been used and enforce single use. The drawback is that you need a new database table, which I wanted to avoid.&lt;/p&gt;
&lt;p&gt;How else can we generate these tokens?&lt;/p&gt;
&lt;p&gt;My first hunch was to reuse Django's &lt;a href="https://github.com/django/django/blob/master/django/contrib/auth/tokens.py"&gt;PasswordResetTokenGenerator&lt;/a&gt;. However, notice that the &lt;code&gt;check_token&lt;/code&gt; function requires a user. This means that the activation link needs to include information about who the user is. So our &lt;code&gt;/activate&lt;/code&gt; link will need to include an url parameter that's either the username, user id, or something else that uniquely identifies a user. I'm not happy with that. This is a link that's supposed to be private and I don't want the user's first impression of my site to be that I'm including their user id in an activation link, when most other sites don't do that.&lt;/p&gt;
&lt;p&gt;The solution that I settled on was encrypting the user id on the server. I'm generating a link of the form &lt;code&gt;http://sitename.com/activate?token=mytoken&lt;/code&gt;. I generate the token using the Python &lt;a href="https://pypi.python.org/pypi/cryptography"&gt;cryptography&lt;/a&gt; package. The token is created by encrypting the username with a salt.&lt;/p&gt;
&lt;p&gt;So why is this not what Django is doing? I suppose the answer is that Python doesn't have a symmetric encryption implementation library coming with it.&lt;/p&gt;
&lt;p&gt;In addition, I also wanted the tokens to expire. This is simple, we can just include a timestamp in the token and compare it against the current time upon decryption.&lt;/p&gt;
&lt;p&gt;Here's a sample class that implements all of this:&lt;/p&gt;
&lt;script src="https://gist.github.com/pminkov/e53d90c348f1dc47553408666431d2a2.js"&gt;&lt;/script&gt;</content></entry><entry><title>Plotting in Octave.</title><link href="http://pminkov.github.io/blog/plotting-in-octave.html" rel="alternate"></link><published>2012-07-29T22:33:00-07:00</published><updated>2012-07-29T22:33:00-07:00</updated><author><name>softwarecomments</name></author><id>tag:pminkov.github.io,2012-07-29:/blog/plotting-in-octave.html</id><summary type="html">&lt;p&gt;Plotting functions in Octave is quite easy and helpful.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
In the lecture on neural networks from Stanford's
&lt;a href="http://ml-class.org/"&gt;machine learning class&lt;/a&gt; a function related to neural
networks is introduced. The function has two inputs - x1 and x2 and it's
supposed to model a logical AND operation. The function is based on …</summary><content type="html">&lt;p&gt;Plotting functions in Octave is quite easy and helpful.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
In the lecture on neural networks from Stanford's
&lt;a href="http://ml-class.org/"&gt;machine learning class&lt;/a&gt; a function related to neural
networks is introduced. The function has two inputs - x1 and x2 and it's
supposed to model a logical AND operation. The function is based on the
sigmoid function.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
The sigmoid function looks like this:&lt;/p&gt;
&lt;p&gt;&lt;center&gt;&lt;img alt="Google sigmoid plot" src="http://pminkov.github.io/blog/images/sigmoid-google.png" /&gt;&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
Computing the sigmoid function in Octave can be seen
&lt;a href="https://gist.github.com/3205075" title="Sidmoid"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
The given example plugs x1 and x2 into the sigmoid function by
computing:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
f(x1, x2) = sigmoid(-30 + 20*x1 + 20*x2)&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
f(1, 1) evaluates to 1&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
f(0, 0), f(0, 1) and f(1, 0) evaluate to 0.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
Intuitively that make sense. Even if x1 or x2 is 1, -30 + 20 is -10,
which corresponds to a very low value for the sigmoid function, as you
can see from the graph above.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
I got curious about how this function looks like for values between zero
and one and wrote this &lt;a href="https://gist.github.com/3205016"&gt;short Octave
program&lt;/a&gt; to plot the output. And here
it is. Pretty neat, I'd say.&lt;/p&gt;
&lt;p&gt;&lt;center&gt;&lt;img alt="Octave sigmoid plot" src="http://pminkov.github.io/blog/images/sigmoid-octave.png" /&gt;&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
It's easy to see that the function behaves as expected at (0,0), (0,1)
and (1,0) and (1,1) and that for values in between its computed values
are somewhere in between as well.&lt;/p&gt;
&lt;/p&gt;</content></entry><entry><title>Stanford's machine learning class.</title><link href="http://pminkov.github.io/blog/stanfords-machine-learning-class.html" rel="alternate"></link><published>2012-07-27T15:00:45-07:00</published><updated>2012-07-27T15:00:45-07:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2012-07-27:/blog/stanfords-machine-learning-class.html</id><summary type="html">&lt;p&gt;Stanford's machine learning class on coursera is pretty good. What's
surprising to me is that exercises take much more time than listening to
lectures and taking after class quizes.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
The programming environment used for the class is Octave. The most
challenging part so far with writing code in Octave is …</summary><content type="html">&lt;p&gt;Stanford's machine learning class on coursera is pretty good. What's
surprising to me is that exercises take much more time than listening to
lectures and taking after class quizes.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
The programming environment used for the class is Octave. The most
challenging part so far with writing code in Octave is coming up with
what's called vectorization solutions. The idea of vectorization is that
instead of writing loops, you compute values by vector and matrix
operations.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
Let's look at a simple example. Imagine that you have a vector of zeros
and ones. You have to convert it to a vector where for each one we have
a one and for each zero we have minus one. That came up as a component
of the cost function computation in logistic regression.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
An iterative solution in Scala might look like this:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
v.map(x =&amp;gt; if (x == 0) -1 else 1)&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
How would that look in Octave if we can't use loops and if statements? A
function F that maps from {0, 1} to {-1, 1} actually looks like this:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
F(x) = 2x - 1&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
Pretty cool. Now if our vector of zeros and ones is A, by using that
function, we can compute the desired value by doing this:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
D = 2 * A - 1&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
This is pretty much only a part of a typical vectorized computation in
machine learning. Crafting those takes some time, but at the end there's
a good a-ha moment and usually a quite short solution.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
So far I went through the linear and logistic regression lectures. Both
methods are widely practical and it's very easy to come up with usage
example. Those methods are examples of supervised learning algorithms,
since we train them on a data set and then once we've computed a model
we just plug new examples into it and come up with results.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
In practice, I doubt that anyone is going to implement their own
gradient descent algorithms to come up with model coefficients. I'd
expect that usually a library / package like Matlab / Octave / R will be
used to train a model. Implementing the model itself is quite trivial
and would be just a couple of lines of code.&lt;/p&gt;
&lt;/p&gt;</content></entry><entry><title>Scala scopes.</title><link href="http://pminkov.github.io/blog/scala-scopes.html" rel="alternate"></link><published>2012-04-27T23:26:00-07:00</published><updated>2012-04-27T23:26:00-07:00</updated><author><name>softwarecomments</name></author><id>tag:pminkov.github.io,2012-04-27:/blog/scala-scopes.html</id><summary type="html">&lt;p&gt;After some programming with Scala, there are a couple of language
features which I really like. One of them is scopes that can evaluate to
a value. How does that look like:&lt;/p&gt;
&lt;p&gt;
&lt;script src="https://gist.github.com/2516506.js" type="text/javascript"&gt;&lt;![CDATA[// &lt;![CDATA[&lt;/p&gt;

&lt;p&gt;// &lt;![CDATA[&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt;// ]]]]]]&gt;&lt;![CDATA[&gt;&lt;![CDATA[&gt;&lt;/p&gt;

&lt;p&gt;// ]]]]&gt;&lt;![CDATA[&gt;]]&gt;&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;
Ignore the obvious inefficiencies …</summary><content type="html">&lt;p&gt;After some programming with Scala, there are a couple of language
features which I really like. One of them is scopes that can evaluate to
a value. How does that look like:&lt;/p&gt;
&lt;p&gt;
&lt;script src="https://gist.github.com/2516506.js" type="text/javascript"&gt;&lt;![CDATA[// &lt;![CDATA[&lt;/p&gt;

&lt;p&gt;// &lt;![CDATA[&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt;// ]]]]]]&gt;&lt;![CDATA[&gt;&lt;![CDATA[&gt;&lt;/p&gt;

&lt;p&gt;// ]]]]&gt;&lt;![CDATA[&gt;]]&gt;&lt;/script&gt;
&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;
Ignore the obvious inefficiencies of the code and take a look at how you
can put a block of code inside the inner scope. What's good about that?
This inner scope is like a lighweight function. The benefits are:&lt;/p&gt;
&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Variables in the function are not seen outside of the scope. Great,
    because you'll get a compile error if you try to use one of
    those variables. Once you're working in the scope you know that any
    variable you declare inside of it won't be used on the outside.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You have a logical block of computation that has a clear start and
    finish, which makes the code easier to read and work with.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Unlike a function, you don't need to declare function parameters.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The drawback is of course that this can become an excuse for creating
long functions, with a lot of scopes like this one inside of them. If
that's avoided, this language feature leads to easier to understand
code.&lt;/p&gt;
&lt;/p&gt;</content></entry><entry><title>Fun problem with Scala.</title><link href="http://pminkov.github.io/blog/fun-problem-with-scala.html" rel="alternate"></link><published>2012-03-06T23:28:00-08:00</published><updated>2012-03-06T23:28:00-08:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2012-03-06:/blog/fun-problem-with-scala.html</id><summary type="html">&lt;p&gt;Here's a fun problem to solve with Scala.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
Given N lists, dedupe them with the following rules. Go through the
first list, dedupe it. Go through every consecutive list and only leave
items which are not in a previous list and also take care of removing
duplicates.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
The challenge here …</summary><content type="html">&lt;p&gt;Here's a fun problem to solve with Scala.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
Given N lists, dedupe them with the following rules. Go through the
first list, dedupe it. Go through every consecutive list and only leave
items which are not in a previous list and also take care of removing
duplicates.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
The challenge here is to do this without using vars and by only using
vals. If you use vars, the solution is trivial.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
The solution to this problem is using foldLeft. foldLeft essentially
gives you a way to operate on the elements of a list while aggregating
some state. The state you aggregate is the elements you've already seen
and the current result. The final solution looks like this:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;
&lt;script src="https://gist.github.com/1991619.js" type="text/javascript"&gt;&amp;lt;![CDATA[// &amp;lt;![CDATA[&lt;/p&gt;&lt;p&gt;// &amp;lt;![CDATA[&lt;/p&gt;&lt;p&gt;// &amp;lt;![CDATA[&lt;/p&gt;&lt;p&gt;// &amp;lt;![CDATA[&lt;/p&gt;&lt;p&gt; &lt;/p&gt;&lt;p&gt;// ]]]]]]]]]]&amp;gt;&amp;lt;![CDATA[&amp;gt;&amp;lt;![CDATA[&amp;gt;&amp;lt;![CDATA[&amp;gt;&amp;lt;![CDATA[&amp;gt;&lt;/p&gt;&lt;p&gt;// ]]]]]]]]&amp;gt;&amp;lt;![CDATA[&amp;gt;&amp;lt;![CDATA[&amp;gt;&amp;lt;![CDATA[&amp;gt;&lt;/p&gt;&lt;p&gt;// ]]]]]]&amp;gt;&amp;lt;![CDATA[&amp;gt;&amp;lt;![CDATA[&amp;gt;&lt;/p&gt;&lt;p&gt;// ]]]]&amp;gt;&amp;lt;![CDATA[&amp;gt;]]&amp;gt;&lt;/script&gt;
&lt;/p&gt;
&lt;/p&gt;
And while we're at it, let's see how the C++ solution looks like, for
comparison. My C++ might be a bit rusty, but the result is longer.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;
&lt;script src="https://gist.github.com/1991674.js" type="text/javascript"&gt;&amp;lt;![CDATA[// &amp;lt;![CDATA[&lt;/p&gt;&lt;p&gt;// &amp;lt;![CDATA[&lt;/p&gt;&lt;p&gt;// &amp;lt;![CDATA[&lt;/p&gt;&lt;p&gt;// &amp;lt;![CDATA[&lt;/p&gt;&lt;p&gt; &lt;/p&gt;&lt;p&gt;// ]]]]]]]]]]&amp;gt;&amp;lt;![CDATA[&amp;gt;&amp;lt;![CDATA[&amp;gt;&amp;lt;![CDATA[&amp;gt;&amp;lt;![CDATA[&amp;gt;&lt;/p&gt;&lt;p&gt;// ]]]]]]]]&amp;gt;&amp;lt;![CDATA[&amp;gt;&amp;lt;![CDATA[&amp;gt;&amp;lt;![CDATA[&amp;gt;&lt;/p&gt;&lt;p&gt;// ]]]]]]&amp;gt;&amp;lt;![CDATA[&amp;gt;&amp;lt;![CDATA[&amp;gt;&lt;/p&gt;&lt;p&gt;// ]]]]&amp;gt;&amp;lt;![CDATA[&amp;gt;]]&amp;gt;&lt;/script&gt;
&lt;/p&gt;
&lt;/p&gt;&lt;/p&gt;</content></entry><entry><title>Simulating HTTP responses in Django.</title><link href="http://pminkov.github.io/blog/simulating-http-responses-in-django.html" rel="alternate"></link><published>2011-11-11T19:15:00-08:00</published><updated>2011-11-11T19:15:00-08:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2011-11-11:/blog/simulating-http-responses-in-django.html</id><summary type="html">&lt;p&gt;One of the most important aspects of your web application's client side
code is how it handles errors and slow connections. In the case of an
error, some reasonable error message should be displayed and in the case
of a slow connection, the user shouldn't be left staring at the …&lt;/p&gt;</summary><content type="html">&lt;p&gt;One of the most important aspects of your web application's client side
code is how it handles errors and slow connections. In the case of an
error, some reasonable error message should be displayed and in the case
of a slow connection, the user shouldn't be left staring at the web app
wondering why did it freeze and you should at least display a spinning
wheel or some other "in progress" indicator.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
To solve that problem in Django, you can write a simple Django
application that simulates errors and slow connections. The way it works
is by installing a middleware component that catches HTTP requests and
returns error codes, or sleeps for some time before returning.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
I'll illustrate how to implement a very simple version of that idea.
Let's say that you'll have a handler sitting at "/http_simulate", which
when accessed will switch the server from error mode to healthy mode and
then back. The second thing you need is a middleware that knows what
mode the server is in and depending on that, fiddles with the HTTP
request and produces an error HTTP response.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
Here's how a very simple middleware class would look like:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;
&lt;script src="https://gist.github.com/1359978.js"&gt; &lt;/script&gt;
Notice how that middleware class ignores requests which go to the view
that switches to error mode. You want to be able to switch back to
normal mode once you switch to error mode.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
The second part you need is a view that switches the &lt;code&gt;IN_ERROR_MODE&lt;/code&gt;
variable.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;
&lt;script src="https://gist.github.com/1359984.js"&gt; &lt;/script&gt;
After you have this code, you can just create a simple Django
application and install that middleware in your settings.py file. Be
careful to not have that turned on in your production environment.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
There are also many ways in which this can be extended:&lt;/p&gt;
&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Support for different error codes.&lt;/li&gt;
&lt;li&gt;Support for slow connections by sleeping before sending the
    HTTP response.&lt;/li&gt;
&lt;li&gt;Setting error mode for only specific urls, not for every request
    sent to the server.&lt;/li&gt;
&lt;/ul&gt;
&lt;/p&gt;</content></entry></feed>