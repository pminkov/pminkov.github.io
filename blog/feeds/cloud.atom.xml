<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Petko's Coding Blog - Cloud</title><link href="http://pminkov.github.io/blog/" rel="alternate"></link><link href="http://pminkov.github.io/blog/feeds/cloud.atom.xml" rel="self"></link><id>http://pminkov.github.io/blog/</id><updated>2017-07-30T21:57:00-07:00</updated><entry><title>Versioning Docker Images</title><link href="http://pminkov.github.io/blog/versioning-docker-images.html" rel="alternate"></link><published>2017-07-30T21:57:00-07:00</published><updated>2017-07-30T21:57:00-07:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2017-07-30:/blog/versioning-docker-images.html</id><summary type="html">&lt;p&gt;If you're running Docker containers in the cloud, you're probably uploading them into a registry. If you're using Google Cloud, that would be &lt;a href="https://cloud.google.com/container-registry/"&gt;gcr.io &lt;/a&gt;(Google Container Registry).&lt;/p&gt;
&lt;p&gt;As you're iterating on your application, you'll need to push new Docker images to the registry. A natural questions that comes is …&lt;/p&gt;</summary><content type="html">&lt;p&gt;If you're running Docker containers in the cloud, you're probably uploading them into a registry. If you're using Google Cloud, that would be &lt;a href="https://cloud.google.com/container-registry/"&gt;gcr.io &lt;/a&gt;(Google Container Registry).&lt;/p&gt;
&lt;p&gt;As you're iterating on your application, you'll need to push new Docker images to the registry. A natural questions that comes is how to version these images? You don't want to overwrite images using the same tag and it's cumbersome to keep track of increasing version numbers. A good versioning scheme is to use a &lt;a href="https://blog.thoughtram.io/git/2014/11/18/the-anatomy-of-a-git-commit.html"&gt;git commit hash&lt;/a&gt;. So your image name might looks like this: &lt;code&gt;gcr.io/kubeproject-172120/simple:88d38d9&lt;/code&gt;. If you take your git repository at this hash, you'll find the files that produced this exact image.&lt;/p&gt;
&lt;p&gt;This sounds simple to implement. You get the last commit's hash, build the image using the hash as a tag and push it to the registry. There's one big inconvinience to this scheme though - you have to commit each change if you want to use a new hash (and you do, you don't want to overwrite your production image) and when you're iterating on an image, that gets tiresome quickly. One possible solution would be to commit "debug" images. These images might be tagged with something like this &lt;code&gt;88d38d9-debug&lt;/code&gt;. This is an image produced by taking the git repo at the &lt;code&gt;88d38d9&lt;/code&gt; hash and making some modifications. You'll know not to include these images in your production files and it's ok to overwrite them as you're iterating.&lt;/p&gt;
&lt;p&gt;So let's look at how all of this can be implemented. Let's say you're putting all your images in one directory. The contents of this directory might look like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ tree
.
├── build-image.sh
└── simple
    ├── app.py
    ├── Dockerfile
    └── requirements.txt

&lt;span class="m"&gt;1&lt;/span&gt; directory, &lt;span class="m"&gt;4&lt;/span&gt; files
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &lt;code&gt;build-image.sh&lt;/code&gt; script builds the Docker image and pushes it to &lt;code&gt;gcr.io&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The script itself looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; -z &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$1&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt;
  &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Usage: &lt;/span&gt;&lt;span class="nv"&gt;$0&lt;/span&gt;&lt;span class="s2"&gt; &amp;lt;image_dir&amp;gt; [--debug]&amp;quot;&lt;/span&gt;
  &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="nv"&gt;IMAGE_NAME&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$1&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$2&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;--debug&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt;
  &lt;span class="c1"&gt;# If we&amp;#39;re debugging, we can push code that&amp;#39;s not committed.&lt;/span&gt;
  &lt;span class="nv"&gt;APPEND&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;-debug&amp;quot;&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt;
  &lt;span class="nv"&gt;IMAGE_PATH&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/&lt;span class="nv"&gt;$IMAGE_NAME&lt;/span&gt;/

  &lt;span class="k"&gt;if&lt;/span&gt; git status . --porcelain &lt;span class="p"&gt;|&lt;/span&gt; grep &lt;span class="nv"&gt;$IMAGE_PATH&lt;/span&gt; &amp;gt; /dev/null&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;You have uncommited changes to your Docker image. Please commit them&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;before building and populating. This helps ensure that all docker images&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;are traceable back to a git commit.&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Or if you&amp;#39;re just building a debug image, use the --debug flag.&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;
  &lt;span class="k"&gt;fi&lt;/span&gt;
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="c1"&gt;# Set image tag.&lt;/span&gt;
&lt;span class="nv"&gt;GIT_REV&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;git log -n &lt;span class="m"&gt;1&lt;/span&gt; --pretty&lt;span class="o"&gt;=&lt;/span&gt;format:%h -- ./&lt;span class="nv"&gt;$IMAGE_NAME&lt;/span&gt;/&lt;span class="k"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; ! &lt;span class="nv"&gt;$GIT_REV&lt;/span&gt; &lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt;
  &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;You&amp;#39;re trying to build an image that has never been committed.&amp;quot;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;You need to commit at least one version.&amp;quot;&lt;/span&gt;
  &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="nv"&gt;TAG&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$GIT_REV&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$APPEND&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;

&lt;span class="c1"&gt;# Set image repo.&lt;/span&gt;
&lt;span class="nv"&gt;PROJECT_ID&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;gcloud config get-value project &lt;span class="m"&gt;2&lt;/span&gt;&amp;gt;/dev/null&lt;span class="k"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;DOCKER_REPO&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;gcr.io/&lt;/span&gt;&lt;span class="nv"&gt;$PROJECT_ID&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;

&lt;span class="c1"&gt;# Full image name.&lt;/span&gt;
&lt;span class="nv"&gt;IMAGE_SPEC&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$DOCKER_REPO&lt;/span&gt;&lt;span class="s2"&gt;/&lt;/span&gt;&lt;span class="nv"&gt;$IMAGE_NAME&lt;/span&gt;&lt;span class="s2"&gt;:&lt;/span&gt;&lt;span class="nv"&gt;$TAG&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;

&lt;span class="nb"&gt;cd&lt;/span&gt; &lt;span class="nv"&gt;$IMAGE_NAME&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; ! -f &lt;span class="nv"&gt;$DOCKERFILE&lt;/span&gt; &lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt;
  &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;No such file: &lt;/span&gt;&lt;span class="nv"&gt;$IMAGE_NAME&lt;/span&gt;&lt;span class="s2"&gt;/&lt;/span&gt;&lt;span class="nv"&gt;$DOCKERFILE&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
  &lt;span class="nb"&gt;exit&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="nv"&gt;$IMAGE_SPEC&lt;/span&gt;

docker build -t &lt;span class="nv"&gt;$IMAGE_SPEC&lt;/span&gt; .
gcloud docker -- push &lt;span class="nv"&gt;$IMAGE_SPEC&lt;/span&gt;

&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Pushed &lt;/span&gt;&lt;span class="nv"&gt;$IMAGE_SPEC&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;One thing to pay attention to is that the hash that we're using is the hash of the last commit to the directory that contains the container files. This way, if you want to push a production ready image (non-debug), you can only commit the files inside this directory and if you're still working on others outside of it, you can continue doing so.&lt;/p&gt;
&lt;p&gt;Let's run the &lt;code&gt;build-image.sh&lt;/code&gt; script:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ ./build-image.sh simple
gcr.io/kubehub-172120/simple:12430ce
Sending build context to Docker daemon &lt;span class="m"&gt;4&lt;/span&gt;.096 kB
Step &lt;span class="m"&gt;1&lt;/span&gt;/9 : FROM ubuntu:latest
 ---&amp;gt; 14f60031763d
Step &lt;span class="m"&gt;2&lt;/span&gt;/9 : MAINTAINER Petko Minkov &lt;span class="s2"&gt;&amp;quot;pminkov@gmail.com&amp;quot;&lt;/span&gt;
 ---&amp;gt; Using cache
 ---&amp;gt; 5a371036a9e3
Step &lt;span class="m"&gt;3&lt;/span&gt;/9 : RUN apt-get update -y
 ---&amp;gt; Using cache
 ---&amp;gt; 8992277faa20
Step &lt;span class="m"&gt;4&lt;/span&gt;/9 : RUN apt-get install -y python-pip python-dev build-essential
 ---&amp;gt; Using cache
 ---&amp;gt; 9c0937facaf0
Step &lt;span class="m"&gt;5&lt;/span&gt;/9 : COPY . /app
 ---&amp;gt; Using cache
 ---&amp;gt; dd9f289c1f55
Step &lt;span class="m"&gt;6&lt;/span&gt;/9 : WORKDIR /app
 ---&amp;gt; Using cache
 ---&amp;gt; d93c62ac371a
Step &lt;span class="m"&gt;7&lt;/span&gt;/9 : RUN pip install --upgrade pip
 ---&amp;gt; Using cache
 ---&amp;gt; cb2f0a65c93f
Step &lt;span class="m"&gt;8&lt;/span&gt;/9 : RUN pip install -r requirements.txt
 ---&amp;gt; Using cache
 ---&amp;gt; d8fd659127d9
Step &lt;span class="m"&gt;9&lt;/span&gt;/9 : CMD python app.py
 ---&amp;gt; Using cache
 ---&amp;gt; 8493c8ad1a01
Successfully built 8493c8ad1a01
The push refers to a repository &lt;span class="o"&gt;[&lt;/span&gt;gcr.io/kubehub-172120/simple&lt;span class="o"&gt;]&lt;/span&gt;
dacb974e8350: Layer already exists 
6c4d57527510: Layer already exists 
5348dff0fc19: Layer already exists 
738da70fc9f8: Layer already exists 
f665434eb0ee: Layer already exists 
26b126eb8632: Layer already exists 
220d34b5f6c9: Layer already exists 
8a5132998025: Layer already exists 
aca233ed29c3: Layer already exists 
e5d2f035d7a4: Layer already exists 
12430ce: digest: sha256:51cd80db604d1ffa5230289c1f3fe40d19b3b8dc2afb0a0c003713360b07d2c6 size: &lt;span class="m"&gt;2411&lt;/span&gt;
Pushed gcr.io/kubehub-172120/simple:12430ce
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Great, now the image is pushed. But I always like to use a "trust but verify" policy, so let's see how can we dig into what's going on at the registry.&lt;/p&gt;
&lt;p&gt;My image's name is this &lt;code&gt;gcr.io/kubehub-172120/simple&lt;/code&gt;. Here's how I see the tags I have uploaded to &lt;code&gt;gcr.io&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ gcloud beta container images list-tags gcr.io/kubehub-172120/simple
DIGEST        TAGS                   TIMESTAMP
9b424f849df2  88d38d9-debug,e8bc006  &lt;span class="m"&gt;2017&lt;/span&gt;-07-30T23:03:14
51cd80db604d  12430ce                &lt;span class="m"&gt;2017&lt;/span&gt;-07-30T23:06:42
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If you want to inspect the contents of the image, you can just run a shell, like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ gcloud docker -- run -i -t gcr.io/kubehub-172120/simple:12430ce /bin/bash
root@27cfb042d947:/app# ls
Dockerfile  app.py  requirements.txt
root@27cfb042d947:/app# 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I've used this workflow when working with a Kubernetes deployment and it worked well for me. Hope it's useful for someone else too. Enjoy.&lt;/p&gt;</content></entry><entry><title>Removing a node from a Kubernetes cluster on GKE (Google Container Engine)</title><link href="http://pminkov.github.io/blog/removing-a-node-from-a-kubernetes-cluster-on-gke-google-container-engine.html" rel="alternate"></link><published>2017-03-30T16:17:00-07:00</published><updated>2017-03-30T16:17:00-07:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2017-03-30:/blog/removing-a-node-from-a-kubernetes-cluster-on-gke-google-container-engine.html</id><summary type="html">&lt;p&gt;In this post, I'll describe how to remove a particular node from a Kubernetes cluster on GKE. Why would you want to do that? In my case, I'm running jupyterhub and I need to do that as part of implementing cluster scaling. That's probably a rare need, but it helped …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In this post, I'll describe how to remove a particular node from a Kubernetes cluster on GKE. Why would you want to do that? In my case, I'm running jupyterhub and I need to do that as part of implementing cluster scaling. That's probably a rare need, but it helped me understand more about the GCE structures behind a Kubernetes cluster.&lt;/p&gt;
&lt;p&gt;So let's start. The first thing you need to do is:&lt;/p&gt;
&lt;h3 id="drain-your-node"&gt;Drain your node&lt;/h3&gt;
&lt;p&gt;Let's look at my nodes:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ kl get nodes
NAME                                      STATUS    AGE
gke-jcluster-default-pool-9cc4e660-rx9p   Ready     1d
gke-jcluster-default-pool-9cc4e660-xr4z   Ready     2d
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I want to remove rx9p. I'll first &lt;a href="https://kubernetes.io/docs/tasks/administer-cluster/safely-drain-node/"&gt;drain&lt;/a&gt; it:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ kl drain gke-jcluster-default-pool-9cc4e660-rx9p  --force
node &lt;span class="s2"&gt;&amp;quot;gke-jcluster-default-pool-9cc4e660-rx9p&amp;quot;&lt;/span&gt; cordoned
error: pods with &lt;span class="nb"&gt;local&lt;/span&gt; storage &lt;span class="o"&gt;(&lt;/span&gt;use --delete-local-data to override&lt;span class="o"&gt;)&lt;/span&gt;: jupyter-petko-1
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Great, the node is now drained. Next is:&lt;/p&gt;
&lt;h3 id="removing-the-gce-vm"&gt;Removing the GCE VM&lt;/h3&gt;
&lt;p&gt;Your Kubernetes cluster runs in an &lt;a href="https://cloud.google.com/compute/docs/instance-groups/"&gt;instance group&lt;/a&gt;. We'll need to know what this group is. Here's how to do it from the command line.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ &lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;GROUP_ID&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;gcloud container clusters describe jcluster --format json &lt;span class="p"&gt;|&lt;/span&gt; jq  --raw-output &lt;span class="s1"&gt;&amp;#39;.instanceGroupUrls[0]&amp;#39;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; rev &lt;span class="p"&gt;|&lt;/span&gt; cut -d&lt;span class="s1"&gt;&amp;#39;/&amp;#39;&lt;/span&gt; -f &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; rev&lt;span class="k"&gt;)&lt;/span&gt;
$ &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="nv"&gt;$GROUP_ID&lt;/span&gt;
gke-jcluster-default-pool-9cc4e660-grp
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Let's check my instances:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ gcloud compute instances list
NAME                                     ZONE           MACHINE_TYPE   PREEMPTIBLE  INTERNAL_IP  EXTERNAL_IP      STATUS
gke-jcluster-default-pool-9cc4e660-rx9p  us-central1-b  n1-standard-1               &lt;span class="m"&gt;10&lt;/span&gt;.128.0.2   &lt;span class="m"&gt;104&lt;/span&gt;.198.174.222  RUNNING
gke-jcluster-default-pool-9cc4e660-xr4z  us-central1-b  n1-standard-1               &lt;span class="m"&gt;10&lt;/span&gt;.128.0.4   &lt;span class="m"&gt;104&lt;/span&gt;.197.237.135  RUNNING
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If I just run &lt;code&gt;gcloud compute instances delete&lt;/code&gt; that won't work! That's because I have an instance group of size 2 and if I delete one of the machines, GCE will start a new one. I have to use the &lt;code&gt;gcloud compute  instance-groups managed delete-instances&lt;/code&gt; command, followed by &lt;code&gt;gcloud compute instance-groups managed wait-until-stable&lt;/code&gt; if I want to wait until the job is done.&lt;/p&gt;
&lt;p&gt;Let's see how that looks like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ gcloud compute instance-groups managed delete-instances &lt;span class="nv"&gt;$GROUP_ID&lt;/span&gt; --instances&lt;span class="o"&gt;=&lt;/span&gt;gke-jcluster-default-pool-9cc4e660-rx9p
Updated &lt;span class="o"&gt;[&lt;/span&gt;https://www.googleapis.com/compute/v1/projects/myhub-161019/zones/us-central1-b/instanceGroupManagers/gke-jcluster-default-pool-9cc4e660-grp&lt;span class="o"&gt;]&lt;/span&gt;.
---
baseInstanceName: gke-jcluster-default-pool-9cc4e660
creationTimestamp: &lt;span class="s1"&gt;&amp;#39;2017-03-25T02:52:22.040-07:00&amp;#39;&lt;/span&gt;
currentActions:
  abandoning: &lt;span class="m"&gt;0&lt;/span&gt;
  creating: &lt;span class="m"&gt;0&lt;/span&gt;
  creatingWithoutRetries: &lt;span class="m"&gt;0&lt;/span&gt;
  deleting: &lt;span class="m"&gt;1&lt;/span&gt;
  none: &lt;span class="m"&gt;1&lt;/span&gt;
  recreating: &lt;span class="m"&gt;0&lt;/span&gt;
  refreshing: &lt;span class="m"&gt;0&lt;/span&gt;
  restarting: &lt;span class="m"&gt;0&lt;/span&gt;
fingerprint: &lt;span class="nv"&gt;kUg7ggCEudY&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;
id: &lt;span class="s1"&gt;&amp;#39;6475008099735012154&amp;#39;&lt;/span&gt;
instanceGroup: gke-jcluster-default-pool-9cc4e660-grp
instanceTemplate: gke-jcluster-default-pool-9cc4e660
kind: compute#instanceGroupManager
name: gke-jcluster-default-pool-9cc4e660-grp
selfLink: https://www.googleapis.com/compute/v1/projects/myhub-161019/zones/us-central1-b/instanceGroupManagers/gke-jcluster-default-pool-9cc4e660-grp
targetSize: &lt;span class="m"&gt;1&lt;/span&gt;
zone: us-central1-b
$ gcloud compute instance-groups managed wait-until-stable &lt;span class="nv"&gt;$GROUP_ID&lt;/span&gt;
Waiting &lt;span class="k"&gt;for&lt;/span&gt; group to become stable, current operations: deleting: &lt;span class="m"&gt;1&lt;/span&gt;
...
Waiting &lt;span class="k"&gt;for&lt;/span&gt; group to become stable, current operations: deleting: &lt;span class="m"&gt;1&lt;/span&gt;
Group is stable
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And indeed, we only have one node left now:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ kl get nodes
gcloud compute instanceNAME                                      STATUS    AGE
gke-jcluster-default-pool-9cc4e660-xr4z   Ready     2d
$ gcloud compute instances list
NAME                                     ZONE           MACHINE_TYPE   PREEMPTIBLE  INTERNAL_IP  EXTERNAL_IP      STATUS
gke-jcluster-default-pool-9cc4e660-xr4z  us-central1-b  n1-standard-1               &lt;span class="m"&gt;10&lt;/span&gt;.128.0.4   &lt;span class="m"&gt;104&lt;/span&gt;.197.237.135  RUNNING
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So that's it. Regardless of whether you need to delete individual nodes, it's interesting to take a look at how you can do that.&lt;/p&gt;</content></entry><entry><title>Starting with Kubernetes on Google Container Engine</title><link href="http://pminkov.github.io/blog/starting-with-kubernetes-on-google-container-engine.html" rel="alternate"></link><published>2017-03-07T12:42:00-08:00</published><updated>2017-03-07T12:42:00-08:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2017-03-07:/blog/starting-with-kubernetes-on-google-container-engine.html</id><summary type="html">&lt;p&gt;This is a tutorial of how to run a simple Kubernetes app on &lt;a href="https://cloud.google.com/container-engine/"&gt;GKE&lt;/a&gt; (Google Container Engine).&lt;/p&gt;
&lt;p&gt;&lt;a href="https://kubernetes.io/"&gt;Kubernetes&lt;/a&gt; is a container orchestration software that started at Google. Right now it's an open source project maintained by &lt;a href="https://www.cncf.io/"&gt;Cloud Native Computing Foundation&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;So what's Kubernetes all about? Roughly, it's about managing a …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is a tutorial of how to run a simple Kubernetes app on &lt;a href="https://cloud.google.com/container-engine/"&gt;GKE&lt;/a&gt; (Google Container Engine).&lt;/p&gt;
&lt;p&gt;&lt;a href="https://kubernetes.io/"&gt;Kubernetes&lt;/a&gt; is a container orchestration software that started at Google. Right now it's an open source project maintained by &lt;a href="https://www.cncf.io/"&gt;Cloud Native Computing Foundation&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;So what's Kubernetes all about? Roughly, it's about managing a cluster (a set of machines) on which we have containers running. &lt;/p&gt;
&lt;h3 id="why-containers"&gt;Why containers?&lt;/h3&gt;
&lt;p&gt;Well, that's a question that probably has a lot of answers, but containers are very lightweight virtual machines more or less. The technology under them is different than virtual machines though. We can orchestrate a set of VMs, but containers are much easier to work with. For example I have one VM running on my MacBook - it eats a lot of memory, it's managed by VirtualBox, it has a lot of stuff installed on it. I can't imagine having to run a bunch of these. Containers though, they're much easier to setup (you just write a text file that describes them - the Dockerfile) and much more lightweight. Their memory footprint can be pretty low. Containers can run on different OSs, some of which are very lightweight. Ok, enough about containers - back to Kubernetes.&lt;/p&gt;
&lt;h3 id="whats-in-a-cluster"&gt;What's in a cluster?&lt;/h3&gt;
&lt;p&gt;I mentioned clusters. But what's a cluster. A cluster has a set of nodes (think computers) on which we have pods, where each pod is a unit that contains several containers. That's the basic structure.&lt;/p&gt;
&lt;h3 id="running-a-simple-kubernetes-app-on-gke"&gt;Running a simple Kubernetes app on GKE.&lt;/h3&gt;
&lt;p&gt;Alright, let's roll our sleeves. Google has its own &lt;a href="https://cloud.google.com/container-engine/docs/quickstart"&gt;Quickstart&lt;/a&gt; tutorial, but what I don't like about it is that it doesn't describe how to create your own container and it doesn't talk about the Kubernetes dashboard. But a lot of the steps here you can see in Google's tutorial as well.&lt;/p&gt;
&lt;p&gt;So let's start.&lt;/p&gt;
&lt;h3 id="create-a-project"&gt;Create a project.&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Go to the &lt;a href="https://console.cloud.google.com"&gt;Cloud Console&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Create a project. Mine is called "mykube". Every project has an id that you're mostly working with. Mine is &lt;code&gt;mykube-160819&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="install-necessary-tools-and-initialize-them"&gt;Install necessary tools and initialize them.&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Install the &lt;a href="https://cloud.google.com/sdk/downloads"&gt;Google Cloud SDK&lt;/a&gt;. There's a web interface for working with the SDK, called Google Cloud Shell, but I like having the tools installed locally.&lt;/li&gt;
&lt;li&gt;Initialize gcloud by running &lt;code&gt;gcloud init&lt;/code&gt;. You'll be asked for the name of your project.&lt;/li&gt;
&lt;li&gt;Set a &lt;a href="https://cloud.google.com/compute/docs/regions-zones/regions-zones#available"&gt;Compute Engine zone&lt;/a&gt;, like this:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gcloud config &lt;span class="nb"&gt;set&lt;/span&gt; compute/zone us-central1-b
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;That's it. You can view your configuration:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ gcloud config list
Your active configuration is: &lt;span class="o"&gt;[&lt;/span&gt;mykube&lt;span class="o"&gt;]&lt;/span&gt;

&lt;span class="o"&gt;[&lt;/span&gt;compute&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;zone&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; us-central1-b
&lt;span class="o"&gt;[&lt;/span&gt;core&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="nv"&gt;account&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; pminkov@gmail.com
&lt;span class="nv"&gt;disable_usage_reporting&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; False
&lt;span class="nv"&gt;project&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; mykube-160819
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Let's authenticate gcloud too:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gcloud auth application-default login
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id="run-a-container-image"&gt;Run a container image.&lt;/h3&gt;
&lt;p&gt;Our container is going to be a node.js application that we'll build ourselves. I wanted to experiment with an app that takes a bit more memory, so here's how my code looks like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nx"&gt;$&lt;/span&gt; &lt;span class="nx"&gt;cat&lt;/span&gt; &lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nx"&gt;server&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;js&lt;/span&gt; 
&lt;span class="kd"&gt;function&lt;/span&gt; &lt;span class="nx"&gt;randomInt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;Math&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;floor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;Math&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;random&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nx"&gt;n&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;http&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;require&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;http&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;N&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;20000000&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;nums&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nb"&gt;Array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;N&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="nx"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="nx"&gt;N&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="nx"&gt;i&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nx"&gt;nums&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;randomInt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;N&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;handleRequest&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kd"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;request&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;response&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nx"&gt;console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Received request for URL: &amp;#39;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nx"&gt;request&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;url&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="nx"&gt;response&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;writeHead&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;randomInt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;N&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="nx"&gt;response&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Returning element at index &amp;#39;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nx"&gt;index&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;: &amp;#39;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nx"&gt;nums&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;index&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;\n&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="nx"&gt;response&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;end&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Hello World!&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;};&lt;/span&gt;
&lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;www&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;http&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;createServer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;handleRequest&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="nx"&gt;console&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Listening on port 8080&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="nx"&gt;www&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;listen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;8080&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We also need a Dockerfile:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ cat ./Dockerfile 
FROM node:4
EXPOSE &lt;span class="m"&gt;8080&lt;/span&gt;
COPY server.js .
CMD node server.js
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In order to run a container on GKE, we need to upload it to &lt;a href="https://cloud.google.com/container-registry/"&gt;Google Container Registry&lt;/a&gt;. Let's do it:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ &lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;PROJECT_ID&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;mykube-160819
$ docker build -t gcr.io/&lt;span class="nv"&gt;$PROJECT_ID&lt;/span&gt;/myserver .
Sending build context to Docker daemon &lt;span class="m"&gt;3&lt;/span&gt;.584 kB
Step &lt;span class="m"&gt;1&lt;/span&gt;/4 : FROM node:4
 ---&amp;gt; d7efee1f035d
Step &lt;span class="m"&gt;2&lt;/span&gt;/4 : EXPOSE &lt;span class="m"&gt;8080&lt;/span&gt;
 ---&amp;gt; Using cache
 ---&amp;gt; 147e7888542d
Step &lt;span class="m"&gt;3&lt;/span&gt;/4 : COPY server.js .
 ---&amp;gt; Using cache
 ---&amp;gt; b610e7975d20
Step &lt;span class="m"&gt;4&lt;/span&gt;/4 : CMD node server.js
 ---&amp;gt; Using cache
 ---&amp;gt; 4e15133cdab2
Successfully built 4e15133cdab2
$ gcloud docker -- push gcr.io/&lt;span class="nv"&gt;$PROJECT_ID&lt;/span&gt;/myserver
The push refers to a repository &lt;span class="o"&gt;[&lt;/span&gt;gcr.io/mykube-160819/myserver&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="c1"&gt;# Note that I already have a project called &amp;quot;hikube&amp;quot; which has the same docker image.&lt;/span&gt;
&lt;span class="c1"&gt;# The &amp;quot;mykube&amp;quot; project is something I created for this tutorial.&lt;/span&gt;
1bcf3881e79d: Mounted from hikube-160719/myserver 
65e403c25ee9: Mounted from hikube-160719/myserver 
4732c3666dd7: Mounted from hikube-160719/myserver 
a1fbf6fa923f: Mounted from hikube-160719/myserver 
1b8ef9ac5116: Mounted from hikube-160719/myserver 
41ef8cc0bccb: Mounted from hikube-160719/myserver 
100396c46221: Mounted from hikube-160719/myserver 
7b4b54c74241: Mounted from hikube-160719/myserver 
d17d48b2382a: Mounted from hikube-160719/myserver 
latest: digest: sha256:4ad68f056e870938823f6c9555355c149cf7c42a213d7243d915f1a4bcfb9cb1 size: &lt;span class="m"&gt;2213&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If you go to the Google Cloud Console and open the Google Container Registry, you'll see the container uploaded:&lt;/p&gt;
&lt;p&gt;&lt;center&gt;&lt;img alt="Google Container Registry" src="http://pminkov.github.io/blog/images/k8s-intro/k1-registry.png"&gt;&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;Now let's create a cluster that we'll be deploying our server to:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ gcloud container clusters create example-cluster
Creating cluster example-cluster...done.                                                                                                                                               
Created &lt;span class="o"&gt;[&lt;/span&gt;https://container.googleapis.com/v1/projects/mykube-160819/zones/us-central1-b/clusters/example-cluster&lt;span class="o"&gt;]&lt;/span&gt;.
kubeconfig entry generated &lt;span class="k"&gt;for&lt;/span&gt; example-cluster.
NAME             ZONE           MASTER_VERSION  MASTER_IP       MACHINE_TYPE   NODE_VERSION  NUM_NODES  STATUS
example-cluster  us-central1-b  &lt;span class="m"&gt;1&lt;/span&gt;.5.3           &lt;span class="m"&gt;104&lt;/span&gt;.198.190.52  n1-standard-1  &lt;span class="m"&gt;1&lt;/span&gt;.5.3         &lt;span class="m"&gt;3&lt;/span&gt;          RUNNING
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Congratulations! We have a cluster running.&lt;/p&gt;
&lt;p&gt;A little segway. kubectl has a config that determines which cluster you're working with. You can switch between different clusters. Try it:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ kubectl config current-context
gke_mykube-160819_us-central1-b_example-cluster
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We're good here - our context is for the "mykube" cluster. The cluster is empty, we can verify it like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ kubectl get pods
No resources found.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now let's start out server finally:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ kubectl run myserver --image&lt;span class="o"&gt;=&lt;/span&gt;gcr.io/&lt;span class="nv"&gt;$PROJECT_ID&lt;/span&gt;/myserver --port&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;8080&lt;/span&gt;
deployment &lt;span class="s2"&gt;&amp;quot;myserver&amp;quot;&lt;/span&gt; created
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We have created a deployment that contains a pod. Let's see what pods we have now:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ kubectl get pods
NAME                        READY     STATUS              RESTARTS   AGE
myserver-3430466764-04b36   &lt;span class="m"&gt;0&lt;/span&gt;/1       ContainerCreating   &lt;span class="m"&gt;0&lt;/span&gt;          17s
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Nice, our container is getting spinned. We wait for a bit and we see:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ kubectl get pods
NAME                        READY     STATUS    RESTARTS   AGE
myserver-3430466764-04b36   &lt;span class="m"&gt;1&lt;/span&gt;/1       Running   &lt;span class="m"&gt;0&lt;/span&gt;          58s
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can now expose the container:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ kubectl expose deployment myserver --type&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;LoadBalancer&amp;quot;&lt;/span&gt;
service &lt;span class="s2"&gt;&amp;quot;myserver&amp;quot;&lt;/span&gt; exposed
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This will also take some time:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ kubectl get service myserver
NAME       CLUSTER-IP   EXTERNAL-IP   PORT&lt;span class="o"&gt;(&lt;/span&gt;S&lt;span class="o"&gt;)&lt;/span&gt;          AGE
myserver   &lt;span class="m"&gt;10&lt;/span&gt;.3.247.6   &amp;lt;pending&amp;gt;     &lt;span class="m"&gt;8080&lt;/span&gt;:31574/TCP   34s
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Aaand, it's done:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ kubectl get service myserver
NAME       CLUSTER-IP   EXTERNAL-IP      PORT&lt;span class="o"&gt;(&lt;/span&gt;S&lt;span class="o"&gt;)&lt;/span&gt;          AGE
myserver   &lt;span class="m"&gt;10&lt;/span&gt;.3.247.6   &lt;span class="m"&gt;104&lt;/span&gt;.155.177.47   &lt;span class="m"&gt;8080&lt;/span&gt;:31574/TCP   1m
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If we go to &lt;code&gt;http://104.155.177.47:8080/&lt;/code&gt;, we'll see:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Returning element at index &lt;span class="m"&gt;6110645&lt;/span&gt;: &lt;span class="m"&gt;116527640&lt;/span&gt;
Hello World!
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now, the tedious part is over. Let's have some fun. We can monitor our cluster through the Kubernetes dashboard. For a reason unclear to me, this dashboard is not available on the Google website. You have to run a proxy to do it. Like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ kubectl proxy
Starting to serve on &lt;span class="m"&gt;127&lt;/span&gt;.0.0.1:8001
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can see the dashboard at &lt;code&gt;localhost:8001/ui&lt;/code&gt;. It looks like this:&lt;/p&gt;
&lt;p&gt;&lt;center&gt;&lt;img alt="Kubernetes Dashboard" src="http://pminkov.github.io/blog/images/k8s-intro/k2-dashboard.png"&gt;&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;This dashboard is a lot of fun. You can dig into everything available in it. You can probably see everything it shows through kubectl as well, but it's easier to do it by using an UI.&lt;/p&gt;
&lt;p&gt;Here's something else that's fun. Your cluster doesn't run on thin air. It runs on Google Compute Engine instances (I believe this is equivalent to AWS' EC2). In your cloud console, you can navigate to your instances and you can even SSH to an instance from the web UI (I wow-ed the first time I did this, much easier than setting up ssh access on AWS).&lt;/p&gt;
&lt;p&gt;Our cluster has three nodes.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ kubectl get nodes
NAME                                             STATUS    AGE
gke-example-cluster-default-pool-2567fc65-1h40   Ready     21m
gke-example-cluster-default-pool-2567fc65-g7lc   Ready     21m
gke-example-cluster-default-pool-2567fc65-n0cp   Ready     21m
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;These are three GCE instances. Where is our pod running at?&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ kubectl get pods -o wide
NAME                        READY     STATUS    RESTARTS   AGE       IP         NODE
myserver-3430466764-04b36   &lt;span class="m"&gt;1&lt;/span&gt;/1       Running   &lt;span class="m"&gt;0&lt;/span&gt;          18m       &lt;span class="m"&gt;10&lt;/span&gt;.0.1.5   gke-example-cluster-default-pool-2567fc65-g7lc
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It's running on &lt;code&gt;gke-example-cluster-default-pool-2567fc65-g7lc&lt;/code&gt;. Now I can navigate to the web page for this instance and ssh to it. Here's a screenshot of how that looks like:&lt;/p&gt;
&lt;p&gt;&lt;center&gt;&lt;img alt="Compute Engine SSH" src="http://pminkov.github.io/blog/images/k8s-intro/k3-compute-engine.png"&gt;&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;I ran &lt;code&gt;ps aux --sort '%mem'&lt;/code&gt; to see which process takes most memory. Since my server uses a lot of memory, it's at the top. It's using 179MB of resident memory.&lt;/p&gt;
&lt;p&gt;It's pretty nice that you're able to nagivate from a high level system like Kubernetes all the way down to ssh-ing to a machine that runs your containers. When you're ssh-ed you can execute &lt;code&gt;docker ps&lt;/code&gt; to see what containers are running, run &lt;code&gt;top&lt;/code&gt; to see what's going on on the machine and do all of the other systems debugging tasks that you can think of.&lt;/p&gt;
&lt;p&gt;And finally, let's delete our cluster:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ gcloud container clusters delete example-cluster
The following clusters will be deleted.
 - &lt;span class="o"&gt;[&lt;/span&gt;example-cluster&lt;span class="o"&gt;]&lt;/span&gt; in &lt;span class="o"&gt;[&lt;/span&gt;us-central1-b&lt;span class="o"&gt;]&lt;/span&gt;

Do you want to &lt;span class="k"&gt;continue&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;Y/n&lt;span class="o"&gt;)&lt;/span&gt;?  

Deleting cluster example-cluster...done.                                                                                                                                               
Deleted &lt;span class="o"&gt;[&lt;/span&gt;https://container.googleapis.com/v1/projects/mykube-160819/zones/us-central1-b/clusters/example-cluster&lt;span class="o"&gt;]&lt;/span&gt;.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;That's all for today - enjoy.&lt;/p&gt;</content></entry><entry><title>How to shut down and restore an Elastic Beanstalk environment.</title><link href="http://pminkov.github.io/blog/how-to-shut-down-and-restore-an-elastic-beanstalk-environment.html" rel="alternate"></link><published>2017-01-30T12:07:00-08:00</published><updated>2017-01-30T12:07:00-08:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2017-01-30:/blog/how-to-shut-down-and-restore-an-elastic-beanstalk-environment.html</id><summary type="html">&lt;p&gt;Let's say you're running an &lt;a href="https://aws.amazon.com/elasticbeanstalk/"&gt;Elastic Beanstalk&lt;/a&gt; application. You might want to stop it so that you're not paying money for it. There's one way to do this by running commands. You can use &lt;code&gt;eb terminate&lt;/code&gt; and &lt;code&gt;eb restore&lt;/code&gt;, but if you terminate a setup with a database and you …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Let's say you're running an &lt;a href="https://aws.amazon.com/elasticbeanstalk/"&gt;Elastic Beanstalk&lt;/a&gt; application. You might want to stop it so that you're not paying money for it. There's one way to do this by running commands. You can use &lt;code&gt;eb terminate&lt;/code&gt; and &lt;code&gt;eb restore&lt;/code&gt;, but if you terminate a setup with a database and you restore it, the contents of the database won't be restored. You can also only restore an environment that has been terminated within the last 6 weeks.&lt;/p&gt;
&lt;p&gt;Let's see how we can terminate and restore without the 6 weeks restriction and let's also see how does the database backup and restore look like.&lt;/p&gt;
&lt;p&gt;The first thing that you have to do is to save your environment, which pretty much consists of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Elastic Beanstalk &lt;a href="http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/environment-configuration-savedconfig.html"&gt;configuration&lt;/a&gt;. This is located in the &lt;code&gt;.elasticbeanstalk&lt;/code&gt; directory.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/ebextensions.html"&gt;Environment customizations&lt;/a&gt;. They're located in the &lt;code&gt;.ebextensions&lt;/code&gt; directory.&lt;/li&gt;
&lt;li&gt;Your source code. Located in your base directory.&lt;/li&gt;
&lt;li&gt;A database (optional).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;My particular app is a single instance Python/Django application with a MySQL database hosted in RDS.&lt;/p&gt;
&lt;p&gt;So let's get started.&lt;/p&gt;
&lt;h2 id="backing-up-your-environment"&gt;Backing up your environment.&lt;/h2&gt;
&lt;p&gt;First, get the name of your environment. Mine is &lt;code&gt;neatlinks-dev&lt;/code&gt;. Run the following commands after that:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;EB_DATE_LABEL&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;date +&lt;span class="s2"&gt;&amp;quot;D%F-T%H-%M-%S&amp;quot;&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;

&lt;span class="c1"&gt;# Name of saved config.&lt;/span&gt;
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;EB_CONFIG&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;saved-&lt;span class="nv"&gt;$EB_DATE_LABEL&lt;/span&gt;

&lt;span class="c1"&gt;# Name of database snapshot.&lt;/span&gt;
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;EB_SNAPSHOT_NAME&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;snapshot-&lt;span class="nv"&gt;$EB_DATE_LABEL&lt;/span&gt;

&lt;span class="c1"&gt;# Instance id for our current database.&lt;/span&gt;
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;EB_DB&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;aaeag9ndvxonft&amp;quot;&lt;/span&gt;

&lt;span class="c1"&gt;# Save the environment cname, we&amp;#39;ll need it later.&lt;/span&gt;
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;EB_CNAME&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;neatlinks-dev-www&amp;#39;&lt;/span&gt;

&lt;span class="c1"&gt;# Save current config.&lt;/span&gt;
eb config save neatlinks-dev --cfg &lt;span class="nv"&gt;$EB_CONFIG&lt;/span&gt;

&lt;span class="c1"&gt;# Create and wait for database snapshot.&lt;/span&gt;
aws rds create-db-snapshot &lt;span class="se"&gt;\&lt;/span&gt;
    --db-instance-identifier &lt;span class="nv"&gt;$EB_DB&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    --db-snapshot-identifier &lt;span class="nv"&gt;$EB_SNAPSHOT_NAME&lt;/span&gt;
&lt;span class="nb"&gt;time&lt;/span&gt; aws rds &lt;span class="nb"&gt;wait&lt;/span&gt; db-snapshot-completed &lt;span class="se"&gt;\&lt;/span&gt;
    --db-instance-identifier &lt;span class="nv"&gt;$EB_DB&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    --db-snapshot-identifier &lt;span class="nv"&gt;$EB_SNAPSHOT_NAME&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So we did two things:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;We saved the environment configuration. You can list your saved configurations by running &lt;code&gt;eb config list&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;We created a snapshot of the database.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;At this point we can terminate our environment by calling &lt;code&gt;eb terminate&lt;/code&gt;. And that's it - Amazon is not charging you anymore - your EC2 instance, RDS instance, load balancers, etc. are down. I don't have a load balancer, but I can verify that everything else is gone.&lt;/p&gt;
&lt;p&gt;You should now commit your configs to your source control so that you have them saved when you come back.&lt;/p&gt;
&lt;p&gt;Now, your application is sitting safely saved for a while and you decide to restore it.&lt;/p&gt;
&lt;h2 id="restoring-your-environment"&gt;Restoring your environment.&lt;/h2&gt;
&lt;p&gt;If you have deleted your application, you'll need to run &lt;code&gt;eb init&lt;/code&gt;. After that, we'll run the following commands:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Create environment. It&amp;#39;s important to specify a cname, so that we don&amp;#39;t have to&lt;/span&gt;
&lt;span class="c1"&gt;# change our DNS config. This takes a lot of time, so I bump the timeout.&lt;/span&gt;
&lt;span class="c1"&gt;# This command will print the name of your new database instance.&lt;/span&gt;
&lt;span class="nb"&gt;time&lt;/span&gt; eb create neatlinks-dev --cfg &lt;span class="nv"&gt;$EB_CONFIG&lt;/span&gt; --cname &lt;span class="nv"&gt;$EB_CNAME&lt;/span&gt; --timeout &lt;span class="m"&gt;30&lt;/span&gt;

&lt;span class="c1"&gt;# Get this id from the printed output of &amp;quot;eb create&amp;quot;.&lt;/span&gt;
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;EB_NEW_DB&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;aa1q3no37rzd407&amp;quot;&lt;/span&gt;

&lt;span class="c1"&gt;# Delete DB instance. We&amp;#39;ll replace it with the snapshot.&lt;/span&gt;
aws rds delete-db-instance --db-instance-identifier &lt;span class="nv"&gt;$EB_NEW_DB&lt;/span&gt; --skip-final-snapshot
aws rds &lt;span class="nb"&gt;wait&lt;/span&gt; db-instance-deleted --db-instance-identifier &lt;span class="nv"&gt;$EB_NEW_DB&lt;/span&gt;

&lt;span class="c1"&gt;# Restore from snapshot.&lt;/span&gt;
aws rds restore-db-instance-from-db-snapshot &lt;span class="se"&gt;\&lt;/span&gt;
        --db-instance-identifier &lt;span class="nv"&gt;$EB_NEW_DB&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
        --db-snapshot-identifier &lt;span class="nv"&gt;$EB_SNAPSHOT_NAME&lt;/span&gt;
aws rds &lt;span class="nb"&gt;wait&lt;/span&gt; db-instance-available --db-instance-identifier &lt;span class="nv"&gt;$EB_NEW_DB&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Your production setup is ready now! Your application probably won't work though, because your DB endpoint is different. Edit your source code or your own configuration files so that your application connects to the new database. Once done, call &lt;code&gt;eb deploy&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;That's it. Your application should be running now. You can use this procedure to rename your Elastic Beanstalk application and environment as well, which is a feature that's missing from the &lt;code&gt;eb&lt;/code&gt; CLI app.&lt;/p&gt;</content></entry><entry><title>The Cloud Infrastructure Landscape</title><link href="http://pminkov.github.io/blog/the-cloud-infrastructure-landscape.html" rel="alternate"></link><published>2017-01-15T12:10:00-08:00</published><updated>2017-01-15T12:10:00-08:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2017-01-15:/blog/the-cloud-infrastructure-landscape.html</id><summary type="html">&lt;p&gt;I'm taking a &lt;a href="https://www.edx.org/course/introduction-cloud-infrastructure-linuxfoundationx-lfs151-x"&gt;Cloud Infrastructure&lt;/a&gt; class on EdX and I have found it to be a really nice overview of the cloud space. It's missing anything related to Hadoop and data analytics, but it describes probably all the tools related to running applications in the cloud. Of course, since the …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I'm taking a &lt;a href="https://www.edx.org/course/introduction-cloud-infrastructure-linuxfoundationx-lfs151-x"&gt;Cloud Infrastructure&lt;/a&gt; class on EdX and I have found it to be a really nice overview of the cloud space. It's missing anything related to Hadoop and data analytics, but it describes probably all the tools related to running applications in the cloud. Of course, since the class describes so many tools, it can't do so in depth, but you can pick whatever is interesting to you and learn more about it.&lt;/p&gt;
&lt;p&gt;Here's a list of all the tools described in it, which list I might use as a future reference for myself. I'd say that knowing a bit about such a big amount of products definitely helps when you're trying to come up with a cloud infrastructure for a project.&lt;/p&gt;
&lt;p&gt;So, big list, based on the course contents:&lt;/p&gt;
&lt;h3 id="virtualization"&gt;Virtualization&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://www.linux-kvm.org/page/Main_Page"&gt;KVM&lt;/a&gt;&lt;br&gt;
&lt;a href="https://www.virtualbox.org/wiki/VirtualBox"&gt;VirtualBox&lt;/a&gt;&lt;br&gt;
&lt;a href="https://www.vagrantup.com/"&gt;Vagrant&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;I use VirtualBox to run Linux on Mac OS X and highly recommend it. Mac OS X is not good if you're trying to learn Linux, too many differences.&lt;/p&gt;
&lt;h3 id="infrastructure-as-a-service-iaas"&gt;Infrastructure as a Service (IaaS)&lt;br&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://aws.amazon.com/ec2/"&gt;Amazon EC2&lt;/a&gt;&lt;br&gt;
&lt;a href="https://azure.microsoft.com/en-us/services/virtual-machines/?b=16.51a"&gt;Azure Virtual Machines&lt;/a&gt;&lt;br&gt;
&lt;a href="https://www.digitalocean.com/"&gt;Digital Ocean&lt;/a&gt;&lt;br&gt;
&lt;a href="https://cloud.google.com/compute/"&gt;Google Compute Engine&lt;/a&gt;&lt;br&gt;
&lt;a href="https://www.openstack.org/"&gt;OpenStack&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;I've only tried EC2 out of these, but it's pretty simple and I like the fact that you can do so many things through the UI, it makes it easier to start with it.&lt;/p&gt;
&lt;h3 id="platform-as-a-sevice-paas"&gt;Platform as a Sevice (PaaS)&lt;br&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://www.cloudfoundry.org/learn/features/"&gt;Cloud Foundry&lt;/a&gt;&lt;br&gt;
&lt;a href="https://www.openshift.com/"&gt;OpenShift&lt;/a&gt;&lt;br&gt;
&lt;a href="https://www.heroku.com/"&gt;Heroku&lt;/a&gt;&lt;br&gt;
&lt;a href="https://deis.com/"&gt;Deis&lt;/a&gt;&lt;br&gt;
&lt;a href="https://aws.amazon.com/elasticbeanstalk/"&gt;AWS Elastic Beanstalk&lt;/a&gt; (my addition)&lt;br&gt;&lt;/p&gt;
&lt;p&gt;I've used Elastic Beanstalk and it's a good way to abstract configuration of load balancers, Apache instances and so on.&lt;/p&gt;
&lt;h3 id="containers"&gt;Containers&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://linuxcontainers.org/"&gt;LXC (Linux Containers)&lt;/a&gt;&lt;br&gt;
&lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Docker is the leader here. I'm surprised that companies like Google or VMWare haven't come up with their own solution. Maybe soon.&lt;/p&gt;
&lt;h3 id="micro-oses-for-containers"&gt;Micro OSes for Containers&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://www.projectatomic.io/"&gt;Atomic Host&lt;/a&gt;&lt;br&gt;
&lt;a href="https://www.coreos.com/"&gt;CoreOS&lt;/a&gt;&lt;br&gt;
&lt;a href="https://vmware.github.io/photon/"&gt;VMWare Photon&lt;/a&gt;&lt;br&gt;
&lt;a href="http://rancher.com/rancher-os/"&gt;RancherOS&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Pretty neat concept of building a minimal OS that's targeted towards running containers.&lt;/p&gt;
&lt;h3 id="container-orchestration"&gt;Container Orchestration&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://www.docker.com/products/docker-swarm"&gt;Docker Swarm&lt;/a&gt;&lt;br&gt;
&lt;a href="https://kubernetes.io/"&gt;Kubernetes&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id="unikernels"&gt;Unikernels&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/emc-advanced-dev/unik"&gt;Unik&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id="container-as-a-service-caas"&gt;Container as a Service (CaaS)&lt;br&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://www.docker.com/products/docker-datacenter"&gt;Docker Datacenter&lt;/a&gt;&lt;br&gt;
&lt;a href="https://wiki.openstack.org/wiki/Magnum"&gt;Project Magnum on OpenStack&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id="software-defined-storage-and-storage-management-for-containers"&gt;Software Defined Storage and Storage Management for Containers&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://ceph.com/"&gt;Ceph&lt;/a&gt;&lt;br&gt;
&lt;a href="https://www.gluster.org/"&gt;Gluster&lt;/a&gt;&lt;br&gt;
&lt;a href="https://storpool.com/"&gt;StorPool&lt;/a&gt; (My addition)&lt;br&gt; &lt;/p&gt;
&lt;h3 id="continuous-integration-continuous-delivery"&gt;Continuous Integration / Continuous Delivery&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://jenkins.io/"&gt;Jenkins&lt;/a&gt;&lt;br&gt;
&lt;a href="https://drone.io/"&gt;Drone&lt;/a&gt;&lt;br&gt;
&lt;a href="https://travis-ci.com/getting_started"&gt;Travis CI&lt;/a&gt;&lt;br&gt;
&lt;a href="https://app.shippable.com/"&gt;Shippable&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;These are very easy to try out if you have projects on GitHub. Here's &lt;a href="https://github.com/pminkov/webserver"&gt;one&lt;/a&gt; on which I slapped the Drone badge.&lt;/p&gt;
&lt;h3 id="tools-for-configuration-management"&gt;Tools for Configuration Management&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://www.ansible.com/"&gt;Ansible&lt;/a&gt;&lt;br&gt;
&lt;a href="https://puppet.com/"&gt;Puppet&lt;/a&gt;&lt;br&gt;
&lt;a href="https://docs.saltstack.com/en/latest/"&gt;SaltStack&lt;/a&gt;&lt;br&gt;
&lt;a href="https://www.chef.io/"&gt;Chef&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Useful tools for running commands on multiple servers.&lt;/p&gt;
&lt;h3 id="build-and-release-tools"&gt;Build and Release Tools&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://www.terraform.io/docs/providers/"&gt;Terraform&lt;/a&gt;&lt;br&gt;
&lt;a href="https://bosh.io"&gt;BOSH&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id="key-value-pair-stores"&gt;Key-Value Pair Stores&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://coreos.com/etcd/"&gt;etcd&lt;/a&gt;&lt;br&gt;
&lt;a href="https://www.consul.io/"&gt;Consul&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3 id="building-images"&gt;Building Images&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://www.packer.io/"&gt;Packer&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Pretty neat. Just describe your instance and build a VM / Amazon image / Docker container. I can see that being pretty useful when you're building AMIs for AWS. Better than building it manually and not being able to reproduce it on another platform.&lt;/p&gt;
&lt;h3 id="debugging-logging-monitoring"&gt;Debugging, Logging, Monitoring&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://www.sysdig.com/"&gt;Sysdig&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/google/cadvisor"&gt;cAdvisor&lt;/a&gt;&lt;br&gt;
&lt;a href="http://www.fluentd.org/"&gt;Fluentd&lt;/a&gt;&lt;br&gt;
&lt;a href="https://www.datadoghq.com/"&gt;Datadog&lt;/a&gt;&lt;br&gt;&lt;/p&gt;</content></entry><entry><title>How much does it cost to run a Django app on AWS using Elastic Beanstalk?</title><link href="http://pminkov.github.io/blog/how-much-does-it-cost-to-run-a-django-app-on-aws-using-elastic-beanstalk.html" rel="alternate"></link><published>2016-04-20T13:56:00-07:00</published><updated>2016-04-20T13:56:00-07:00</updated><author><name>Petko Minkov</name></author><id>tag:pminkov.github.io,2016-04-20:/blog/how-much-does-it-cost-to-run-a-django-app-on-aws-using-elastic-beanstalk.html</id><summary type="html">&lt;p&gt;I've been running a Django app on &lt;a href="http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create-deploy-python-django.html"&gt;Elastic Beanstalk&lt;/a&gt; for a couple of months and I have a decent idea now of the costs involved and the pros and cons of this approach. My goal was to get something going as soon as possible and I'd say Elastic Beanstalk is …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've been running a Django app on &lt;a href="http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create-deploy-python-django.html"&gt;Elastic Beanstalk&lt;/a&gt; for a couple of months and I have a decent idea now of the costs involved and the pros and cons of this approach. My goal was to get something going as soon as possible and I'd say Elastic Beanstalk is good for that purpose. There are a few things that took me more time to figure out and I might write about them too, but overall everything is running smoothly now.&lt;/p&gt;
&lt;p&gt;Let's first describe what my setup is. Elastic Beanstalk is AWS's PaaS offering. I use a MySQL database running on RDS, a load balancer, a single EC2 instance and I have a DNS setup on Route 53. And that's more or less what I'm paying for. My bill was &lt;strong&gt;$42.58&lt;/strong&gt; last month. Breaking it down, here are the three major components it has:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;EC2&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I'm running a &lt;a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/t2-instances.html"&gt;t2.micro&lt;/a&gt; instance. It costs $0.013 per hour and I paid for 745 hours. Total: &lt;strong&gt;$9.69&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Load balancing&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Load balancing is not cheap. It costs $0.025 per hour and for 744 hours shown, that comes down to &lt;strong&gt;$18.60&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;RDS&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;RDS costs $0.017 per RDS T2 Micro instance hour and for 743 hours shown, I paid &lt;strong&gt;$12.63&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;If we sum these three, it comes down to &lt;strong&gt;$40.92&lt;/strong&gt;. I also paid the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$0.56 for RDS service storage.&lt;/li&gt;
&lt;li&gt;$0.45 for &lt;a href="https://aws.amazon.com/ebs/"&gt;EBS&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;$0.51 for Route 53.&lt;/li&gt;
&lt;li&gt;$0.07 for data transfer (my site being served to places around the world, but my site is not popular yet).&lt;/li&gt;
&lt;li&gt;$0.05 for S3 costs.&lt;/li&gt;
&lt;li&gt;$0.01 for data processed by the load balancer.&lt;/li&gt;
&lt;li&gt;$0.01 for SES.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These are minimal costs. Some of these are going to increase if my site becomes popular, but right now they are minimal.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How can I bring these costs down?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;It's possible to do all of this with a single EC2 instance and avoid paying for load balancing and RDS. What I get from these components right now is convenience and scalability. I don't really need scalability, since I don't operate at scale and might not come to that point. Convenience can be traded for the learning experience of settings up things manually. AWS has an &lt;a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/install-LAMP.html"&gt;article&lt;/a&gt; on how to install a LAMP setup on EC2. It doesn't look too complicated. Supposedly my bill will be around $10 per month for my 1GB RAM t2.micro machine.&lt;/p&gt;
&lt;p&gt;Another option would be to use &lt;a href="https://www.digitalocean.com/pricing/"&gt;Digital Ocean&lt;/a&gt;. They're basically offering something similar to EC2 instances, but I haven't looked too much in detail. Digital Ocean is an IaaS provider, you need to do some manual setup. Their cost is pretty similar. An offering with 1GB of RAM costs $10 per month too. That's a very rough comparison, but it seems like we're in the same ballpark if we're not pushing the limits on disk space or bandwidth.&lt;/p&gt;
&lt;p&gt;It should also be possibe to continue to use Elastic Beanstalk, but run a MySQL server directly on the EC2 instance. Here's a long &lt;a href="http://d0.awsstatic.com/whitepapers/rdbms-in-the-cloud-sql-server-on-aws.pdf"&gt;white paper&lt;/a&gt; that talks about this.&lt;/p&gt;</content><category term="AWS"></category><category term="Elastic Beanstalk"></category><category term="Python"></category><category term="Django"></category></entry></feed>